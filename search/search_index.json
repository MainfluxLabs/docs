{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MainfluxLabs # Getting Started API Mainflux is modern, scalable, secure open source and patent-free IoT cloud platform written in Go. It accepts user and thing connections over various network protocols (i.e. HTTP, MQTT, WebSocket, CoAP), thus making a seamless bridge between them. It is used as the IoT middleware for building complex IoT solutions. Features # Protocol bridging (i.e. HTTP, MQTT, WebSocket, CoAP) Device management and provisioning Fine-grained access control Platform logging and instrumentation support Container-based deployment using Docker License # Apache-2.0","title":"Overview"},{"location":"#mainfluxlabs","text":"Getting Started API Mainflux is modern, scalable, secure open source and patent-free IoT cloud platform written in Go. It accepts user and thing connections over various network protocols (i.e. HTTP, MQTT, WebSocket, CoAP), thus making a seamless bridge between them. It is used as the IoT middleware for building complex IoT solutions.","title":"MainfluxLabs"},{"location":"#features","text":"Protocol bridging (i.e. HTTP, MQTT, WebSocket, CoAP) Device management and provisioning Fine-grained access control Platform logging and instrumentation support Container-based deployment using Docker","title":"Features"},{"location":"#license","text":"Apache-2.0","title":"License"},{"location":"api/","text":"API # Reference # API reference in the Swagger UI can be found at: https://mainfluxlabs.github.io/mainflux Users # Create Token # To log in to the Mainflux system, you need to create a user_token . The obtained token is used for access control in the system. Must-have: registered email and password curl -s -S -i -X POST -H \"Content-Type: application/json\" http://localhost/tokens -d '{\"email\":\"<user_email>\", \"password\":\"<user_password>\"}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:07:18 GMT Content-Type: application/json Content-Length: 281 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * {\"token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MTU0MjQ4MzgsImlhdCI6MTYxNTM4ODgzOCwiaXNzIjoibWFpbmZsdXguYXV0aCIsInN1YiI6InRlc3RAZW1haWwuY29tIiwiaXNzdWVyX2lkIjoiZDc4MmI0MmItZTMxNy00Y2Q3LTlkZDAtNGUyZWEwZjM0OWM4IiwidHlwZSI6MH0.TAQxV6TImKw06RsK0J11rOHiWPvexEOA4BNZnhLhtxs\"} Create User # The predefined user within the Mainflux system is the root admin . In order to add users to the system, the root administrator must create accounts for them. Must-have: email , password (password must contain at least 8 characters) and user_token curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/users -d '{\"email\":\"<user_email>\", \"password\":\"<user_password>\"}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:06:45 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Location: /users/d782b42b-e317-4cd7-9dd0-4e2ea0f349c8 Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * View User # You can always check the user entity that is logged in by entering the user ID and user_token . Must-have: user_id and user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/users/<user_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:09:47 GMT Content-Type: application/json Content-Length: 85 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * {\"id\":\"d782b42b-e317-4cd7-9dd0-4e2ea0f349c8\",\"email\":\"test@email.com\"} List Users # You can get all users in the database by calling this function Must-have: user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/users Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:11:28 GMT Content-Type: application/json Content-Length: 217 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * {\"total\":2,\"offset\":0,\"limit\":10,\"Users\":[{\"id\":\"4bf4a13a-e9c3-4207-aa11-fe569986c301\",\"email\":\"admin@example.com\"},{\"id\":\"d782b42b-e317-4cd7-9dd0-4e2ea0f349c8\",\"email\":\"test@email.com\"}]} Update User # Updating user's metadata Must-have: user_token curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/users -d '{\"metadata\":{\"foo\":\"bar\"}}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:15:31 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * Change Password # Changing the user password can be done by calling the update password function Must-have: user_token , old_password and password (new_password) curl -s -S -i -X PATCH -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/password -d '{\"old_password\":\"<old_password>\", \"password\":\"<new_password>\"}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:17:36 GMT Content-Type: application/json Content-Length: 11 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * Orgs # Create Org # To create an org, you need the org name, description, metadata and a user_token Must-have: user_token curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs -d '{\"name\": \"<org_name>\", \"description\": \"<org_description>\", \"metadata\": {}}' Response: HTTP/1.1 201 Created Content-Type: application/json Location: /orgs/25da5d7a-d3f5-435e-bcad-0cf22343121a Date: Fri, 14 Jul 2023 14:03:14 GMT Content-Length: 0 View Org # To view an org, you need the org ID and a user_token Must-have: user_token and org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id> Response: HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 14 Jul 2023 14:22:48 GMT Content-Length: 250 {\"id\":\"25da5d7a-d3f5-435e-bcad-0cf22343121a\",\"name\":\"org_name\",\"owner_id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"description\":\"org_description\",\"created_at\":\"2023-07-14T14:03:14.897Z\",\"updated_at\":\"2023-07-14T14:03:14.897Z\"} Update Org # To update an org, you need the org ID, name, description, metadata and a user_token Must-have: user_token and org_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id> -d '{\"name\": \"<org_name>\", \"description\": \"<org_desc>\", \"metadata\":{}}' Response: HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 14 Jul 2023 14:41:23 GMT Content-Length: 0 Delete Org # To delete an org, you need the org ID and a user_token Must-have: user_token and org_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id> Response: HTTP/1.1 204 No Content Content-Type: application/json Date: Fri, 14 Jul 2023 14:47:24 GMT List Orgs # To list orgs, you need a user_token Only admin users can list all orgs, other users can only list orgs they are members of. Must-have: user_token curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs Response: HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 14 Jul 2023 20:43:58 GMT Content-Length: 456 {\"limit\":10,\"offset\":0,\"total\":2,\"orgs\":[{\"id\":\"9883c534-eeb5-4e30-aec9-bd6cf1639f95\",\"name\":\"org_name_1\",\"owner_id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\", \"metadata\":{\"meta\":\"test1\"},\"created_at\":\"2023-07-13T09:35:40.116Z\",\"updated_at\":\"2023-07-13T10:58:32.523Z\"},{\"id\":\"49114ab9-acbb-4d0b-be01-0dc2f396136c\",\"name\":\"org_name_2\",\"owner_id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"metadata\":{\"meta\":\"test2\"},\"created_at\":\"2023-07-13T09:29:41.718Z\",\"updated_at\":\"2023-07-13T11:08:22.586Z\"}]} Org Members # Assign Members # To assign members to an org, you need the org ID, member emails, member roles and a user_token Only roles defined on Roles Section are allowed. Must-have: email , user_token and org_id curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members -d '{\"org_members\":[{\"email\": \"<user_email>\",\"role\": \"user_role\"}]}' Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 17 Jul 2023 08:24:44 GMT Content-Length: 0 Unassign Members # To unassign members from an org, you need the org ID, member IDs and a user_token Must-have: user_token , org_id and member_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members -d '{\"member_ids\":[\"<member_id>\"]}' Response: HTTP/1.1 204 No Content Content-Type: application/json Date: Mon, 17 Jul 2023 08:44:58 GMT Update Members # To update members of an org, you need the org ID, member ids, role and a user_token Must-have: user_token , org_id and user_email curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_id>\" http://localhost/orgs/<org_id>/members -d '{\"org_members\":[{\"member_id\":\"<member_id>\", \"role\":\"new_role\"}]}' View Member # To view member of an org, you need the org ID, member ID and a user_token Must-have: user_token , member_id , org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members/<member_id> Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 24 Mar 2025 09:10:20 GMT Content-Length: 87 {\"id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"email\":\"user@example.com\",\"role\":\"owner\"} Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 17 Jul 2023 08:54:12 GMT Content-Length: 0 List Members # To list members of an org, you need the org ID and a user_token Must-have: user_token and org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 17 Jul 2023 09:13:22 GMT Content-Length: 235 {\"limit\":10,\"offset\":0,\"total\":2,\"members\":[{\"id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"email\":\"user@example.com\",\"role\":\"owner\"},{\"id\":\"34cf0a14-dc23-42ed-87bd-fa7ecc205bc2\",\"email\":\"user_2@example.com\",\"role\":\"admin\"} Groups # Create Group # To create a group, you need the group name, description, metadata, org_id and a user_token Must-have: org_id , user_token curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/groups -d '{\"name\": \"<group_name>\", \"description\": \"<group_description>\", \"metadata\": {}}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 16:58:09 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Location: /groups/01F0EH61SA7C7NDKWYCXVG7PWD Access-Control-Expose-Headers: Location View Group # Get a group entity for a logged-in user Must-have: user_token and group_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:06:48 GMT Content-Type: application/json Content-Length: 264 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"} List Groups # Get all groups, list requests accepts limit and offset query parameters Must-have: user_token curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:09:28 GMT Content-Type: application/json Content-Length: 573 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"limit\":10,\"offset\":0,\"groups\":[{\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"},{\"id\":\"2513d843-abf8-4db4-93fd-bdc8917d42mm\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name_1\",\"description\":\"desc\",\"created_at\":\"2021-03-10T17:07:52.13Z\",\"updated_at\":\"2021-03-10T17:07:52.13Z\"}]} List Groups by Org # Get groups by a specific organization Must-have: user_token , org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 15:10:28 GMT Content-Type: application/json Content-Length: 573 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"limit\":10,\"offset\":0,\"groups\":[{\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"},{\"id\":\"2513d843-abf8-4db4-93fd-bdc8917d42mm\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name_1\",\"description\":\"desc\",\"created_at\":\"2021-03-10T17:07:52.13Z\",\"updated_at\":\"2021-03-10T17:07:52.13Z\"}]} Update Group # Update group entity Must-have: user_token , group_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id> -d '{\"name\": \"<group_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:11:51 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location Delete Group # Delete a group entity Must-have: user_token , group_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id> Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:14:13 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location View Group by Thing # Get a group entity by thing Must-have: user_token , thing_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id>/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:06:48 GMT Content-Type: application/json Content-Length: 264 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"} View Group by Profile # Get a group entity by profile Must-have: user_token , profile_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id>/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:06:48 GMT Content-Type: application/json Content-Length: 264 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"} Group Members # Assign Members # In order to assign members to a group, you need the group ID, member roles and a user_token Only roles defined on Roles Section are allowed. Must-have: user_token , group_id , group_members curl -isSX POST http://localhost/groups/<group_id>/members -d '{\"group_members\":{\"id\":\"123e4567-e89b-12d3-a456-426614174000\",\"role\":\"viewer\"}}' -H \"Authorization: Bearer <user_token>\" -H 'Content-Type: application/json' Response: HTTP/1.1 201 Created Content-Type: application/json Date: Wed, 03 Nov 2021 13:00:14 GMT Content-Length: 3 {} Unassign Members # To unassign members from a group, you need the group ID, member IDs, role and a user_token Must-have: user_token , group_id , member_ids curl -isSX PATCH http://localhost/groups/<group_id>/members -d '{\"member_ids\":[\"987fbc97-4bed-5078-9f07-9141ba07c9f3\",\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\"]}' -H \"Authorization: Bearer <user_token>\" -H 'Content-Type: application/json' Response: HTTP/1.1 204 No Content Content-Type: application/json Date: Wed, 03 Nov 2021 13:00:05 GMT Update Members # To update members of an group, you need the group ID, member ids and a user_token Must-have: user_token , group_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/members -d '{\"group_members\":{\"id\":\"123e4567-e89b-12d3-a456-426614174000\",\"role\":\"viewer\"}}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:11:51 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location List Members by Group # To list members by group, you need the group ID and a user_token Must-have: user_token , group_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/members Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:09:28 GMT Content-Type: application/json Content-Length: 225 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"limit\":10,\"offset\":0,\"group_members\":[{\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"email\":\"user@gmail.com\",\"role\":\"viewer\"},{\"id\":\"2513d843-abf8-4db4-93fd-bdc8917d42mm\",\"email\":\"user2@gmail.com\",\"role\":\"editor\"}]} Profiles # Create Profile with external ID # A profile is a set of configuration parameters that can be applied to a Thing within the same group. To create a profile with external ID, the user needs to provide a UUID v4 format unique ID, group_id , metadata, config and a user_token . The detailed configuration of the Profile Config can be found at Profile Config . Must-have: user_token , group_id curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"name\": \"<profile_name>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:26:51 GMT Content-Type: application/json Content-Length: 204 Connection: keep-alive Location: /profiles/db4b7428-e278-4fe3-b85a-d65554d6abe9 Access-Control-Expose-Headers: Location {\"profiles\":[{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"name\":\"profile_name\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]} Create Profiles # The same as creating a profile with external ID the user can create multiple profiles at once by providing UUID v4 format unique ID in a series of profiles together with a user_token and <group_id> . Must-have: user_token , group_id and profiles curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles -d '[{\"name\": \"<profile_name_1>\"}, {\"name\": \"<profile_name_2>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:28:10 GMT Content-Type: application/json Content-Length: 352 Connection: keep-alive Access-Control-Expose-Headers: Location {\"profiles\":[{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"name\":\"profile_name_1\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\"},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"name\":\"profile_name_2\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\",\"metadata\":{\"key\":\"val\"},\"config\":{\"content-type\":\"application/json\"}}]} Create Profiles with external ID # You can create multiple profiles with external ID at once Must-have: user_token , group_id and at least 2 profiles curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx1>\",\"name\": \"<profile_name_1>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}, {\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx2>\",\"name\": \"<profile_name_2>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:28:10 GMT Content-Type: application/json Content-Length: 398 Connection: keep-alive Access-Control-Expose-Headers: Location {\"profiles\":[{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx1>\",\"name\":\"profile_name_1\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx2>\",\"name\":\"profile_name_2\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]} View Profile # Get a profile entity for a logged-in user Must-have: user_token and profile_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:29:49 GMT Content-Type: application/json Content-Length: 188 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"content-type\":\"application/json\"}} View Profile by Thing # Get a profile by a specific thing Must-have: user_token and thing_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id>/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 11:20:10 GMT Content-Type: application/json Content-Length: 188 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"content-type\":\"application/json\"}} List Profiles # Get all profiles that the user can access, list requests accepts limit and offset query parameters Must-have: user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:30:34 GMT Content-Type: application/json Content-Length: 493 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"profiles\":[{\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_1\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_2\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]} List Profiles by Group # Get all profiles by a certain group where the user has access Must-have: user_token , <group_id> curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:30:34 GMT Content-Type: application/json Content-Length: 427 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"offset\":0,\"limit\":10,\"profiles\":[{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_1\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_2\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]} List Profiles by Org # Get all profiles by a certain organization Must-have: user_token , <org_id> curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 10:30:34 GMT Content-Type: application/json Content-Length: 493 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"profiles\":[{\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"b9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_1\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_2\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]} Update Profile # Update profile entity Must-have: user_token and profile_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id> -d '{\"name\": \"<profile_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:32:08 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location Delete Profile # Delete a profile entity that is not assigned to any Thing Must-have: user_token and profile_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id> Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:33:21 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location Things # Create Thing with external ID # It is often the case that the user will want to integrate the existing solutions, e.g. an asset management system, with the Mainflux platform. To simplify the integration between the systems and avoid artificial cross-platform reference, such as special fields in Mainflux Things metadata, it is possible to set Mainflux Thing ID with an existing unique ID while create the Thing. This way, the user can set the existing ID as the Thing ID of a newly created Thing to keep reference between Thing and the asset that Thing represents. There are two limitations - the existing ID have to be in UUID V4 format, and it has to be unique in the Mainflux domain. To create a thing with an external ID, you need provide the UUID v4 format ID together with thing name, and other fields as well as a user_token , metadata, group_id and the profile ID assigned to it. Must-have: user_token , group_id , profile_id curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"profile_id\":\"<profile_id>\",\"name\":\"<thing_name>\",\"metadata\":{\"key\":\"val\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:18:37 GMT Content-Type: application/json Content-Length: 199 Connection: keep-alive Access-Control-Expose-Headers: Location {\"things\":[{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}}]} Create Things # You can create multiple things at once by entering a series of things structures, group_id and a user_token Must-have: user_token , group_id and things curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things -d '[{\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_1>\"}, {\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_2>\",\"metadata\":{\"key\":\"val\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:19:48 GMT Content-Type: application/json Content-Length: 365 Connection: keep-alive Access-Control-Expose-Headers: Location {\"things\":[{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"x9bf9e57-1685-4c89-bafb-ff5af830be8x\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\",\"metadata\":{\"key\":\"val\"}}]} Create Things with external ID # The same as creating a Thing with external ID the user can create multiple things at once by providing UUID v4 format unique ID in a series of things together with a user_token and group_id Must-have: user_token , group_id and things curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx1>\",\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_1>\"}, {\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx2>\",\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_2>\"}]' View Thing # You can get thing entity by entering the thing ID and user_token Must-have: user_token and thing_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:20:52 GMT Content-Type: application/json Content-Length: 185 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}} View Metadata by Key # Get thing metadata by providing the thing_key Must-have: thing_key curl -s -S -i -X GET -H \"Authorization: Thing <thing_key>\" http://localhost/metadata Response: Server: nginx/1.20.0 Date: Tue, 21 Jan 2025 15:46:10 GMT Content-Type: application/json Content-Length: 29 Connection: keep-alive Access-Control-Expose-Headers: Location {\"metadata\":{\"test\":\"data\"}} List Things # Get all things that the user can access, list requests accepts limit and offset query parameters Must-have: user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]} List Things by Group # Get all things by a certain group Must-have: user_token , group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]} List Things by Profile # Get all things by a certain profile Must-have: user_token , profile_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id>/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]} List Things by Org # Get all things by a certain organization Must-have: user_token , org_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]} Update Thing # Updating a thing entity Must-have: user_token and thing_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id> -d '{\"name\": \"<thing_name>\",\"profile_id\":\"<profile_id>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:23:36 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location Update Things Metadata # Updating a things metadata Must-have: user_token curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things -d '[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"metadata\":{\"new_key1\":\"new_val1\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"metadata\":{\"new_key2\":\"new_val2\"}}]' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 16:00:00 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location Delete Thing # To delete a thing you need a thing_id and a user_token Must-have: user_token and thing_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id> Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:24:44 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location Identify # Validates thing's key and returns its ID if key is valid Must-have: thing_key curl -s -S -i -X POST -H \"Content-Type: application/json\" http://localhost/identify -d '{\"token\": \"<thing_key>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 22 Mar 2021 15:04:41 GMT Content-Type: application/json Content-Length: 46 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"d69d0098-072b-41bf-8c6e-ce4dbb12d333\"} Messages # Send Messages # Sends message via HTTP protocol Must-have: thing_key curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Thing <thing_key>\" http://localhost/http/messages -d '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09,\"bu\":\"A\",\"bver\":5,\"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' Response: HTTP/1.1 202 Accepted Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 16:53:54 GMT Content-Length: 0 Connection: keep-alive Read Messages # Reads messages from database Must-have: thing_key curl -s -S -i -H \"Authorization: Thing <thing_key>\" http://localhost:<service_port>/messages?offset=0&limit=5 Response: HTTP/1.1 200 OK Content-Type: application/json Date: Wed, 10 Mar 2021 16:54:58 GMT Content-Length: 660 {\"offset\":0,\"limit\":10,\"format\":\"messages\",\"total\":3,\"messages\":[{\"publisher\":\"33eb28c3-4ca2-45c3-b1c5-d5d049c6c24e\",\"protocol\":\"http\",\"name\":\"some-base-name:voltage\",\"unit\":\"V\",\"time\":1276020076.001,\"value\":120.1},{\"publisher\":\"33eb28c3-4ca2-45c3-b1c5-d5d049c6c24e\",\"protocol\":\"http\",\"name\":\"some-base-name:current\",\"unit\":\"A\",\"time\":1276020072.001,\"value\":1.3},{\"publisher\":\"33eb28c3-4ca2-45c3-b1c5-d5d049c6c24e\",\"protocol\":\"http\",\"name\":\"some-base-name:current\",\"unit\":\"A\",\"time\":1276020071.001,\"value\":1.2}]} API Key # Issue API Key # Generates a new API key. Then new API key will be uniquely identified by its ID. Duration is expressed in seconds. Must-have: user_token curl -isSX POST http://localhost/keys -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" -d '{\"type\":2, \"duration\":10000}' Response: HTTP/1.1 201 Created Server: nginx/1.20.0 Date: Sun, 19 Dec 2021 17:39:44 GMT Content-Type: application/json Content-Length: 476 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"4d62fb1e-085e-435c-a0c5-5255febfa35b\",\"value\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NDAwMzU1ODQsImp0aSI6IjRkNjJmYjFlLTA4NWUtNDM1Yy1hMGM1LTUyNTVmZWJmYTM1YiIsImlhdCI6MTYzOTkzNTU4NCwiaXNzIjoibWFpbmZsdXguYXV0aCIsInN1YiI6ImZscDFAZW1haWwuY29tIiwiaXNzdWVyX2lkIjoiYzkzY2FmYjMtYjNhNy00ZTdmLWE0NzAtMTVjMTRkOGVkMWUwIiwidHlwZSI6Mn0.RnvjhygEPPWFDEUKtfk5okzVhZzOcO0azr8gd5vby5M\",\"issued_at\":\"2021-12-19T17:39:44.175088349Z\",\"expires_at\":\"2021-12-20T21:26:24.175088349Z\"} View API key details # Must-have: 'user_token' and 'key_id' curl -isSX GET http://localhost/keys/<key_id> -H 'Content-Type: application/json' -H 'Authorization: Bearer <user_token>' Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Sun, 19 Dec 2021 17:43:30 GMT Content-Type: application/json Content-Length: 218 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"issuer_id\":\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"subject\":\"test@email.com\",\"type\":2,\"issued_at\":\"2021-12-19T17:42:40.884521Z\",\"expires_at\":\"2021-12-20T21:29:20.884521Z\"} Revoke API key identified by the given ID # Must-have: 'user_token' and 'key_id' curl -isSX DELETE http://localhost/keys/<key_id> -H 'Content-Type: application/json' -H 'Authorization: Bearer <user_token>' Response: HTTP/1.1 204 No Content Server: nginx/1.20.0 Date: Sun, 19 Dec 2021 17:47:11 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location Webhooks # Create Webhooks # To forward a message to another platform, you need to create a Webhook with the necessary data such as the name of the Webhook, thing_id which refers to the Thing for which the Webhook is being created, the url to which the message will be forwarded and HTTP headers specific for the certain webhook. You can create multiple Webhooks at once by entering a series of Webhooks structures, thing_id and a user_token . Must-have: user_token , thing_id , name and url curl -s -S -i -X POST -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/webhooks -d '{\"webhooks: [{\"name\":\"webhook_name\",\"url\":\"https://webhook.com\",\"headers\":{\"Content-Type\":\"application/json\"}}]}' Response: HTTP/1.1 201 Created Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 11:47:12 GMT Content-Type: application/json Content-Length: 191 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"name\":\"webhook_name\",\"url\":\"https://webhook.com\",\"headers\":{\"Content-Type\":\"application/json\"}} List Webhooks by Group # You can get all Webhooks for certain Group by entering user_token and group_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/webhooks Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 11:44:57 GMT Content-Type: application/json Content-Length: 488 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"webhooks\":[{\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"url\":\"https://api.test.com/\",\"headers\":{\"Content-Type\":\"application/json\"}},{\"id\":\"1234f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"12140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test2\",\"url\":\"https://api.test2.com/\",\"headers\":{}}]} List Webhooks by Thing # You can get all Webhooks for certain Thing by entering user_token and thing_id . Must-have: user_token and thing_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/things/<thing_id>/webhooks Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Mon, 24 Mar 2025 11:44:57 GMT Content-Type: application/json Content-Length: 250 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":1,\"offset\":0,\"limit\":10,\"webhooks\":[{\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"url\":\"https://api.test.com/\",\"headers\":{\"Content-Type\":\"application/json\"}}]} View Webhook # View details of a certain Webhook by entering user_token and webhook_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/webhooks/<webhook_id> Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 11:44:57 GMT Content-Type: application/json Content-Length: 185 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"url\":\"https://api.test.com/\",\"headers\":{\"Content-Type\":\"application/json\"}} Update Webhook # Update data of webhook with provided ID and user_token Must-have: user_token and webhook_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/webhooks/<webhook_id> -d '{\"name\": \"<webhook_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 11:54:52 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location Delete Webhooks # Delete webhooks by given IDs Must-have: user_token , webhook_ids curl -s -S -i -X PATCH -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/webhooks -d '{\"webhook_ids\":[\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"2513d843-abf8-4db4-93fd-bdc8917d42mm\"]}' Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 11:55:10 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location Notifiers # Create Notifiers # In order to send email notifications to certain contacts when a message arrives, you need to create a Notifier with the necessary data, such as the Notifier's name , group_id , which refers to the Group for which the Notifier is being created, the contacts to which the notifications will be sent and optional metadata . You can create multiple Notifiers at once by entering a series of Notifiers structures, group_id and a user_token . Must-have: user_token , group_id , name and contacts curl -s -S -i -X POST -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/notifiers -d '{\"notifiers: [{\"name\":\"notifier_name\",\"contacts\": [\"email1@example.com\", \"email2@example.com\"],\"metadata\":{}}]}' Response: HTTP/1.1 201 Created Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 12:17:12 GMT Content-Type: application/json Content-Length: 190 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"a630f594-d967-4c54-85ef-af58efe8e8eb\",\"group_id\":\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"name\":\"notifier_name\",\"contacts\": [\"email1@example.com\", \"email2@example.com\"],\"metadata\":{}} Note: The logged-in user who creates a Notifier for a certain Group must have the role of \"editor\" of that Group. List Notifiers by Group # You can get all Notifiers for certain Group by entering user_token and group_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/notifiers Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 12:19:57 GMT Content-Type: application/json Content-Length: 337 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"offset\":0,\"limit\":10,\"notifiers\":[{\"id\":\"a630f594-d967-4c54-85ef-af58efe8e8eb\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"contacts\": [\"test1@example.com\"]},{\"id\":\"2234f594-d967-4c54-85ef-af58efe8e8ed\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test2\",\"contacts\": [\"test2@example.com\"]}]} View Notifier # View details of a certain Notifier by entering user_token and notifier_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/notifiers/<notifier_id> Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 12:24:57 GMT Content-Type: application/json Content-Length: 145 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"a630f594-d967-4c54-85ef-af58efe8e8eb\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"contacts\": [\"test1@example.com\"]}} Update Notifier # Update data of notifier with provided ID and user_token Must-have: user_token and notifier_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/notifiers/<notifier_id> -d '{\"name\": \"<new_notifier_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 12:34:52 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location Delete Notifiers # Delete notifiers by given IDs Must-have: user_token , group_id , notifier_ids curl -s -S -i -X PATCH -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/notifiers -d '{\"notifier_ids\":[\"a93cafb3-b3a7-4e7f-a470-15c14d8ed1e1\",\"b513d843-abf8-4db4-93fd-bdc8917d42m2\"]}' Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 12:55:10 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location","title":"API"},{"location":"api/#api","text":"","title":"API"},{"location":"api/#reference","text":"API reference in the Swagger UI can be found at: https://mainfluxlabs.github.io/mainflux","title":"Reference"},{"location":"api/#users","text":"","title":"Users"},{"location":"api/#create-token","text":"To log in to the Mainflux system, you need to create a user_token . The obtained token is used for access control in the system. Must-have: registered email and password curl -s -S -i -X POST -H \"Content-Type: application/json\" http://localhost/tokens -d '{\"email\":\"<user_email>\", \"password\":\"<user_password>\"}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:07:18 GMT Content-Type: application/json Content-Length: 281 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * {\"token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MTU0MjQ4MzgsImlhdCI6MTYxNTM4ODgzOCwiaXNzIjoibWFpbmZsdXguYXV0aCIsInN1YiI6InRlc3RAZW1haWwuY29tIiwiaXNzdWVyX2lkIjoiZDc4MmI0MmItZTMxNy00Y2Q3LTlkZDAtNGUyZWEwZjM0OWM4IiwidHlwZSI6MH0.TAQxV6TImKw06RsK0J11rOHiWPvexEOA4BNZnhLhtxs\"}","title":"Create Token"},{"location":"api/#create-user","text":"The predefined user within the Mainflux system is the root admin . In order to add users to the system, the root administrator must create accounts for them. Must-have: email , password (password must contain at least 8 characters) and user_token curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/users -d '{\"email\":\"<user_email>\", \"password\":\"<user_password>\"}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:06:45 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Location: /users/d782b42b-e317-4cd7-9dd0-4e2ea0f349c8 Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: *","title":"Create User"},{"location":"api/#view-user","text":"You can always check the user entity that is logged in by entering the user ID and user_token . Must-have: user_id and user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/users/<user_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:09:47 GMT Content-Type: application/json Content-Length: 85 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * {\"id\":\"d782b42b-e317-4cd7-9dd0-4e2ea0f349c8\",\"email\":\"test@email.com\"}","title":"View User"},{"location":"api/#list-users","text":"You can get all users in the database by calling this function Must-have: user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/users Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:11:28 GMT Content-Type: application/json Content-Length: 217 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: * {\"total\":2,\"offset\":0,\"limit\":10,\"Users\":[{\"id\":\"4bf4a13a-e9c3-4207-aa11-fe569986c301\",\"email\":\"admin@example.com\"},{\"id\":\"d782b42b-e317-4cd7-9dd0-4e2ea0f349c8\",\"email\":\"test@email.com\"}]}","title":"List Users"},{"location":"api/#update-user","text":"Updating user's metadata Must-have: user_token curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/users -d '{\"metadata\":{\"foo\":\"bar\"}}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:15:31 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: *","title":"Update User"},{"location":"api/#change-password","text":"Changing the user password can be done by calling the update password function Must-have: user_token , old_password and password (new_password) curl -s -S -i -X PATCH -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/password -d '{\"old_password\":\"<old_password>\", \"password\":\"<new_password>\"}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:17:36 GMT Content-Type: application/json Content-Length: 11 Connection: keep-alive Strict-Transport-Security: max-age=63072000; includeSubdomains X-Frame-Options: DENY X-Content-Type-Options: nosniff Access-Control-Allow-Origin: * Access-Control-Allow-Methods: * Access-Control-Allow-Headers: *","title":"Change Password"},{"location":"api/#orgs","text":"","title":"Orgs"},{"location":"api/#create-org","text":"To create an org, you need the org name, description, metadata and a user_token Must-have: user_token curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs -d '{\"name\": \"<org_name>\", \"description\": \"<org_description>\", \"metadata\": {}}' Response: HTTP/1.1 201 Created Content-Type: application/json Location: /orgs/25da5d7a-d3f5-435e-bcad-0cf22343121a Date: Fri, 14 Jul 2023 14:03:14 GMT Content-Length: 0","title":"Create Org"},{"location":"api/#view-org","text":"To view an org, you need the org ID and a user_token Must-have: user_token and org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id> Response: HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 14 Jul 2023 14:22:48 GMT Content-Length: 250 {\"id\":\"25da5d7a-d3f5-435e-bcad-0cf22343121a\",\"name\":\"org_name\",\"owner_id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"description\":\"org_description\",\"created_at\":\"2023-07-14T14:03:14.897Z\",\"updated_at\":\"2023-07-14T14:03:14.897Z\"}","title":"View Org"},{"location":"api/#update-org","text":"To update an org, you need the org ID, name, description, metadata and a user_token Must-have: user_token and org_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id> -d '{\"name\": \"<org_name>\", \"description\": \"<org_desc>\", \"metadata\":{}}' Response: HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 14 Jul 2023 14:41:23 GMT Content-Length: 0","title":"Update Org"},{"location":"api/#delete-org","text":"To delete an org, you need the org ID and a user_token Must-have: user_token and org_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id> Response: HTTP/1.1 204 No Content Content-Type: application/json Date: Fri, 14 Jul 2023 14:47:24 GMT","title":"Delete Org"},{"location":"api/#list-orgs","text":"To list orgs, you need a user_token Only admin users can list all orgs, other users can only list orgs they are members of. Must-have: user_token curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs Response: HTTP/1.1 200 OK Content-Type: application/json Date: Fri, 14 Jul 2023 20:43:58 GMT Content-Length: 456 {\"limit\":10,\"offset\":0,\"total\":2,\"orgs\":[{\"id\":\"9883c534-eeb5-4e30-aec9-bd6cf1639f95\",\"name\":\"org_name_1\",\"owner_id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\", \"metadata\":{\"meta\":\"test1\"},\"created_at\":\"2023-07-13T09:35:40.116Z\",\"updated_at\":\"2023-07-13T10:58:32.523Z\"},{\"id\":\"49114ab9-acbb-4d0b-be01-0dc2f396136c\",\"name\":\"org_name_2\",\"owner_id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"metadata\":{\"meta\":\"test2\"},\"created_at\":\"2023-07-13T09:29:41.718Z\",\"updated_at\":\"2023-07-13T11:08:22.586Z\"}]}","title":"List Orgs"},{"location":"api/#org-members","text":"","title":"Org Members"},{"location":"api/#assign-members","text":"To assign members to an org, you need the org ID, member emails, member roles and a user_token Only roles defined on Roles Section are allowed. Must-have: email , user_token and org_id curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members -d '{\"org_members\":[{\"email\": \"<user_email>\",\"role\": \"user_role\"}]}' Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 17 Jul 2023 08:24:44 GMT Content-Length: 0","title":"Assign Members"},{"location":"api/#unassign-members","text":"To unassign members from an org, you need the org ID, member IDs and a user_token Must-have: user_token , org_id and member_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members -d '{\"member_ids\":[\"<member_id>\"]}' Response: HTTP/1.1 204 No Content Content-Type: application/json Date: Mon, 17 Jul 2023 08:44:58 GMT","title":"Unassign Members"},{"location":"api/#update-members","text":"To update members of an org, you need the org ID, member ids, role and a user_token Must-have: user_token , org_id and user_email curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_id>\" http://localhost/orgs/<org_id>/members -d '{\"org_members\":[{\"member_id\":\"<member_id>\", \"role\":\"new_role\"}]}'","title":"Update Members"},{"location":"api/#view-member","text":"To view member of an org, you need the org ID, member ID and a user_token Must-have: user_token , member_id , org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members/<member_id> Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 24 Mar 2025 09:10:20 GMT Content-Length: 87 {\"id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"email\":\"user@example.com\",\"role\":\"owner\"} Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 17 Jul 2023 08:54:12 GMT Content-Length: 0","title":"View Member"},{"location":"api/#list-members","text":"To list members of an org, you need the org ID and a user_token Must-have: user_token and org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/members Response: HTTP/1.1 200 OK Content-Type: application/json Date: Mon, 17 Jul 2023 09:13:22 GMT Content-Length: 235 {\"limit\":10,\"offset\":0,\"total\":2,\"members\":[{\"id\":\"a08bd22c-916d-4ed1-8ca4-8d32ede58822\",\"email\":\"user@example.com\",\"role\":\"owner\"},{\"id\":\"34cf0a14-dc23-42ed-87bd-fa7ecc205bc2\",\"email\":\"user_2@example.com\",\"role\":\"admin\"}","title":"List Members"},{"location":"api/#groups","text":"","title":"Groups"},{"location":"api/#create-group","text":"To create a group, you need the group name, description, metadata, org_id and a user_token Must-have: org_id , user_token curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/groups -d '{\"name\": \"<group_name>\", \"description\": \"<group_description>\", \"metadata\": {}}' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 16:58:09 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Location: /groups/01F0EH61SA7C7NDKWYCXVG7PWD Access-Control-Expose-Headers: Location","title":"Create Group"},{"location":"api/#view-group","text":"Get a group entity for a logged-in user Must-have: user_token and group_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:06:48 GMT Content-Type: application/json Content-Length: 264 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"}","title":"View Group"},{"location":"api/#list-groups","text":"Get all groups, list requests accepts limit and offset query parameters Must-have: user_token curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:09:28 GMT Content-Type: application/json Content-Length: 573 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"limit\":10,\"offset\":0,\"groups\":[{\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"},{\"id\":\"2513d843-abf8-4db4-93fd-bdc8917d42mm\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name_1\",\"description\":\"desc\",\"created_at\":\"2021-03-10T17:07:52.13Z\",\"updated_at\":\"2021-03-10T17:07:52.13Z\"}]}","title":"List Groups"},{"location":"api/#list-groups-by-org","text":"Get groups by a specific organization Must-have: user_token , org_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 15:10:28 GMT Content-Type: application/json Content-Length: 573 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"limit\":10,\"offset\":0,\"groups\":[{\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"},{\"id\":\"2513d843-abf8-4db4-93fd-bdc8917d42mm\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name_1\",\"description\":\"desc\",\"created_at\":\"2021-03-10T17:07:52.13Z\",\"updated_at\":\"2021-03-10T17:07:52.13Z\"}]}","title":"List Groups by Org"},{"location":"api/#update-group","text":"Update group entity Must-have: user_token , group_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id> -d '{\"name\": \"<group_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:11:51 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Update Group"},{"location":"api/#delete-group","text":"Delete a group entity Must-have: user_token , group_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id> Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:14:13 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Delete Group"},{"location":"api/#view-group-by-thing","text":"Get a group entity by thing Must-have: user_token , thing_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id>/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:06:48 GMT Content-Type: application/json Content-Length: 264 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"}","title":"View Group by Thing"},{"location":"api/#view-group-by-profile","text":"Get a group entity by profile Must-have: user_token , profile_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id>/groups Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:06:48 GMT Content-Type: application/json Content-Length: 264 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"org_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"group_name\",\"description\":\"desc\",\"created_at\":\"2021-03-10T16:58:09.579Z\",\"updated_at\":\"2021-03-10T16:58:09.579Z\"}","title":"View Group by Profile"},{"location":"api/#group-members","text":"","title":"Group Members"},{"location":"api/#assign-members_1","text":"In order to assign members to a group, you need the group ID, member roles and a user_token Only roles defined on Roles Section are allowed. Must-have: user_token , group_id , group_members curl -isSX POST http://localhost/groups/<group_id>/members -d '{\"group_members\":{\"id\":\"123e4567-e89b-12d3-a456-426614174000\",\"role\":\"viewer\"}}' -H \"Authorization: Bearer <user_token>\" -H 'Content-Type: application/json' Response: HTTP/1.1 201 Created Content-Type: application/json Date: Wed, 03 Nov 2021 13:00:14 GMT Content-Length: 3 {}","title":"Assign Members"},{"location":"api/#unassign-members_1","text":"To unassign members from a group, you need the group ID, member IDs, role and a user_token Must-have: user_token , group_id , member_ids curl -isSX PATCH http://localhost/groups/<group_id>/members -d '{\"member_ids\":[\"987fbc97-4bed-5078-9f07-9141ba07c9f3\",\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\"]}' -H \"Authorization: Bearer <user_token>\" -H 'Content-Type: application/json' Response: HTTP/1.1 204 No Content Content-Type: application/json Date: Wed, 03 Nov 2021 13:00:05 GMT","title":"Unassign Members"},{"location":"api/#update-members_1","text":"To update members of an group, you need the group ID, member ids and a user_token Must-have: user_token , group_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/members -d '{\"group_members\":{\"id\":\"123e4567-e89b-12d3-a456-426614174000\",\"role\":\"viewer\"}}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:11:51 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Update Members"},{"location":"api/#list-members-by-group","text":"To list members by group, you need the group ID and a user_token Must-have: user_token , group_id curl -s -S -i -X GET -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/members Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 17:09:28 GMT Content-Type: application/json Content-Length: 225 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"limit\":10,\"offset\":0,\"group_members\":[{\"id\":\"5316d843-abf8-4db4-93fd-bdc8917d42ec\",\"email\":\"user@gmail.com\",\"role\":\"viewer\"},{\"id\":\"2513d843-abf8-4db4-93fd-bdc8917d42mm\",\"email\":\"user2@gmail.com\",\"role\":\"editor\"}]}","title":"List Members by Group"},{"location":"api/#profiles","text":"","title":"Profiles"},{"location":"api/#create-profile-with-external-id","text":"A profile is a set of configuration parameters that can be applied to a Thing within the same group. To create a profile with external ID, the user needs to provide a UUID v4 format unique ID, group_id , metadata, config and a user_token . The detailed configuration of the Profile Config can be found at Profile Config . Must-have: user_token , group_id curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"name\": \"<profile_name>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:26:51 GMT Content-Type: application/json Content-Length: 204 Connection: keep-alive Location: /profiles/db4b7428-e278-4fe3-b85a-d65554d6abe9 Access-Control-Expose-Headers: Location {\"profiles\":[{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"name\":\"profile_name\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]}","title":"Create Profile with external ID"},{"location":"api/#create-profiles","text":"The same as creating a profile with external ID the user can create multiple profiles at once by providing UUID v4 format unique ID in a series of profiles together with a user_token and <group_id> . Must-have: user_token , group_id and profiles curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles -d '[{\"name\": \"<profile_name_1>\"}, {\"name\": \"<profile_name_2>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:28:10 GMT Content-Type: application/json Content-Length: 352 Connection: keep-alive Access-Control-Expose-Headers: Location {\"profiles\":[{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"name\":\"profile_name_1\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\"},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"name\":\"profile_name_2\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\",\"metadata\":{\"key\":\"val\"},\"config\":{\"content-type\":\"application/json\"}}]}","title":"Create Profiles"},{"location":"api/#create-profiles-with-external-id","text":"You can create multiple profiles with external ID at once Must-have: user_token , group_id and at least 2 profiles curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx1>\",\"name\": \"<profile_name_1>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}, {\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx2>\",\"name\": \"<profile_name_2>\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:28:10 GMT Content-Type: application/json Content-Length: 398 Connection: keep-alive Access-Control-Expose-Headers: Location {\"profiles\":[{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx1>\",\"name\":\"profile_name_1\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx2>\",\"name\":\"profile_name_2\",\"group_id\":\"123e4567-e89b-12d3-a456-426614174000\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]}","title":"Create Profiles with external ID"},{"location":"api/#view-profile","text":"Get a profile entity for a logged-in user Must-have: user_token and profile_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:29:49 GMT Content-Type: application/json Content-Length: 188 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"content-type\":\"application/json\"}}","title":"View Profile"},{"location":"api/#view-profile-by-thing","text":"Get a profile by a specific thing Must-have: user_token and thing_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id>/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 11:20:10 GMT Content-Type: application/json Content-Length: 188 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"content-type\":\"application/json\"}}","title":"View Profile by Thing"},{"location":"api/#list-profiles","text":"Get all profiles that the user can access, list requests accepts limit and offset query parameters Must-have: user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:30:34 GMT Content-Type: application/json Content-Length: 493 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"profiles\":[{\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_1\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_2\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]}","title":"List Profiles"},{"location":"api/#list-profiles-by-group","text":"Get all profiles by a certain group where the user has access Must-have: user_token , <group_id> curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:30:34 GMT Content-Type: application/json Content-Length: 427 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"offset\":0,\"limit\":10,\"profiles\":[{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_1\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_2\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]}","title":"List Profiles by Group"},{"location":"api/#list-profiles-by-org","text":"Get all profiles by a certain organization Must-have: user_token , <org_id> curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/profiles Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 10:30:34 GMT Content-Type: application/json Content-Length: 493 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"profiles\":[{\"id\":\"db4b7428-e278-4fe3-b85a-d65554d6abe9\",\"group_id\":\"b9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"b8073d41-01dc-46ad-bb26-cfecc596c6c1\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_1\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}},{\"id\":\"2200527a-f590-4fe5-b9d6-892fc6f825c3\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"name\":\"profile_name_2\",\"metadata\":{\"key\":\"val\"},\"config\":{\"Content-Type\":\"application/json\"}}]}","title":"List Profiles by Org"},{"location":"api/#update-profile","text":"Update profile entity Must-have: user_token and profile_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id> -d '{\"name\": \"<profile_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:32:08 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Update Profile"},{"location":"api/#delete-profile","text":"Delete a profile entity that is not assigned to any Thing Must-have: user_token and profile_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id> Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:33:21 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Delete Profile"},{"location":"api/#things","text":"","title":"Things"},{"location":"api/#create-thing-with-external-id","text":"It is often the case that the user will want to integrate the existing solutions, e.g. an asset management system, with the Mainflux platform. To simplify the integration between the systems and avoid artificial cross-platform reference, such as special fields in Mainflux Things metadata, it is possible to set Mainflux Thing ID with an existing unique ID while create the Thing. This way, the user can set the existing ID as the Thing ID of a newly created Thing to keep reference between Thing and the asset that Thing represents. There are two limitations - the existing ID have to be in UUID V4 format, and it has to be unique in the Mainflux domain. To create a thing with an external ID, you need provide the UUID v4 format ID together with thing name, and other fields as well as a user_token , metadata, group_id and the profile ID assigned to it. Must-have: user_token , group_id , profile_id curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"profile_id\":\"<profile_id>\",\"name\":\"<thing_name>\",\"metadata\":{\"key\":\"val\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:18:37 GMT Content-Type: application/json Content-Length: 199 Connection: keep-alive Access-Control-Expose-Headers: Location {\"things\":[{\"id\":\"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxxx>\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}}]}","title":"Create Thing with external ID"},{"location":"api/#create-things","text":"You can create multiple things at once by entering a series of things structures, group_id and a user_token Must-have: user_token , group_id and things curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things -d '[{\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_1>\"}, {\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_2>\",\"metadata\":{\"key\":\"val\"}}]' Response: HTTP/1.1 201 Created Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:19:48 GMT Content-Type: application/json Content-Length: 365 Connection: keep-alive Access-Control-Expose-Headers: Location {\"things\":[{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"x9bf9e57-1685-4c89-bafb-ff5af830be8x\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\",\"metadata\":{\"key\":\"val\"}}]}","title":"Create Things"},{"location":"api/#create-things-with-external-id","text":"The same as creating a Thing with external ID the user can create multiple things at once by providing UUID v4 format unique ID in a series of things together with a user_token and group_id Must-have: user_token , group_id and things curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things -d '[{\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx1>\",\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_1>\"}, {\"id\": \"<xxxxxxxx-xxxx-xxxx-xxxxxxxxxxxxxxx2>\",\"profile_id\":\"<profile_id>\",\"name\": \"<thing_name_2>\"}]'","title":"Create Things with external ID"},{"location":"api/#view-thing","text":"You can get thing entity by entering the thing ID and user_token Must-have: user_token and thing_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id> Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:20:52 GMT Content-Type: application/json Content-Length: 185 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"c9bf9e57-1685-4c89-bafb-ff5af830be8a\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}}","title":"View Thing"},{"location":"api/#view-metadata-by-key","text":"Get thing metadata by providing the thing_key Must-have: thing_key curl -s -S -i -X GET -H \"Authorization: Thing <thing_key>\" http://localhost/metadata Response: Server: nginx/1.20.0 Date: Tue, 21 Jan 2025 15:46:10 GMT Content-Type: application/json Content-Length: 29 Connection: keep-alive Access-Control-Expose-Headers: Location {\"metadata\":{\"test\":\"data\"}}","title":"View Metadata by Key"},{"location":"api/#list-things","text":"Get all things that the user can access, list requests accepts limit and offset query parameters Must-have: user_token curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]}","title":"List Things"},{"location":"api/#list-things-by-group","text":"Get all things by a certain group Must-have: user_token , group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]}","title":"List Things by Group"},{"location":"api/#list-things-by-profile","text":"Get all things by a certain profile Must-have: user_token , profile_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/profiles/<profile_id>/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]}","title":"List Things by Profile"},{"location":"api/#list-things-by-org","text":"Get all things by a certain organization Must-have: user_token , org_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" http://localhost/orgs/<org_id>/things Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 15:21:49 GMT Content-Type: application/json Content-Length: 582 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"things\":[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name\",\"key\":\"659aa6ca-1781-4a69-9a20-689ddb235506\",\"metadata\":{\"key\":\"val\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_1\",\"key\":\"828c6985-c2d6-419e-a124-ba99147b9920\"},{\"id\":\"38aa33fe-39e5-4ee3-97ba-4227cfac63f6\",\"group_id\":\"550e8400-e29b-41d4-a716-446655440000\",\"profile_id\":\"a9bf9e57-1685-4c89-bafb-ff5af830be8b\",\"name\":\"thing_name_2\",\"key\":\"f73e7342-06c1-499a-9584-35de495aa338\"}]}","title":"List Things by Org"},{"location":"api/#update-thing","text":"Updating a thing entity Must-have: user_token and thing_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id> -d '{\"name\": \"<thing_name>\",\"profile_id\":\"<profile_id>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:23:36 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Update Thing"},{"location":"api/#update-things-metadata","text":"Updating a things metadata Must-have: user_token curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things -d '[{\"id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"metadata\":{\"new_key1\":\"new_val1\"}},{\"id\":\"4328f3e4-4c67-40b3-9491-0ab782c48d50\",\"metadata\":{\"new_key2\":\"new_val2\"}}]' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 24 Mar 2025 16:00:00 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Update Things Metadata"},{"location":"api/#delete-thing","text":"To delete a thing you need a thing_id and a user_token Must-have: user_token and thing_id curl -s -S -i -X DELETE -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/things/<thing_id> Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 15:24:44 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Delete Thing"},{"location":"api/#identify","text":"Validates thing's key and returns its ID if key is valid Must-have: thing_key curl -s -S -i -X POST -H \"Content-Type: application/json\" http://localhost/identify -d '{\"token\": \"<thing_key>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Mon, 22 Mar 2021 15:04:41 GMT Content-Type: application/json Content-Length: 46 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"d69d0098-072b-41bf-8c6e-ce4dbb12d333\"}","title":"Identify"},{"location":"api/#messages","text":"","title":"Messages"},{"location":"api/#send-messages","text":"Sends message via HTTP protocol Must-have: thing_key curl -s -S -i -X POST -H \"Content-Type: application/json\" -H \"Authorization: Thing <thing_key>\" http://localhost/http/messages -d '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09,\"bu\":\"A\",\"bver\":5,\"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' Response: HTTP/1.1 202 Accepted Server: nginx/1.16.0 Date: Wed, 10 Mar 2021 16:53:54 GMT Content-Length: 0 Connection: keep-alive","title":"Send Messages"},{"location":"api/#read-messages","text":"Reads messages from database Must-have: thing_key curl -s -S -i -H \"Authorization: Thing <thing_key>\" http://localhost:<service_port>/messages?offset=0&limit=5 Response: HTTP/1.1 200 OK Content-Type: application/json Date: Wed, 10 Mar 2021 16:54:58 GMT Content-Length: 660 {\"offset\":0,\"limit\":10,\"format\":\"messages\",\"total\":3,\"messages\":[{\"publisher\":\"33eb28c3-4ca2-45c3-b1c5-d5d049c6c24e\",\"protocol\":\"http\",\"name\":\"some-base-name:voltage\",\"unit\":\"V\",\"time\":1276020076.001,\"value\":120.1},{\"publisher\":\"33eb28c3-4ca2-45c3-b1c5-d5d049c6c24e\",\"protocol\":\"http\",\"name\":\"some-base-name:current\",\"unit\":\"A\",\"time\":1276020072.001,\"value\":1.3},{\"publisher\":\"33eb28c3-4ca2-45c3-b1c5-d5d049c6c24e\",\"protocol\":\"http\",\"name\":\"some-base-name:current\",\"unit\":\"A\",\"time\":1276020071.001,\"value\":1.2}]}","title":"Read Messages"},{"location":"api/#api-key","text":"","title":"API Key"},{"location":"api/#issue-api-key","text":"Generates a new API key. Then new API key will be uniquely identified by its ID. Duration is expressed in seconds. Must-have: user_token curl -isSX POST http://localhost/keys -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" -d '{\"type\":2, \"duration\":10000}' Response: HTTP/1.1 201 Created Server: nginx/1.20.0 Date: Sun, 19 Dec 2021 17:39:44 GMT Content-Type: application/json Content-Length: 476 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"4d62fb1e-085e-435c-a0c5-5255febfa35b\",\"value\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NDAwMzU1ODQsImp0aSI6IjRkNjJmYjFlLTA4NWUtNDM1Yy1hMGM1LTUyNTVmZWJmYTM1YiIsImlhdCI6MTYzOTkzNTU4NCwiaXNzIjoibWFpbmZsdXguYXV0aCIsInN1YiI6ImZscDFAZW1haWwuY29tIiwiaXNzdWVyX2lkIjoiYzkzY2FmYjMtYjNhNy00ZTdmLWE0NzAtMTVjMTRkOGVkMWUwIiwidHlwZSI6Mn0.RnvjhygEPPWFDEUKtfk5okzVhZzOcO0azr8gd5vby5M\",\"issued_at\":\"2021-12-19T17:39:44.175088349Z\",\"expires_at\":\"2021-12-20T21:26:24.175088349Z\"}","title":"Issue API Key"},{"location":"api/#view-api-key-details","text":"Must-have: 'user_token' and 'key_id' curl -isSX GET http://localhost/keys/<key_id> -H 'Content-Type: application/json' -H 'Authorization: Bearer <user_token>' Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Sun, 19 Dec 2021 17:43:30 GMT Content-Type: application/json Content-Length: 218 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"issuer_id\":\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"subject\":\"test@email.com\",\"type\":2,\"issued_at\":\"2021-12-19T17:42:40.884521Z\",\"expires_at\":\"2021-12-20T21:29:20.884521Z\"}","title":"View API key details"},{"location":"api/#revoke-api-key-identified-by-the-given-id","text":"Must-have: 'user_token' and 'key_id' curl -isSX DELETE http://localhost/keys/<key_id> -H 'Content-Type: application/json' -H 'Authorization: Bearer <user_token>' Response: HTTP/1.1 204 No Content Server: nginx/1.20.0 Date: Sun, 19 Dec 2021 17:47:11 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Revoke API key identified by the given ID"},{"location":"api/#webhooks","text":"","title":"Webhooks"},{"location":"api/#create-webhooks","text":"To forward a message to another platform, you need to create a Webhook with the necessary data such as the name of the Webhook, thing_id which refers to the Thing for which the Webhook is being created, the url to which the message will be forwarded and HTTP headers specific for the certain webhook. You can create multiple Webhooks at once by entering a series of Webhooks structures, thing_id and a user_token . Must-have: user_token , thing_id , name and url curl -s -S -i -X POST -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/webhooks -d '{\"webhooks: [{\"name\":\"webhook_name\",\"url\":\"https://webhook.com\",\"headers\":{\"Content-Type\":\"application/json\"}}]}' Response: HTTP/1.1 201 Created Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 11:47:12 GMT Content-Type: application/json Content-Length: 191 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"name\":\"webhook_name\",\"url\":\"https://webhook.com\",\"headers\":{\"Content-Type\":\"application/json\"}}","title":"Create Webhooks"},{"location":"api/#list-webhooks-by-group","text":"You can get all Webhooks for certain Group by entering user_token and group_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/webhooks Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 11:44:57 GMT Content-Type: application/json Content-Length: 488 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":3,\"offset\":0,\"limit\":10,\"webhooks\":[{\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"url\":\"https://api.test.com/\",\"headers\":{\"Content-Type\":\"application/json\"}},{\"id\":\"1234f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"12140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test2\",\"url\":\"https://api.test2.com/\",\"headers\":{}}]}","title":"List Webhooks by Group"},{"location":"api/#list-webhooks-by-thing","text":"You can get all Webhooks for certain Thing by entering user_token and thing_id . Must-have: user_token and thing_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/things/<thing_id>/webhooks Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Mon, 24 Mar 2025 11:44:57 GMT Content-Type: application/json Content-Length: 250 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":1,\"offset\":0,\"limit\":10,\"webhooks\":[{\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"url\":\"https://api.test.com/\",\"headers\":{\"Content-Type\":\"application/json\"}}]}","title":"List Webhooks by Thing"},{"location":"api/#view-webhook","text":"View details of a certain Webhook by entering user_token and webhook_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/webhooks/<webhook_id> Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 11:44:57 GMT Content-Type: application/json Content-Length: 185 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"f630f594-d967-4c54-85ef-af58efe8e8ed\",\"thing_id\":\"64140f0b-6448-41cf-967e-1bbcc703c332\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"url\":\"https://api.test.com/\",\"headers\":{\"Content-Type\":\"application/json\"}}","title":"View Webhook"},{"location":"api/#update-webhook","text":"Update data of webhook with provided ID and user_token Must-have: user_token and webhook_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/webhooks/<webhook_id> -d '{\"name\": \"<webhook_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 11:54:52 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Update Webhook"},{"location":"api/#delete-webhooks","text":"Delete webhooks by given IDs Must-have: user_token , webhook_ids curl -s -S -i -X PATCH -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/webhooks -d '{\"webhook_ids\":[\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"2513d843-abf8-4db4-93fd-bdc8917d42mm\"]}' Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 11:55:10 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Delete Webhooks"},{"location":"api/#notifiers","text":"","title":"Notifiers"},{"location":"api/#create-notifiers","text":"In order to send email notifications to certain contacts when a message arrives, you need to create a Notifier with the necessary data, such as the Notifier's name , group_id , which refers to the Group for which the Notifier is being created, the contacts to which the notifications will be sent and optional metadata . You can create multiple Notifiers at once by entering a series of Notifiers structures, group_id and a user_token . Must-have: user_token , group_id , name and contacts curl -s -S -i -X POST -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/notifiers -d '{\"notifiers: [{\"name\":\"notifier_name\",\"contacts\": [\"email1@example.com\", \"email2@example.com\"],\"metadata\":{}}]}' Response: HTTP/1.1 201 Created Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 12:17:12 GMT Content-Type: application/json Content-Length: 190 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"a630f594-d967-4c54-85ef-af58efe8e8eb\",\"group_id\":\"c93cafb3-b3a7-4e7f-a470-15c14d8ed1e0\",\"name\":\"notifier_name\",\"contacts\": [\"email1@example.com\", \"email2@example.com\"],\"metadata\":{}} Note: The logged-in user who creates a Notifier for a certain Group must have the role of \"editor\" of that Group.","title":"Create Notifiers"},{"location":"api/#list-notifiers-by-group","text":"You can get all Notifiers for certain Group by entering user_token and group_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/groups/<group_id>/notifiers Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 12:19:57 GMT Content-Type: application/json Content-Length: 337 Connection: keep-alive Access-Control-Expose-Headers: Location {\"total\":2,\"offset\":0,\"limit\":10,\"notifiers\":[{\"id\":\"a630f594-d967-4c54-85ef-af58efe8e8eb\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"contacts\": [\"test1@example.com\"]},{\"id\":\"2234f594-d967-4c54-85ef-af58efe8e8ed\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test2\",\"contacts\": [\"test2@example.com\"]}]}","title":"List Notifiers by Group"},{"location":"api/#view-notifier","text":"View details of a certain Notifier by entering user_token and notifier_id . Must-have: user_token and group_id curl -s -S -i -X GET -H \"Authorization: Bearer <user_token>\" -H \"Content-Type: application/json\" http://localhost/notifiers/<notifier_id> Response: HTTP/1.1 200 OK Server: nginx/1.20.0 Date: Thu, 11 Apr 2024 12:24:57 GMT Content-Type: application/json Content-Length: 145 Connection: keep-alive Access-Control-Expose-Headers: Location {\"id\":\"a630f594-d967-4c54-85ef-af58efe8e8eb\",\"group_id\":\"50e6b371-60ff-45cf-bb52-8200e7cde536\",\"name\":\"Test\",\"contacts\": [\"test1@example.com\"]}}","title":"View Notifier"},{"location":"api/#update-notifier","text":"Update data of notifier with provided ID and user_token Must-have: user_token and notifier_id curl -s -S -i -X PUT -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/notifiers/<notifier_id> -d '{\"name\": \"<new_notifier_name>\"}' Response: HTTP/1.1 200 OK Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 12:34:52 GMT Content-Type: application/json Content-Length: 0 Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Update Notifier"},{"location":"api/#delete-notifiers","text":"Delete notifiers by given IDs Must-have: user_token , group_id , notifier_ids curl -s -S -i -X PATCH -H \"Content-Type: application/json\" -H \"Authorization: Bearer <user_token>\" http://localhost/groups/<group_id>/notifiers -d '{\"notifier_ids\":[\"a93cafb3-b3a7-4e7f-a470-15c14d8ed1e1\",\"b513d843-abf8-4db4-93fd-bdc8917d42m2\"]}' Response: HTTP/1.1 204 No Content Server: nginx/1.16.0 Date: Thu, 11 Apr 2024 12:55:10 GMT Content-Type: application/json Connection: keep-alive Access-Control-Expose-Headers: Location","title":"Delete Notifiers"},{"location":"architecture/","text":"Architecture # Components # Mainflux IoT platform is comprised of the following services: Service Description auth Manages platform's orgs and auth concerns users Manages platform's users and auth concerns things Manages platform's things, profiles, groups and group members http-adapter Provides an HTTP interface for sending messages mqtt-adapter Provides an MQTT and MQTT over WS interface for sending messages coap-adapter Provides a CoAP interface for sending messages mainflux-cli Command line interface Domain Model # The platform is built around 5 main entities: users , organizations , groups , profiles and things . User represents the real (human) user of the system. It is represented via its e-mail and password, which he uses as platform access credentials in order to obtain an access token. Once logged into the system, user can manage his resources (i.e. groups, things and profiles) in CRUD fashion and define access control. Org represents the highest entity in the system hierarchy consisting of its members and groups . It unites all the elements into a whole. Group within an organization represents a set of Things, Profiles, Notifiers, Webhooks, Downlinks. Access to these entities requires appropriate rights, which are obtained when assigning a user to a group. Profile determines message topics that can be consumed by all things to which it is assigned. Thing represents devices (or applications) connected to Mainflux that uses the platform for message exchange with other \"things\". Messaging # Mainflux uses NATS as its messaging backbone, due to its lightweight and performant nature. You can treat its subjects as physical representation of Mainflux channels, where subject name is constructed using channel unique identifier. In general, there is no constrained put on content that is being exchanged through channels. However, in order to be post-processed and normalized, messages should be formatted using SenML . Edge # Mainflux platform can be run on the edge as well. Deploying Mainflux on a gateway makes it able to collect, store and analyze data, organize and authenticate devices. To connect Mainflux instances running on a gateway with Mainflux in a cloud we can use two gateway services developed for that purpose: Agent Export Unified IoT Platform # Running Mainflux on gateway moves computation from cloud towards the edge thus decentralizing IoT system. Since we can deploy same Mainflux code on gateway and in the cloud there are many benefits but the biggest one is easy deployment and adoption - once the engineers understand how to deploy and maintain the platform, they will have the same known work across the whole edge-fog-cloud continuum. Same set of tools can be used, same patches and bug fixes can be applied. The whole system is much easier to reason about, and the maintenance is much easier and less costly.","title":"Architecture"},{"location":"architecture/#architecture","text":"","title":"Architecture"},{"location":"architecture/#components","text":"Mainflux IoT platform is comprised of the following services: Service Description auth Manages platform's orgs and auth concerns users Manages platform's users and auth concerns things Manages platform's things, profiles, groups and group members http-adapter Provides an HTTP interface for sending messages mqtt-adapter Provides an MQTT and MQTT over WS interface for sending messages coap-adapter Provides a CoAP interface for sending messages mainflux-cli Command line interface","title":"Components"},{"location":"architecture/#domain-model","text":"The platform is built around 5 main entities: users , organizations , groups , profiles and things . User represents the real (human) user of the system. It is represented via its e-mail and password, which he uses as platform access credentials in order to obtain an access token. Once logged into the system, user can manage his resources (i.e. groups, things and profiles) in CRUD fashion and define access control. Org represents the highest entity in the system hierarchy consisting of its members and groups . It unites all the elements into a whole. Group within an organization represents a set of Things, Profiles, Notifiers, Webhooks, Downlinks. Access to these entities requires appropriate rights, which are obtained when assigning a user to a group. Profile determines message topics that can be consumed by all things to which it is assigned. Thing represents devices (or applications) connected to Mainflux that uses the platform for message exchange with other \"things\".","title":"Domain Model"},{"location":"architecture/#messaging","text":"Mainflux uses NATS as its messaging backbone, due to its lightweight and performant nature. You can treat its subjects as physical representation of Mainflux channels, where subject name is constructed using channel unique identifier. In general, there is no constrained put on content that is being exchanged through channels. However, in order to be post-processed and normalized, messages should be formatted using SenML .","title":"Messaging"},{"location":"architecture/#edge","text":"Mainflux platform can be run on the edge as well. Deploying Mainflux on a gateway makes it able to collect, store and analyze data, organize and authenticate devices. To connect Mainflux instances running on a gateway with Mainflux in a cloud we can use two gateway services developed for that purpose: Agent Export","title":"Edge"},{"location":"architecture/#unified-iot-platform","text":"Running Mainflux on gateway moves computation from cloud towards the edge thus decentralizing IoT system. Since we can deploy same Mainflux code on gateway and in the cloud there are many benefits but the biggest one is easy deployment and adoption - once the engineers understand how to deploy and maintain the platform, they will have the same known work across the whole edge-fog-cloud continuum. Same set of tools can be used, same patches and bug fixes can be applied. The whole system is much easier to reason about, and the maintenance is much easier and less costly.","title":"Unified IoT Platform"},{"location":"authentication/","text":"Authentication # User authentication # For user authentication Mainflux uses Authentication keys. There are three types of authentication keys: User key - keys issued to the user upon login request API key - keys issued upon the user request Recovery key - password recovery key Authentication keys are represented and distributed by the corresponding JWT . User keys are issued when user logs in. Each user request (other than registration and login) contains user key that is used to authenticate the user. API keys are similar to the User keys. The main difference is that API keys have configurable expiration time. If no time is set, the key will never expire. API keys are the only key type that can be revoked . This also means that, despite being used as a JWT, it requires a query to the database to validate the API key. The user with API key can perform all the same actions as the user with login key (can act on behalf of the user for Thing, Profile, or user profile management), except issuing new API keys . Recovery key is the password recovery key. It's short-lived token used for password recovery process. The following actions are supported: create (all key types) verify (all key types) obtain (API keys only; secret is never obtained) revoke (API keys only) Authentication with Mainflux keys # By default, Mainflux uses Mainflux Thing keys for authentication. The Thing key is a secret key that's generated at the Thing creation. In order to authenticate, the Thing needs to send its key with the message. The way the key is passed depends on the protocol used to send a message and differs from adapter to adapter. For more details on how this key is passed around, please check out messaging section . This is the default Mainflux authentication mechanism and this method is used if the composition is started using the following command: docker-compose -f docker/docker-compose.yml up Mutual TLS Authentication with X.509 Certificates # In most of the cases, HTTPS, MQTTS or secure CoAP are secure enough. However, sometimes you might need an even more secure connection. Mainflux supports mutual TLS authentication ( mTLS ) based on X.509 certificates . By default, the TLS protocol only proves the identity of the server to the client using the X.509 certificate and the authentication of the client to the server is left to the application layer. TLS also offers client-to-server authentication using client-side X.509 authentication. This is called two-way or mutual authentication. Mainflux currently supports mTLS over HTTP, MQTT and MQTT over WS protocols. In order to run Docker composition with mTLS turned on, you can execute the following command from the project root: AUTH=x509 docker-compose -f docker/docker-compose.yml up -d Mutual authentication includes client-side certificates. Certificates can be generated using the simple script provided here . In order to create a valid certificate, you need to create Mainflux thing. After that, you need to fetch created thing key. Thing key will be used to create x.509 certificate for the corresponding thing. To create a certificate, execute the following commands: cd docker/ssl make ca CN=<common_name> O=<organization> OU=<organizational_unit> emailAddress=<email_address> make server_cert CN=<common_name> O=<organization> OU=<organizational_unit> emailAddress=<email_address> make thing_cert THING_KEY=<thing_key> CRT_FILE_NAME=<cert_name> O=<organization> OU=<organizational_unit> emailAddress=<email_address> These commands use OpenSSL tool, so please make sure that you have it installed and set up before running these commands. The default values for Makefile variables are CRT_LOCATION = certs THING_KEY = d7cc2964-a48b-4a6e-871a-08da28e7883d O = Mainflux OU = mainflux EA = info@mainflux.com CN = localhost CRT_FILE_NAME = thing Normally, in order to get things running, you will need to specify only THING_KEY . The other variables are not mandatory and the termination should work with the default values. Command make ca will generate a self-signed certificate that will later be used as a CA to sign other generated certificates. CA will expire in 3 years. Command make server_cert will generate and sign (with previously created CA) server cert, which will expire after 1000 days. This cert is used as a Mainflux server-side certificate in usual TLS flow to establish HTTPS or MQTTS connection. Command make thing_cert will finally generate and sign a client-side certificate and private key for the thing. In this example <thing_key> represents key of the thing and <cert_name> represents the name of the certificate and key file which will be saved in docker/ssl/certs directory. Generated Certificate will expire after 2 years. The key must be stored in the x.509 certificate CN field. This script is created for testing purposes and is not meant to be used in production. We strongly recommend avoiding self-signed certificates and using a certificate management tool such as Vault for the production. Once you have created CA and server-side cert, you can spin the composition using: AUTH=x509 docker-compose -f docker/docker-compose.yml up -d Then, you can create user and provision things and profiles within the same group. Now, in order to send a message from the specific thing (which has an assigned profile), you need to generate corresponding client certificate using the aforementioned commands. To publish a message, thing should send following request: HTTPS # curl -s -S -i --cacert docker/ssl/certs/ca.crt --cert docker/ssl/certs/<thing_cert_name>.crt --key docker/ssl/certs/<thing_cert_key>.key -X POST -H \"Content-Type: application/senml+json\" https://localhost/http/messages -d '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' MQTTS # Publish # mosquitto_pub -u <thing_id> -P <thing_key> -t /messages -h localhost -p 8883 --cafile docker/ssl/certs/ca.crt --cert docker/ssl/certs/<thing_cert_name>.crt --key docker/ssl/certs/<thing_cert_key>.key -m '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' Subscribe # mosquitto_sub -u <thing_id> -P <thing_key> --cafile docker/ssl/certs/ca.crt --cert docker/ssl/certs/<thing_cert_name>.crt --key docker/ssl/certs/<thing_cert_key>.key -t /messages -h localhost -p 8883","title":"Authentication"},{"location":"authentication/#authentication","text":"","title":"Authentication"},{"location":"authentication/#user-authentication","text":"For user authentication Mainflux uses Authentication keys. There are three types of authentication keys: User key - keys issued to the user upon login request API key - keys issued upon the user request Recovery key - password recovery key Authentication keys are represented and distributed by the corresponding JWT . User keys are issued when user logs in. Each user request (other than registration and login) contains user key that is used to authenticate the user. API keys are similar to the User keys. The main difference is that API keys have configurable expiration time. If no time is set, the key will never expire. API keys are the only key type that can be revoked . This also means that, despite being used as a JWT, it requires a query to the database to validate the API key. The user with API key can perform all the same actions as the user with login key (can act on behalf of the user for Thing, Profile, or user profile management), except issuing new API keys . Recovery key is the password recovery key. It's short-lived token used for password recovery process. The following actions are supported: create (all key types) verify (all key types) obtain (API keys only; secret is never obtained) revoke (API keys only)","title":"User authentication"},{"location":"authentication/#authentication-with-mainflux-keys","text":"By default, Mainflux uses Mainflux Thing keys for authentication. The Thing key is a secret key that's generated at the Thing creation. In order to authenticate, the Thing needs to send its key with the message. The way the key is passed depends on the protocol used to send a message and differs from adapter to adapter. For more details on how this key is passed around, please check out messaging section . This is the default Mainflux authentication mechanism and this method is used if the composition is started using the following command: docker-compose -f docker/docker-compose.yml up","title":"Authentication with Mainflux keys"},{"location":"authentication/#mutual-tls-authentication-with-x509-certificates","text":"In most of the cases, HTTPS, MQTTS or secure CoAP are secure enough. However, sometimes you might need an even more secure connection. Mainflux supports mutual TLS authentication ( mTLS ) based on X.509 certificates . By default, the TLS protocol only proves the identity of the server to the client using the X.509 certificate and the authentication of the client to the server is left to the application layer. TLS also offers client-to-server authentication using client-side X.509 authentication. This is called two-way or mutual authentication. Mainflux currently supports mTLS over HTTP, MQTT and MQTT over WS protocols. In order to run Docker composition with mTLS turned on, you can execute the following command from the project root: AUTH=x509 docker-compose -f docker/docker-compose.yml up -d Mutual authentication includes client-side certificates. Certificates can be generated using the simple script provided here . In order to create a valid certificate, you need to create Mainflux thing. After that, you need to fetch created thing key. Thing key will be used to create x.509 certificate for the corresponding thing. To create a certificate, execute the following commands: cd docker/ssl make ca CN=<common_name> O=<organization> OU=<organizational_unit> emailAddress=<email_address> make server_cert CN=<common_name> O=<organization> OU=<organizational_unit> emailAddress=<email_address> make thing_cert THING_KEY=<thing_key> CRT_FILE_NAME=<cert_name> O=<organization> OU=<organizational_unit> emailAddress=<email_address> These commands use OpenSSL tool, so please make sure that you have it installed and set up before running these commands. The default values for Makefile variables are CRT_LOCATION = certs THING_KEY = d7cc2964-a48b-4a6e-871a-08da28e7883d O = Mainflux OU = mainflux EA = info@mainflux.com CN = localhost CRT_FILE_NAME = thing Normally, in order to get things running, you will need to specify only THING_KEY . The other variables are not mandatory and the termination should work with the default values. Command make ca will generate a self-signed certificate that will later be used as a CA to sign other generated certificates. CA will expire in 3 years. Command make server_cert will generate and sign (with previously created CA) server cert, which will expire after 1000 days. This cert is used as a Mainflux server-side certificate in usual TLS flow to establish HTTPS or MQTTS connection. Command make thing_cert will finally generate and sign a client-side certificate and private key for the thing. In this example <thing_key> represents key of the thing and <cert_name> represents the name of the certificate and key file which will be saved in docker/ssl/certs directory. Generated Certificate will expire after 2 years. The key must be stored in the x.509 certificate CN field. This script is created for testing purposes and is not meant to be used in production. We strongly recommend avoiding self-signed certificates and using a certificate management tool such as Vault for the production. Once you have created CA and server-side cert, you can spin the composition using: AUTH=x509 docker-compose -f docker/docker-compose.yml up -d Then, you can create user and provision things and profiles within the same group. Now, in order to send a message from the specific thing (which has an assigned profile), you need to generate corresponding client certificate using the aforementioned commands. To publish a message, thing should send following request:","title":"Mutual TLS Authentication with X.509 Certificates"},{"location":"authentication/#https","text":"curl -s -S -i --cacert docker/ssl/certs/ca.crt --cert docker/ssl/certs/<thing_cert_name>.crt --key docker/ssl/certs/<thing_cert_key>.key -X POST -H \"Content-Type: application/senml+json\" https://localhost/http/messages -d '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]'","title":"HTTPS"},{"location":"authentication/#mqtts","text":"","title":"MQTTS"},{"location":"authentication/#publish","text":"mosquitto_pub -u <thing_id> -P <thing_key> -t /messages -h localhost -p 8883 --cafile docker/ssl/certs/ca.crt --cert docker/ssl/certs/<thing_cert_name>.crt --key docker/ssl/certs/<thing_cert_key>.key -m '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]'","title":"Publish"},{"location":"authentication/#subscribe","text":"mosquitto_sub -u <thing_id> -P <thing_key> --cafile docker/ssl/certs/ca.crt --cert docker/ssl/certs/<thing_cert_name>.crt --key docker/ssl/certs/<thing_cert_key>.key -t /messages -h localhost -p 8883","title":"Subscribe"},{"location":"authorization/","text":"Authorization # At the beginning, it is necessary to ensure access to the platform for users. User registration in the system is performed exclusively by the platform administrator or Root Admin . After the user is registered by the Root Admin , in order to be able to manage entities within the system, it is necessary to have certain rights. Mainflux uses roles to control permissions for entities at two levels: at the Organization level and at the Group level. More information about creating a user can be found at Users API . Roles # Roles determine the permissions a User has within an Organization or Group. Below are the predefined roles in the system: Viewer # Can only view entities (read-only access). Applies to both Organization and Group levels. Editor # Can create, delete, and view entities within the Organization or Group (more details are in the table below). Admin # Has all the permissions of an editor. Can assign and unassign Members to the Organization or Group. Owner # Has all the permissions of an admin. Has access to all entities within the Organization or Group they own. Root Admin # Has all permissions across all Organizations and Groups (and entities within them). Acts as the primary administrator for the entire platform. Although these roles are the same for an Organization and a Group, they operate completely separately at those levels , which means that one User can have different roles in an Organization and a Group within that Organization. Org Members # When a logged-in User creates an Organization, they become the Owner of that Organization. Within it, they can add other registered users by assigning them appropriate roles defined in the table above. Unlike an Admin of the Organization, an Owner has full rights over the entities within their Organization, meaning they can manage Groups and entities in Groups without an explicit Group membership. For a simpler understanding of access control in an Org, the table below provides a clear overview: Operation Viewer Editor Admin Owner Root Admin View Org \u2705 \u2705 \u2705 \u2705 \u2705 Update Org \u274c \u274c \u2705 \u2705 \u2705 Delete Org \u274c \u274c \u274c \u2705 \u2705 Assign/Unassign Members \u274c \u274c \u2705 \u2705 \u2705 Create Groups \u274c \u2705 \u2705 \u2705 \u2705 The operation 'Create Org' is omitted from the table because every registered (and logged-in) user has the right to do so. An example of assigning Members to an Organization can be found at Org Members API . Examples of unauthorized access # Let's imagine that we have one Organization and four Members of that Organization with different roles: org_id member_id role 550e8400-e29b-41d4-a716-446655440000 3f3f9cc2-1a84-40cd-a7fb-02d9c5e1e5c8 viewer 550e8400-e29b-41d4-a716-446655440000 6b9e77a1-22f8-4e72-b2f3-122ad8b37f48 editor 550e8400-e29b-41d4-a716-446655440000 c9b8f7d5-8143-47b4-9d72-f83d3f73834e admin 550e8400-e29b-41d4-a716-446655440000 f1c6e7b3-4b29-496a-810b-bf7397dc3842 owner If a Viewer tries to create a Group within that Organization, they will receive a message indicating that the creation has failed: {\"error\": \"failed to perform authorization over the entity\"} In the second case, if a Viewer or Editor tries to invite new users to the Organization, they will also get the above error message. Next case, if an Admin attempts to access entities within that Organization's Groups (of which they are not a Member), access will also be denied with an authorization failure message. The same error message will be received if the Owner , or any other Organization Member who is not a Root Admin , tries to access an Organization in which they are not Members. Group Members # In order to enable the correct management of the entities within the Group, the rights that the members have over these entities are checked. Rights over entities are defined based on the role in the Group in which they belong. As previously emphasized, roles in an Organization and roles in a Group are independent and don't affect each other, which means that if a User is a Viewer in an Organization and a Group Admin adds them to the Group as an Editor , they will have higher rights in the Group than the rights they have in the Organization. By creating a Group, the User becomes its Owner and has the rights defined in the table. For a simpler understanding of access control in a Group, the table below provides a clear overview: Operation Viewer Editor Admin Owner Root Admin View Group \u2705 \u2705 \u2705 \u2705 \u2705 Update Group \u274c \u274c \u2705 \u2705 \u2705 Delete Group \u274c \u274c \u274c \u2705 \u2705 Assign/Unassign Members \u274c \u274c \u2705 \u2705 \u2705 Create Group Entities \u274c \u2705 \u2705 \u2705 \u2705 View Group Entities \u2705 \u2705 \u2705 \u2705 \u2705 Update Group Entities \u274c \u2705 \u2705 \u2705 \u2705 Delete Group Entities \u274c \u2705 \u2705 \u2705 \u2705 The 'Create Group' operation is omitted from the table because the rights are defined in the Org table, where it can be clearly seen that everyone except the Organization Viewer can create a Group. If we keep the data from the previous table and expand it with new data by creating Groups within the Organization and assigning Group roles to the existing members of the Organization, the additional table would look like this: org_id group_id member_id role 550e8400-e29b-41d4-a716-446655440000 9f8e7a61-d34e-4a7a-9836-df8c3f54d3a1 3f3f9cc2-1a84-40cd-a7fb-02d9c5e1e5c8 editor 550e8400-e29b-41d4-a716-446655440000 15ee88e2-3632-41fb-acfa-2625645a2b8d 6b9e77a1-22f8-4e72-b2f3-122ad8b37f48 viewer 550e8400-e29b-41d4-a716-446655440000 565ddcfb-bf64-4e6b-80ac-371516bd0e01 c9b8f7d5-8143-47b4-9d72-f83d3f73834e admin We can notice that the User who has the role of Viewer in the Organization now has the role of Editor in the group with ID 9f8e7a61-d34e-4a7a-9836-df8c3f54d3a1 . This means that the User now has all the rights provided by that role. On the other hand, the User with ID 6b9e77a1-22f8-4e72-b2f3-122ad8b37f48 who is an Organization Editor now has the Group's Viewer role. Therefore, that Member has no rights in the Group other than viewing. Since the Admin of the Organization is also the Admin of the Group with ID 565ddcfb-bf64-4e6b-80ac-371516bd0e01 , it means that they have the same rights. Based on the above examples of unauthorized access within the Organization, the same rules are applied within the Group based on the roles of the Members. In addition to the basic access rights that apply to Members, note the case of Thing creation. When creating a Thing, it needs to be assigned a specific Profile by specifying its ID. The Profile being assigned and the Thing must belong to the same Group. An example of assigning Members to a Group can be found at Group Members API .","title":"Authorization"},{"location":"authorization/#authorization","text":"At the beginning, it is necessary to ensure access to the platform for users. User registration in the system is performed exclusively by the platform administrator or Root Admin . After the user is registered by the Root Admin , in order to be able to manage entities within the system, it is necessary to have certain rights. Mainflux uses roles to control permissions for entities at two levels: at the Organization level and at the Group level. More information about creating a user can be found at Users API .","title":"Authorization"},{"location":"authorization/#roles","text":"Roles determine the permissions a User has within an Organization or Group. Below are the predefined roles in the system:","title":"Roles"},{"location":"authorization/#viewer","text":"Can only view entities (read-only access). Applies to both Organization and Group levels.","title":"Viewer"},{"location":"authorization/#editor","text":"Can create, delete, and view entities within the Organization or Group (more details are in the table below).","title":"Editor"},{"location":"authorization/#admin","text":"Has all the permissions of an editor. Can assign and unassign Members to the Organization or Group.","title":"Admin"},{"location":"authorization/#owner","text":"Has all the permissions of an admin. Has access to all entities within the Organization or Group they own.","title":"Owner"},{"location":"authorization/#root-admin","text":"Has all permissions across all Organizations and Groups (and entities within them). Acts as the primary administrator for the entire platform. Although these roles are the same for an Organization and a Group, they operate completely separately at those levels , which means that one User can have different roles in an Organization and a Group within that Organization.","title":"Root Admin"},{"location":"authorization/#org-members","text":"When a logged-in User creates an Organization, they become the Owner of that Organization. Within it, they can add other registered users by assigning them appropriate roles defined in the table above. Unlike an Admin of the Organization, an Owner has full rights over the entities within their Organization, meaning they can manage Groups and entities in Groups without an explicit Group membership. For a simpler understanding of access control in an Org, the table below provides a clear overview: Operation Viewer Editor Admin Owner Root Admin View Org \u2705 \u2705 \u2705 \u2705 \u2705 Update Org \u274c \u274c \u2705 \u2705 \u2705 Delete Org \u274c \u274c \u274c \u2705 \u2705 Assign/Unassign Members \u274c \u274c \u2705 \u2705 \u2705 Create Groups \u274c \u2705 \u2705 \u2705 \u2705 The operation 'Create Org' is omitted from the table because every registered (and logged-in) user has the right to do so. An example of assigning Members to an Organization can be found at Org Members API .","title":"Org Members"},{"location":"authorization/#examples-of-unauthorized-access","text":"Let's imagine that we have one Organization and four Members of that Organization with different roles: org_id member_id role 550e8400-e29b-41d4-a716-446655440000 3f3f9cc2-1a84-40cd-a7fb-02d9c5e1e5c8 viewer 550e8400-e29b-41d4-a716-446655440000 6b9e77a1-22f8-4e72-b2f3-122ad8b37f48 editor 550e8400-e29b-41d4-a716-446655440000 c9b8f7d5-8143-47b4-9d72-f83d3f73834e admin 550e8400-e29b-41d4-a716-446655440000 f1c6e7b3-4b29-496a-810b-bf7397dc3842 owner If a Viewer tries to create a Group within that Organization, they will receive a message indicating that the creation has failed: {\"error\": \"failed to perform authorization over the entity\"} In the second case, if a Viewer or Editor tries to invite new users to the Organization, they will also get the above error message. Next case, if an Admin attempts to access entities within that Organization's Groups (of which they are not a Member), access will also be denied with an authorization failure message. The same error message will be received if the Owner , or any other Organization Member who is not a Root Admin , tries to access an Organization in which they are not Members.","title":"Examples of unauthorized access"},{"location":"authorization/#group-members","text":"In order to enable the correct management of the entities within the Group, the rights that the members have over these entities are checked. Rights over entities are defined based on the role in the Group in which they belong. As previously emphasized, roles in an Organization and roles in a Group are independent and don't affect each other, which means that if a User is a Viewer in an Organization and a Group Admin adds them to the Group as an Editor , they will have higher rights in the Group than the rights they have in the Organization. By creating a Group, the User becomes its Owner and has the rights defined in the table. For a simpler understanding of access control in a Group, the table below provides a clear overview: Operation Viewer Editor Admin Owner Root Admin View Group \u2705 \u2705 \u2705 \u2705 \u2705 Update Group \u274c \u274c \u2705 \u2705 \u2705 Delete Group \u274c \u274c \u274c \u2705 \u2705 Assign/Unassign Members \u274c \u274c \u2705 \u2705 \u2705 Create Group Entities \u274c \u2705 \u2705 \u2705 \u2705 View Group Entities \u2705 \u2705 \u2705 \u2705 \u2705 Update Group Entities \u274c \u2705 \u2705 \u2705 \u2705 Delete Group Entities \u274c \u2705 \u2705 \u2705 \u2705 The 'Create Group' operation is omitted from the table because the rights are defined in the Org table, where it can be clearly seen that everyone except the Organization Viewer can create a Group. If we keep the data from the previous table and expand it with new data by creating Groups within the Organization and assigning Group roles to the existing members of the Organization, the additional table would look like this: org_id group_id member_id role 550e8400-e29b-41d4-a716-446655440000 9f8e7a61-d34e-4a7a-9836-df8c3f54d3a1 3f3f9cc2-1a84-40cd-a7fb-02d9c5e1e5c8 editor 550e8400-e29b-41d4-a716-446655440000 15ee88e2-3632-41fb-acfa-2625645a2b8d 6b9e77a1-22f8-4e72-b2f3-122ad8b37f48 viewer 550e8400-e29b-41d4-a716-446655440000 565ddcfb-bf64-4e6b-80ac-371516bd0e01 c9b8f7d5-8143-47b4-9d72-f83d3f73834e admin We can notice that the User who has the role of Viewer in the Organization now has the role of Editor in the group with ID 9f8e7a61-d34e-4a7a-9836-df8c3f54d3a1 . This means that the User now has all the rights provided by that role. On the other hand, the User with ID 6b9e77a1-22f8-4e72-b2f3-122ad8b37f48 who is an Organization Editor now has the Group's Viewer role. Therefore, that Member has no rights in the Group other than viewing. Since the Admin of the Organization is also the Admin of the Group with ID 565ddcfb-bf64-4e6b-80ac-371516bd0e01 , it means that they have the same rights. Based on the above examples of unauthorized access within the Organization, the same rules are applied within the Group based on the roles of the Members. In addition to the basic access rights that apply to Members, note the case of Thing creation. When creating a Thing, it needs to be assigned a specific Profile by specifying its ID. The Profile being assigned and the Thing must belong to the same Group. An example of assigning Members to a Group can be found at Group Members API .","title":"Group Members"},{"location":"benchmark/","text":"Test spec # Tools # MZBench vmq_mzbench mzb_api_ec2_plugin Setting up MZBench # MZbench is open-source tool for that can generate large traffic and measure performance of the application. MZBench is distributed, cloud-aware benchmarking tool that can seamlessly scale to millions of requests. It's originally developed by satori-com but we will use mzbench fork because it can run with newest Erlang releases and the original MzBench repository is not maintained anymore. We will describe installing MZBench server on Ubuntu 18.04 (this can be on your PC or some external cloud server, like droplet on Digital Ocean) Install latest OTP/Erlang (it's version 22.3 for me) sudo apt update sudo apt install erlang For running this tool you will also need libz-dev package: sudo apt-get update sudo apt-get install libz-dev and pip: sudo apt install python-pip Clone mzbench tool and install the requirements: git clone https://github.com/mzbench/mzbench cd mzbench sudo pip install -r requirements.txt This should be enough for installing MZBench, and you can now start MZBench server with this CLI command: ./bin/mzbench start_server The MZBench CLI lets you control the server and benchmarks from the command line. Another way of using MZBench is over Dashboard . After starting server you should check dashboard on http://localhost:4800 . Note that if you are installing MZBench on external server (i.e. Digital Ocean droplet), that you'll be able to reach MZBench dashboard on your server's IP address:4800, if you previously: - change default value for network_interface from 127.0.0.1 to 0.0.0.0 in configuration file. Default configuration file location is ~/.config/mzbench/server.config , create it from sample configuration file ~/.config/mzbench/server.config.example - open port 4800 with ufw allow 4800 MZBench can run your test scenarios on many nodes, simultaneously. For now, you are able to run tests locally, so your nodes will be virtual nodes on machine where MZBench server is installed (your PC or DO droplet). You can try one of our MQTT scenarios that uses vmq_mzbench worker. Copy-paste scenario in MZBench dashboard, click button Environmental variables -> Add from script and add appropriate values. Because it's running locally, you should try with smaller values, for example for fan-in scenario use 100 publishers on 2 nodes. Try this before moving forward in setting up Amazon EC2 plugin. Setting up Amazon EC2 plugin # For larger-scale tests we will set up MZBench to run each node as one of Amazon EC2 instance with built-in plugin mzb_api_ec2_plugin . This is basic architecture when running MZBench: Every node that runs your scenarios will be one of Amazon EC2 instance; plus one more additional node \u2014 the director node. The director doesn't run scenarios, it collects the metrics from the other nodes and runs post and pre hooks . So, if you want to run jobs on 10 nodes, actually 11 EC2 instances will be created. All instances will be automatically terminated when the test finishes. We will use one of ready-to-use Amazon Machine Images (AMI) with all necessary dependencies. We will choose AMI with OTP 22, because that is the version we have on MZBench server. So, we will search for MZBench-erl22 AMI and find one with id ami-03a169923be706764 available in us-west-1b zone. If you have chosen this AMI, everything you do from now must be in us-west-1 zone. We must have IAM user with AmazonEC2FullAccess and IAMFullAccess permissions policies, and his access_key_id and secret_access_key goes to configuration file. In EC2 dashboard, you must create new security group MZbench_cluster where you will add inbound rules to open ssh and TCP ports 4801-4804. Also, in EC2 dashboard go to section key pairs , click Actions -> Import key pair and upload public key you have on your MZBench server in ~/.ssh/id_rsa.pub (if you need to create new, run ssh-keygen and follow instructions). Give it a name on EC2 dashboard, put that name ( key_name ) and path ( keyfile ) in configuration file. [ {mzbench_api, [ {network_interface,\"0.0.0.0\"}, {keyfile, \"~/.ssh/id_rsa\"}, {cloud_plugins, [ {local,#{module => mzb_dummycloud_plugin}}, {ec2, #{module => mzb_api_ec2_plugin, instance_spec => [ {image_id, \"ami-03a169923be706764\"}, {group_set, [\"MZbench_cluster\"]}, {instance_type, \"t2.micro\"}, {availability_zone, \"us-west-1b\"}, {iam_instance_profile_name, \"mzbench\"}, {key_name, \"key_pair_name\"} ], config => [ {ec2_host, \"ec2.us-west-1.amazonaws.com\"}, {access_key_id, \"IAM_USER_ACCESS_KEY_ID\"}, {secret_access_key, \"IAM_USER_SECRET_ACCESS_KEY\"} ], instance_user => \"ec2-user\" }} ] } ]}]. There is both local and ec2 plugin in this configuration file, so you can choose to run tests on either of them. Default path for configuration file is ~/.config/mzbench/server.config , if it's somewhere else, server is starting with: $ ./bin/mzbench start_server --config <config_file> Note that every time you update the configuration you have to restart the server: $ ./bin/mzbench restart_server Test scenarios # Testing environment to be determined. Message publishing # In this scenario, large number of requests are sent to HTTP adapter service every second. This test checks how much time HTTP adapter needs to respond to each request. Results # TBD Create and get client # In this scenario, large number of requests are sent to things service to create things and than to retrieve their data. This test checks how much time things service needs to respond to each request. Results # TBD","title":"Benchmark"},{"location":"benchmark/#test-spec","text":"","title":"Test spec"},{"location":"benchmark/#tools","text":"MZBench vmq_mzbench mzb_api_ec2_plugin","title":"Tools"},{"location":"benchmark/#setting-up-mzbench","text":"MZbench is open-source tool for that can generate large traffic and measure performance of the application. MZBench is distributed, cloud-aware benchmarking tool that can seamlessly scale to millions of requests. It's originally developed by satori-com but we will use mzbench fork because it can run with newest Erlang releases and the original MzBench repository is not maintained anymore. We will describe installing MZBench server on Ubuntu 18.04 (this can be on your PC or some external cloud server, like droplet on Digital Ocean) Install latest OTP/Erlang (it's version 22.3 for me) sudo apt update sudo apt install erlang For running this tool you will also need libz-dev package: sudo apt-get update sudo apt-get install libz-dev and pip: sudo apt install python-pip Clone mzbench tool and install the requirements: git clone https://github.com/mzbench/mzbench cd mzbench sudo pip install -r requirements.txt This should be enough for installing MZBench, and you can now start MZBench server with this CLI command: ./bin/mzbench start_server The MZBench CLI lets you control the server and benchmarks from the command line. Another way of using MZBench is over Dashboard . After starting server you should check dashboard on http://localhost:4800 . Note that if you are installing MZBench on external server (i.e. Digital Ocean droplet), that you'll be able to reach MZBench dashboard on your server's IP address:4800, if you previously: - change default value for network_interface from 127.0.0.1 to 0.0.0.0 in configuration file. Default configuration file location is ~/.config/mzbench/server.config , create it from sample configuration file ~/.config/mzbench/server.config.example - open port 4800 with ufw allow 4800 MZBench can run your test scenarios on many nodes, simultaneously. For now, you are able to run tests locally, so your nodes will be virtual nodes on machine where MZBench server is installed (your PC or DO droplet). You can try one of our MQTT scenarios that uses vmq_mzbench worker. Copy-paste scenario in MZBench dashboard, click button Environmental variables -> Add from script and add appropriate values. Because it's running locally, you should try with smaller values, for example for fan-in scenario use 100 publishers on 2 nodes. Try this before moving forward in setting up Amazon EC2 plugin.","title":"Setting up MZBench"},{"location":"benchmark/#setting-up-amazon-ec2-plugin","text":"For larger-scale tests we will set up MZBench to run each node as one of Amazon EC2 instance with built-in plugin mzb_api_ec2_plugin . This is basic architecture when running MZBench: Every node that runs your scenarios will be one of Amazon EC2 instance; plus one more additional node \u2014 the director node. The director doesn't run scenarios, it collects the metrics from the other nodes and runs post and pre hooks . So, if you want to run jobs on 10 nodes, actually 11 EC2 instances will be created. All instances will be automatically terminated when the test finishes. We will use one of ready-to-use Amazon Machine Images (AMI) with all necessary dependencies. We will choose AMI with OTP 22, because that is the version we have on MZBench server. So, we will search for MZBench-erl22 AMI and find one with id ami-03a169923be706764 available in us-west-1b zone. If you have chosen this AMI, everything you do from now must be in us-west-1 zone. We must have IAM user with AmazonEC2FullAccess and IAMFullAccess permissions policies, and his access_key_id and secret_access_key goes to configuration file. In EC2 dashboard, you must create new security group MZbench_cluster where you will add inbound rules to open ssh and TCP ports 4801-4804. Also, in EC2 dashboard go to section key pairs , click Actions -> Import key pair and upload public key you have on your MZBench server in ~/.ssh/id_rsa.pub (if you need to create new, run ssh-keygen and follow instructions). Give it a name on EC2 dashboard, put that name ( key_name ) and path ( keyfile ) in configuration file. [ {mzbench_api, [ {network_interface,\"0.0.0.0\"}, {keyfile, \"~/.ssh/id_rsa\"}, {cloud_plugins, [ {local,#{module => mzb_dummycloud_plugin}}, {ec2, #{module => mzb_api_ec2_plugin, instance_spec => [ {image_id, \"ami-03a169923be706764\"}, {group_set, [\"MZbench_cluster\"]}, {instance_type, \"t2.micro\"}, {availability_zone, \"us-west-1b\"}, {iam_instance_profile_name, \"mzbench\"}, {key_name, \"key_pair_name\"} ], config => [ {ec2_host, \"ec2.us-west-1.amazonaws.com\"}, {access_key_id, \"IAM_USER_ACCESS_KEY_ID\"}, {secret_access_key, \"IAM_USER_SECRET_ACCESS_KEY\"} ], instance_user => \"ec2-user\" }} ] } ]}]. There is both local and ec2 plugin in this configuration file, so you can choose to run tests on either of them. Default path for configuration file is ~/.config/mzbench/server.config , if it's somewhere else, server is starting with: $ ./bin/mzbench start_server --config <config_file> Note that every time you update the configuration you have to restart the server: $ ./bin/mzbench restart_server","title":"Setting up Amazon EC2 plugin"},{"location":"benchmark/#test-scenarios","text":"Testing environment to be determined.","title":"Test scenarios"},{"location":"benchmark/#message-publishing","text":"In this scenario, large number of requests are sent to HTTP adapter service every second. This test checks how much time HTTP adapter needs to respond to each request.","title":"Message publishing"},{"location":"benchmark/#results","text":"TBD","title":"Results"},{"location":"benchmark/#create-and-get-client","text":"In this scenario, large number of requests are sent to things service to create things and than to retrieve their data. This test checks how much time things service needs to respond to each request.","title":"Create and get client"},{"location":"benchmark/#results_1","text":"TBD","title":"Results"},{"location":"cli/","text":"CLI # Mainflux CLI makes it easy to manage users, things, profiles, groups, orgs, webhooks and messages. CLI can be downloaded as separate asset from project realeses or it can be built with GNU Make tool: Get the mainflux code go get github.com/MainfluxLabs/mainflux Build the mainfluxlabs-cli make cli which will build mainfluxlabs-cli in <project_root>/build folder. Executing build/mainfluxlabs-cli without any arguments will output help with all available commands and flags: Usage: mainfluxlabs-cli [command] Available Commands: certs Certificates management group_roles Group roles management groups Groups management health Health Check help Help about any command keys Keys management messages Send or read messages orgs Orgs management profiles Profiles management provision Provision things and profiles from a config file things Things management users Users management webhooks Webhooks management Flags: -a, --auth-url string Auth service URL (default \"http://localhost\") -c, --certs-url string Certs service URL (default \"http://localhost\") -y, --content-type string Message content type (default \"application/senml+json\") -e, --email string User email query parameter -f, --format string Message format query parameter -h, --help help for mainfluxlabs-cli -p, --http-url string HTTP adapter URL (default \"http://localhost/http\") -i, --insecure Do not check for TLS cert -l, --limit uint Limit query parameter (default 100) -m, --metadata string Metadata query parameter -n, --name string Name query parameter -o, --offset uint Offset query parameter -r, --raw Enables raw output mode for easier parsing of output -s, --subtopic string Subtopic query parameter -t, --things-url string Things service URL (default \"http://localhost\") -u, --users-url string Users service URL (default \"http://localhost\") -w, --webhooks-url string Webhooks service URL (default \"http://localhost/svcwebhooks\") Use \"mainfluxlabs-cli [command] --help\" for more information about a command. It is also possible to use the docker image mainflux/cli to execute CLI command: docker run -it --rm mainflux/cli -m http://<IP_SERVER> [command] You can execute each command with -h flag for more information about that command, e.g. mainflux-cli profiles -h will get you usage info: Profiles management: create, get, update or delete Profiles and get Profile by Thing Usage: mainfluxlabs-cli profiles [flags] mainfluxlabs-cli profiles [command] Available Commands: create create <JSON_profile> <group_id> <user_token> delete delete <profile_id> <user_token> get get [all | thing | by-id] <user_token> <id> update update <JSON_string> <profile_id> <user_token> Service # Get Mainflux Things services health check # mainfluxlabs-cli health Users management # Create User # Within Mainflux, the admin creates users. The <user_token> is required because the token is used to verify that the requester is admin or not. For more details, please see Authorization page . mainfluxlabs-cli users create <user_email> <user_password> <user_token> Login User # mainfluxlabs-cli users token <user_email> <user_password> Retrieve User # mainfluxlabs-cli users get <user_token> Update User Metadata # mainfluxlabs-cli users update '{\"key1\":\"value1\", \"key2\":\"value2\"}' <user_token> Update User Password # mainfluxlabs-cli users password <old_password> <password> <user_token> System Provisioning # Provision Things # mainfluxlabs-cli provision things <file> <user_token> file - A CSV or JSON file containing things (must have extension .csv or .json ) user_token - A valid user auth token for the current system Provision Profiles # mainfluxlabs-cli provision profiles <file> <user_token> file - A CSV or JSON file containing profiles user_token - A valid user auth token for the current system Things # Create Thing # mainfluxlabs-cli things create '{\"name\":\"<thing_name>\",\"profile_id\":\"<profile_id>\"}' <group_id> <user_token> Create Thing with metadata # mainfluxlabs-cli things create '{\"name\":\"<thing_name>\",\"profile_id\":\"<profile_id>\",\"metadata\": {\"key1\":\"value1\"}}' <group_id> <user_token> Update Thing # mainfluxlabs-cli things update '{\"name\":\"<new_name>\",\"profile_id\":\"<profile_id>\"}' <thing_id> <user_token> Remove Thing # mainfluxlabs-cli things delete <thing_id> <user_token> Retrieve a subset list of provisioned Things # mainfluxlabs-cli things get all <user_token> Retrieve Thing by ID # mainfluxlabs-cli things get by-id <thing_id> <user_token> Retrieve Things by Profile # mainfluxlabs-cli things get by-profile <profile_id> <user_token> Retrieve Metadata by Key # mainfluxlabs-cli things metadata <thing_key> Retrieve Thing ID by Key # mainfluxlabs-cli things identify <thing_key> Profiles # Create Profile # mainfluxlabs-cli profiles create '{\"name\":\"<profile_name>\"}' <group_id> <user_token> Update Profile # mainfluxlabs-cli profiles update '{\"name\":\"<new_name>\"}' <profile_id> <user_token> Remove Profile # mainfluxlabs-cli profiles delete <profile_id> <user_token> Retrieve a subset list of provisioned Profiles # mainfluxlabs-cli profiles get all <user_token> Retrieve Profile by ID # mainfluxlabs-cli profiles get by-id <profile_id> <user_token> Retrieve a Profile by Thing # mainfluxlabs-cli profiles get by-thing <thing_id> <user_token> Messaging # Send a message over HTTP # mainfluxlabs-cli messages send [subtopic] '[{\"bn\":\"Dev1\",\"n\":\"temp\",\"v\":20}, {\"n\":\"hum\",\"v\":40}, {\"bn\":\"Dev2\", \"n\":\"temp\",\"v\":20}, {\"n\":\"hum\",\"v\":40}]' <thing_key> Read messages over HTTP # Read messages from a specific subtopic by adding a flag -s=<subtopic> Reading SenML messages is the default. To read JSON messages add the flag -f=json Setting the by-admin flag allows the admin to list all messages of a certain format, from all publishers If by-admin is set, auth_token will be admin_token , otherwise auth_token is thing_key mainfluxlabs-cli messages read [by-admin] <auth_token> Groups # Create Group # mainfluxlabs-cli groups create '{\"name\":\"<group_name>\",\"description\":\"<description>\",\"metadata\":{\"key\":\"value\",...}}' <org_id> <user_token> Delete Group # mainfluxlabs-cli groups delete <group_id> <user_token> Get Group by ID # mainfluxlabs-cli groups get <group_id> <user_token> List all Groups # mainfluxlabs-cli groups get all <user_token> Update Group # mainfluxlabs-cli groups update '{\"name\":\"<new_name>\"}' <group_id> <user_token> List Things by Group # mainfluxlabs-cli groups things <group_id> <user_token> View Group by Thing # mainfluxlabs-cli groups thing <thing_id> <user_token> List Profiles by Group # mainfluxlabs-cli groups profiles <group_id> <user_token> View Group by Profile # mainfluxlabs-cli groups profile <profile_id> <user_token> Orgs # Create Org # mainfluxlabs-cli orgs create '{\"name\":\"<org_name>\",\"description\":\"<description>\",\"metadata\":{\"key\":\"value\",...}}' <user_token> Get Org by ID # mainfluxlabs-cli orgs get <org_id> <user_token> List all Orgs # mainfluxlabs-cli orgs get all <user_token> Update Org # mainfluxlabs-cli orgs update '{\"name\":\"<new_name>\"}' <org_id> <user_token> Delete Org # mainfluxlabs-cli orgs delete <org_id> <user_token> Assign Member to Org # mainfluxlabs-cli orgs assign '[{\"member_id\":\"<member_id>\",\"email\":\"<email>\",\"role\":\"<role>\"}]' <org_id> <user_token> Unassign Member from Org # mainfluxlabs-cli orgs unassign '[\"<member_id>\"]' <org_id> <user_token> Get Member from Org # mainfluxlabs-cli orgs member <org_id> <member_id> <user_token> Update Members # mainfluxlabs-cli orgs update-members '[{\"member_id\":\"<member_id>\",\"role\":\"<new_role>\"}]' <org_id> <user_token> List Members by Org # mainfluxlabs-cli orgs members <org_id> <user_token> Webhooks # Create Webhooks # mainfluxlabs-cli webhooks create '[{\"name\":\"<webhook_name>\",\"url\":\"<http://webhook-url.com>\",\"headers\":{\"key\":\"value\",...}}]' <thing_id> <user_token> Get Webhook by ID # mainfluxlabs-cli webhooks get by-id <id> <user_token> Get Webhooks by Group # mainfluxlabs-cli webhooks get by-group <group_id> <user_token> Get Webhooks by Thing # mainfluxlabs-cli webhooks get by-thing <thing_id> <user_token> Update Webhook # mainfluxlabs-cli webhooks update '{\"name\":\"<new_name>\",\"url\":\"<http://webhook-url.com>\"}' <webhook_id> <user_token> Delete Webhooks # mainfluxlabs-cli webhooks delete '[\"<webhook_id>\"]' <user_token> Keys management # Issue a new Key # mainfluxlabs-cli keys issue <duration> <user_token> Remove API key from database # mainfluxlabs-cli keys revoke <key_id> <user_token> Retrieve API key with given id # mainfluxlabs-cli keys retrieve <key_id> <user_token>","title":"CLI"},{"location":"cli/#cli","text":"Mainflux CLI makes it easy to manage users, things, profiles, groups, orgs, webhooks and messages. CLI can be downloaded as separate asset from project realeses or it can be built with GNU Make tool: Get the mainflux code go get github.com/MainfluxLabs/mainflux Build the mainfluxlabs-cli make cli which will build mainfluxlabs-cli in <project_root>/build folder. Executing build/mainfluxlabs-cli without any arguments will output help with all available commands and flags: Usage: mainfluxlabs-cli [command] Available Commands: certs Certificates management group_roles Group roles management groups Groups management health Health Check help Help about any command keys Keys management messages Send or read messages orgs Orgs management profiles Profiles management provision Provision things and profiles from a config file things Things management users Users management webhooks Webhooks management Flags: -a, --auth-url string Auth service URL (default \"http://localhost\") -c, --certs-url string Certs service URL (default \"http://localhost\") -y, --content-type string Message content type (default \"application/senml+json\") -e, --email string User email query parameter -f, --format string Message format query parameter -h, --help help for mainfluxlabs-cli -p, --http-url string HTTP adapter URL (default \"http://localhost/http\") -i, --insecure Do not check for TLS cert -l, --limit uint Limit query parameter (default 100) -m, --metadata string Metadata query parameter -n, --name string Name query parameter -o, --offset uint Offset query parameter -r, --raw Enables raw output mode for easier parsing of output -s, --subtopic string Subtopic query parameter -t, --things-url string Things service URL (default \"http://localhost\") -u, --users-url string Users service URL (default \"http://localhost\") -w, --webhooks-url string Webhooks service URL (default \"http://localhost/svcwebhooks\") Use \"mainfluxlabs-cli [command] --help\" for more information about a command. It is also possible to use the docker image mainflux/cli to execute CLI command: docker run -it --rm mainflux/cli -m http://<IP_SERVER> [command] You can execute each command with -h flag for more information about that command, e.g. mainflux-cli profiles -h will get you usage info: Profiles management: create, get, update or delete Profiles and get Profile by Thing Usage: mainfluxlabs-cli profiles [flags] mainfluxlabs-cli profiles [command] Available Commands: create create <JSON_profile> <group_id> <user_token> delete delete <profile_id> <user_token> get get [all | thing | by-id] <user_token> <id> update update <JSON_string> <profile_id> <user_token>","title":"CLI"},{"location":"cli/#service","text":"","title":"Service"},{"location":"cli/#get-mainflux-things-services-health-check","text":"mainfluxlabs-cli health","title":"Get Mainflux Things services health check"},{"location":"cli/#users-management","text":"","title":"Users management"},{"location":"cli/#create-user","text":"Within Mainflux, the admin creates users. The <user_token> is required because the token is used to verify that the requester is admin or not. For more details, please see Authorization page . mainfluxlabs-cli users create <user_email> <user_password> <user_token>","title":"Create User"},{"location":"cli/#login-user","text":"mainfluxlabs-cli users token <user_email> <user_password>","title":"Login User"},{"location":"cli/#retrieve-user","text":"mainfluxlabs-cli users get <user_token>","title":"Retrieve User"},{"location":"cli/#update-user-metadata","text":"mainfluxlabs-cli users update '{\"key1\":\"value1\", \"key2\":\"value2\"}' <user_token>","title":"Update User Metadata"},{"location":"cli/#update-user-password","text":"mainfluxlabs-cli users password <old_password> <password> <user_token>","title":"Update User Password"},{"location":"cli/#system-provisioning","text":"","title":"System Provisioning"},{"location":"cli/#provision-things","text":"mainfluxlabs-cli provision things <file> <user_token> file - A CSV or JSON file containing things (must have extension .csv or .json ) user_token - A valid user auth token for the current system","title":"Provision Things"},{"location":"cli/#provision-profiles","text":"mainfluxlabs-cli provision profiles <file> <user_token> file - A CSV or JSON file containing profiles user_token - A valid user auth token for the current system","title":"Provision Profiles"},{"location":"cli/#things","text":"","title":"Things"},{"location":"cli/#create-thing","text":"mainfluxlabs-cli things create '{\"name\":\"<thing_name>\",\"profile_id\":\"<profile_id>\"}' <group_id> <user_token>","title":"Create Thing"},{"location":"cli/#create-thing-with-metadata","text":"mainfluxlabs-cli things create '{\"name\":\"<thing_name>\",\"profile_id\":\"<profile_id>\",\"metadata\": {\"key1\":\"value1\"}}' <group_id> <user_token>","title":"Create Thing with metadata"},{"location":"cli/#update-thing","text":"mainfluxlabs-cli things update '{\"name\":\"<new_name>\",\"profile_id\":\"<profile_id>\"}' <thing_id> <user_token>","title":"Update Thing"},{"location":"cli/#remove-thing","text":"mainfluxlabs-cli things delete <thing_id> <user_token>","title":"Remove Thing"},{"location":"cli/#retrieve-a-subset-list-of-provisioned-things","text":"mainfluxlabs-cli things get all <user_token>","title":"Retrieve a subset list of provisioned Things"},{"location":"cli/#retrieve-thing-by-id","text":"mainfluxlabs-cli things get by-id <thing_id> <user_token>","title":"Retrieve Thing by ID"},{"location":"cli/#retrieve-things-by-profile","text":"mainfluxlabs-cli things get by-profile <profile_id> <user_token>","title":"Retrieve Things by Profile"},{"location":"cli/#retrieve-metadata-by-key","text":"mainfluxlabs-cli things metadata <thing_key>","title":"Retrieve Metadata by Key"},{"location":"cli/#retrieve-thing-id-by-key","text":"mainfluxlabs-cli things identify <thing_key>","title":"Retrieve Thing ID by Key"},{"location":"cli/#profiles","text":"","title":"Profiles"},{"location":"cli/#create-profile","text":"mainfluxlabs-cli profiles create '{\"name\":\"<profile_name>\"}' <group_id> <user_token>","title":"Create Profile"},{"location":"cli/#update-profile","text":"mainfluxlabs-cli profiles update '{\"name\":\"<new_name>\"}' <profile_id> <user_token>","title":"Update Profile"},{"location":"cli/#remove-profile","text":"mainfluxlabs-cli profiles delete <profile_id> <user_token>","title":"Remove Profile"},{"location":"cli/#retrieve-a-subset-list-of-provisioned-profiles","text":"mainfluxlabs-cli profiles get all <user_token>","title":"Retrieve a subset list of provisioned Profiles"},{"location":"cli/#retrieve-profile-by-id","text":"mainfluxlabs-cli profiles get by-id <profile_id> <user_token>","title":"Retrieve Profile by ID"},{"location":"cli/#retrieve-a-profile-by-thing","text":"mainfluxlabs-cli profiles get by-thing <thing_id> <user_token>","title":"Retrieve a Profile by Thing"},{"location":"cli/#messaging","text":"","title":"Messaging"},{"location":"cli/#send-a-message-over-http","text":"mainfluxlabs-cli messages send [subtopic] '[{\"bn\":\"Dev1\",\"n\":\"temp\",\"v\":20}, {\"n\":\"hum\",\"v\":40}, {\"bn\":\"Dev2\", \"n\":\"temp\",\"v\":20}, {\"n\":\"hum\",\"v\":40}]' <thing_key>","title":"Send a message over HTTP"},{"location":"cli/#read-messages-over-http","text":"Read messages from a specific subtopic by adding a flag -s=<subtopic> Reading SenML messages is the default. To read JSON messages add the flag -f=json Setting the by-admin flag allows the admin to list all messages of a certain format, from all publishers If by-admin is set, auth_token will be admin_token , otherwise auth_token is thing_key mainfluxlabs-cli messages read [by-admin] <auth_token>","title":"Read messages over HTTP"},{"location":"cli/#groups","text":"","title":"Groups"},{"location":"cli/#create-group","text":"mainfluxlabs-cli groups create '{\"name\":\"<group_name>\",\"description\":\"<description>\",\"metadata\":{\"key\":\"value\",...}}' <org_id> <user_token>","title":"Create Group"},{"location":"cli/#delete-group","text":"mainfluxlabs-cli groups delete <group_id> <user_token>","title":"Delete Group"},{"location":"cli/#get-group-by-id","text":"mainfluxlabs-cli groups get <group_id> <user_token>","title":"Get Group by ID"},{"location":"cli/#list-all-groups","text":"mainfluxlabs-cli groups get all <user_token>","title":"List all Groups"},{"location":"cli/#update-group","text":"mainfluxlabs-cli groups update '{\"name\":\"<new_name>\"}' <group_id> <user_token>","title":"Update Group"},{"location":"cli/#list-things-by-group","text":"mainfluxlabs-cli groups things <group_id> <user_token>","title":"List Things by Group"},{"location":"cli/#view-group-by-thing","text":"mainfluxlabs-cli groups thing <thing_id> <user_token>","title":"View Group by Thing"},{"location":"cli/#list-profiles-by-group","text":"mainfluxlabs-cli groups profiles <group_id> <user_token>","title":"List Profiles by Group"},{"location":"cli/#view-group-by-profile","text":"mainfluxlabs-cli groups profile <profile_id> <user_token>","title":"View Group by Profile"},{"location":"cli/#orgs","text":"","title":"Orgs"},{"location":"cli/#create-org","text":"mainfluxlabs-cli orgs create '{\"name\":\"<org_name>\",\"description\":\"<description>\",\"metadata\":{\"key\":\"value\",...}}' <user_token>","title":"Create Org"},{"location":"cli/#get-org-by-id","text":"mainfluxlabs-cli orgs get <org_id> <user_token>","title":"Get Org by ID"},{"location":"cli/#list-all-orgs","text":"mainfluxlabs-cli orgs get all <user_token>","title":"List all Orgs"},{"location":"cli/#update-org","text":"mainfluxlabs-cli orgs update '{\"name\":\"<new_name>\"}' <org_id> <user_token>","title":"Update Org"},{"location":"cli/#delete-org","text":"mainfluxlabs-cli orgs delete <org_id> <user_token>","title":"Delete Org"},{"location":"cli/#assign-member-to-org","text":"mainfluxlabs-cli orgs assign '[{\"member_id\":\"<member_id>\",\"email\":\"<email>\",\"role\":\"<role>\"}]' <org_id> <user_token>","title":"Assign Member to Org"},{"location":"cli/#unassign-member-from-org","text":"mainfluxlabs-cli orgs unassign '[\"<member_id>\"]' <org_id> <user_token>","title":"Unassign Member from Org"},{"location":"cli/#get-member-from-org","text":"mainfluxlabs-cli orgs member <org_id> <member_id> <user_token>","title":"Get Member from Org"},{"location":"cli/#update-members","text":"mainfluxlabs-cli orgs update-members '[{\"member_id\":\"<member_id>\",\"role\":\"<new_role>\"}]' <org_id> <user_token>","title":"Update Members"},{"location":"cli/#list-members-by-org","text":"mainfluxlabs-cli orgs members <org_id> <user_token>","title":"List Members by Org"},{"location":"cli/#webhooks","text":"","title":"Webhooks"},{"location":"cli/#create-webhooks","text":"mainfluxlabs-cli webhooks create '[{\"name\":\"<webhook_name>\",\"url\":\"<http://webhook-url.com>\",\"headers\":{\"key\":\"value\",...}}]' <thing_id> <user_token>","title":"Create Webhooks"},{"location":"cli/#get-webhook-by-id","text":"mainfluxlabs-cli webhooks get by-id <id> <user_token>","title":"Get Webhook by ID"},{"location":"cli/#get-webhooks-by-group","text":"mainfluxlabs-cli webhooks get by-group <group_id> <user_token>","title":"Get Webhooks by Group"},{"location":"cli/#get-webhooks-by-thing","text":"mainfluxlabs-cli webhooks get by-thing <thing_id> <user_token>","title":"Get Webhooks by Thing"},{"location":"cli/#update-webhook","text":"mainfluxlabs-cli webhooks update '{\"name\":\"<new_name>\",\"url\":\"<http://webhook-url.com>\"}' <webhook_id> <user_token>","title":"Update Webhook"},{"location":"cli/#delete-webhooks","text":"mainfluxlabs-cli webhooks delete '[\"<webhook_id>\"]' <user_token>","title":"Delete Webhooks"},{"location":"cli/#keys-management","text":"","title":"Keys management"},{"location":"cli/#issue-a-new-key","text":"mainfluxlabs-cli keys issue <duration> <user_token>","title":"Issue a new Key"},{"location":"cli/#remove-api-key-from-database","text":"mainfluxlabs-cli keys revoke <key_id> <user_token>","title":"Remove API key from database"},{"location":"cli/#retrieve-api-key-with-given-id","text":"mainfluxlabs-cli keys retrieve <key_id> <user_token>","title":"Retrieve API key with given id"},{"location":"dev-guide/","text":"Developer's guide # Getting Mainflux # Mainflux source can be found in the official Mainflux GitHub repository . You should fork this repository in order to make changes to the project. The forked version of the repository should be cloned using the following: git clone <forked repository> $SOMEPATH/mainflux cd $SOMEPATH/mainflux Note: If your $SOMEPATH is equal to $GOPATH/src/github.com/MainfluxLabs/mainflux , make sure that your $GOROOT and $GOPATH do not overlap (otherwise, go modules won't work). Building # Prerequisites # Make sure that you have Protocol Buffers (version 3.19.1) compiler ( protoc ) installed. Go Protobuf installation instructions are here . Go Protobuf uses C bindings, so you will need to install C++ protobuf as a prerequisite. Mainflux uses Protocol Buffers for Go with Gadgets to generate faster marshaling and unmarshaling Go code. Protocol Buffers for Go with Gadgets installation instructions can be found here . A copy of Go (version 1.17.5) and docker template (version 3.7) will also need to be installed on your system. If any of these versions seem outdated, the latest can always be found in our CI script . Build All Services # Use the GNU Make tool to build all Mainflux services: make Build artifacts will be put in the build directory. N.B. All Mainflux services are built as a statically linked binaries. This way they can be portable (transferred to any platform just by placing them there and running them) as they contain all needed libraries and do not relay on shared system libraries. This helps creating FROM scratch dockers. Build Individual Microservice # Individual microservices can be built with: make <microservice_name> For example: make http will build the HTTP Adapter microservice. Building Dockers # Dockers can be built with: make dockers or individually with: make docker_<microservice_name> For example: make docker_http N.B. Mainflux creates FROM scratch docker containers which are compact and small in size. N.B. The things-db and users-db containers are built from a vanilla PostgreSQL docker image downloaded from docker hub which does not persist the data when these containers are rebuilt. Thus, rebuilding of all docker containers with make dockers or rebuilding the things-db and users-db containers separately with make docker_things-db and make docker_users-db respectively, will cause data loss. All your users, things, profiles, groups will be lost! As we use this setup only for development, we don't guarantee any permanent data persistence. Though, in order to enable data retention, we have configured persistent volumes for each container that stores some data. If you want to update your Mainflux dockerized installation and want to keep your data, use make cleandocker to clean the containers and images and keep the data (stored in docker persistent volumes) and then make run to update the images and the containers. Check the Cleaning up your dockerized Mainflux setup section for details. Please note that this kind of updating might not work if there are database changes. Building Docker images for development # In order to speed up build process, you can use commands such as: make dockers_dev or individually with make docker_dev_<microservice_name> Commands make dockers and make dockers_dev are similar. The main difference is that building images in the development mode is done on the local machine, rather than an intermediate image, which makes building images much faster. Before running this command, corresponding binary needs to be built in order to make changes visible. This can be done using make or make <service_name> command. Commands make dockers_dev and make docker_dev_<service_name> should be used only for development to speed up the process of image building. For deployment images, commands from section above should be used. Suggested workflow # When the project is first cloned to your system, you will need to make sure and build all of the Mainflux services. make make dockers_dev As you develop and test changes, only the services related to your changes will need to be rebuilt. This will reduce compile time and create a much more enjoyable development experience. make <microservice_name> make docker_dev_<microservice_name> make run Overriding the default docker-compose configuration # Sometimes, depending on the use case and the user's needs it might be useful to override or add some extra parameters to the docker-compose configuration. These configuration changes can be done by specifying multiple compose files with the docker-compose command line option -f as described here . The following format of the docker-compose command can be used to extend or override the configuration: docker-compose -f docker/docker-compose.yml -f docker/docker-compose.custom1.yml -f docker/docker-compose.custom2.yml up [-d] In the command above each successive file overrides the previous parameters. A practical example in our case would be to enable debugging and tracing in NATS so that we can see better how are the messages moving around. docker-compose.nats-debugging.yml version: \"3\" services: nats: command: --debug -DV When we have the override files in place, to compose the whole infrastructure including the persistent volumes we can execute: docker-compose -f docker/docker-compose.yml -f docker/docker-compose.nats-debugging.yml up -d Note: Please store your customizations to some folder outside the Mainflux's source folder and maybe add them to some other git repository. You can always apply your customizations by pointing to the right file using docker-compose -f ... . Cleaning up your dockerized Mainflux setup # If you want to clean your whole dockerized Mainflux installation you can use the make pv=true cleandocker command. Please note that by default the make cleandocker command will stop and delete all of the containers and images, but NOT DELETE persistent volumes . If you want to delete the gathered data in the system (the persistent volumes) please use the following command make pv=true cleandocker (pv = persistent volumes). This form of the command will stop and delete the containers, the images and will also delete the persistent volumes. MQTT Microservice # The MQTT Microservice in Mainflux is special, as it is currently the only microservice written in NodeJS. It is not compiled, but node modules need to be downloaded in order to start the service: cd mqtt npm install Note that there is a shorthand for doing these commands with make tool: make mqtt After that, the MQTT Adapter can be started from top directory (as it needs to find *.proto files) with: node mqtt/mqtt.js Troubleshooting # Depending on your use case, MQTT topics, message size, the number of clients and the frequency with which the messages are sent it can happen that you experience some problems. Up until now it has been noticed that in case of high load, big messages and many clients it can happen that the MQTT microservice crashes with the following error: mainflux-mqtt | FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory mainflux-mqtt exited with code 137 This problem is caused the default allowed memory in node (V8). V8 gives the user 1.7GB per default . To fix the problem you should add the following environment variable NODE_OPTIONS:--max-old-space-size=SPACE_IN_MB in the environment section of the aedes.yml configuration. To find the right value for the --max-old-space-size parameter you'll have to experiment a bit depending on your needs. The Mainflux MQTT service uses the Aedes MQTT Broker for implementation of the MQTT related things. Therefore, for some questions or problems you can also check out the Aedes's documentation or reach out its contributors. Protobuf # If you've made any changes to .proto files, you should call protoc command prior to compiling individual microservices. To do this by hand, execute: protoc --gofast_out=plugins=grpc:. *.proto protoc --gogo_out=plugins=grpc:. broker/*.proto A shorthand to do this via make tool is: make proto N.B. This must be done once at the beginning in order to generate protobuf Go structures needed for the build. However, if you don't change any of .proto files, this step is not mandatory, since all generated files are included in the repository (those are files with .pb.go extension). Cross-compiling for ARM # Mainflux can be compiled for ARM platform and run on Raspberry Pi or other similar IoT gateways, by following the instructions here or here as well as information found here . The environment variables GOARCH=arm and GOARM=7 must be set for the compilation. Cross-compilation for ARM with Mainflux make: GOOS=linux GOARCH=arm GOARM=7 make Running tests # To run all of the tests you can execute: make test Dockertest is used for the tests, so to run them, you will need the Docker daemon/service running. Installing # Installing Go binaries is simple: just move them from build to $GOBIN (do not fortget to add $GOBIN to your $PATH ). You can execute: make install which will do this copying of the binaries. N.B. Only Go binaries will be installed this way. The MQTT adapter is a NodeJS script and will stay in the mqtt dir. Deployment # Prerequisites # Mainflux depends on several infrastructural services, notably NATS broker and PostgreSQL database. NATS # Mainflux uses NATS as it's central message bus. For development purposes (when not run via Docker), it expects that NATS is installed on the local system. To do this execute: go get github.com/nats-io/gnatsd This will install gnatsd binary that can be simply run by executing: gnatsd PostgreSQL # Mainflux uses PostgreSQL to store metadata ( users , orgs , groups , things and profiles entities alongside with authorization tokens). It expects that PostgreSQL DB is installed, set up and running on the local system. Information how to set-up (prepare) PostgreSQL database can be found here , and it is done by executing following commands: # Create `users` and `things` databases sudo -u postgres createdb users sudo -u postgres createdb things # Set-up Postgres roles sudo su - postgres psql -U postgres postgres=# CREATE ROLE mainflux WITH LOGIN ENCRYPTED PASSWORD 'mainflux'; postgres=# ALTER USER mainflux WITH LOGIN ENCRYPTED PASSWORD 'mainflux'; Mainflux Services # Running of the Mainflux microservices can be tricky, as there is a lot of them and each demand configuration in the form of environment variables. The whole system (set of microservices) can be run with one command: make rundev which will properly configure and run all microservices. Please assure that MQTT microservice has node_modules installed, as explained in MQTT Microservice chapter. N.B. make rundev actually calls helper script scripts/run.sh , so you can inspect this script for the details. Events # In order to be easily integratable system, Mainflux is using Redis Streams as an event log for event sourcing. Services that are publishing events to Redis Streams are things service and mqtt adapter. Things Service # For every operation that has side effects (that is changing service state) things service will generate new event and publish it to Redis Stream called mainflux.things . Every event has its own event ID that is automatically generated and operation field that can have one of the following values: - thing.create for thing creation, - thing.update for thing update, - thing.remove for thing removal, - profile.create for profile creation, - profile.update for profile update, - profile.remove for profile removal. By fetching and processing these events you can reconstruct things service state. If you store some of your custom data in metadata field, this is the perfect way to fetch it and process it. If you want to integrate through docker-compose.yml you can use mainflux-es-redis service. Just connect to it and consume events from Redis Stream named mainflux.things . Thing create event # Whenever thing is created, things service will generate new create event. This event will have the following format: 1) \"1555334740911-0\" 2) 1) \"id\" 2) \"1c36273a-94ea-4802-84d6-a51de140112a\" 3) \"group_id\" 4) \"2c36273a-94ea-4802-84d6-a51de140112b\" 5) \"profile_id\" 6) \"3c36273a-94ea-4802-84d6-a51de140112c\" 7) \"operation\" 8) \"thing.create\" 9) \"name\" 10) \"d0\" 11) \"metadata\" 12) \"{}\" As you can see from this example, every odd field represents field name while every even field represents field value. This is standard event format for Redis Streams. If you want to extract metadata field from this event, you'll have to read it as string first and then you can deserialize it to some structured format. Thing update event # Whenever thing instance is updated, things service will generate new update event. This event will have the following format: 1) \"1555336161544-0\" 2) 1) \"id\" 2) \"3c36273a-94ea-4802-84d6-a51de140112e\" 3) \"profile_id\" 4) \"3c36273a-94ea-4802-84d6-a51de140112c\" 5) \"operation\" 6) \"thing.update\" 7) \"name\" 8) \"weio\" Note that thing update event will contain only those fields that were updated using update endpoint. Thing remove event # Whenever thing instance is removed from the system, things service will generate and publish new remove event. This event will have the following format: 1) 1) \"1555339313003-0\" 2) 1) \"id\" 2) \"3c36273a-94ea-4802-84d6-a51de140112e\" 3) \"operation\" 4) \"thing.remove\" Profile create event # Whenever profile instance is created, things service will generate and publish new create event. This event will have the following format: 1) \"1555334740918-0\" 2) 1) \"id\" 2) \"16fb2748-8d3b-4783-b272-bb5f4ad4d661\" 3) \"group_id\" 4) \"2c36273a-94ea-4802-84d6-a51de140112b\" 5) \"operation\" 6) \"profile.create\" 7) \"name\" 8) \"p1\" Profile update event # Whenever profile instance is updated, things service will generate and publish new update event. This event will have the following format: 1) \"1555338870341-0\" 2) 1) \"id\" 2) \"d9d8f31b-f8d4-49c5-b943-6db10d8e2949\" 3) \"name\" 4) \"profile1\" 5) \"operation\" 6) \"profile.update\" Note that update profile event will contain only those fields that were updated using update profile endpoint. Profile remove event # Whenever profile instance is removed from the system, things service will generate and publish new remove event. This event will have the following format: 1) 1) \"1555339429661-0\" 2) 1) \"id\" 2) \"d9d8f31b-f8d4-49c5-b943-6db10d8e2949\" 3) \"operation\" 4) \"profile.remove\" Note: Every one of these events will omit fields that were not used or are not relevant for specific operation. Also, field ordering is not guaranteed, so DO NOT rely on it. MQTT Adapter # Instead of using heartbeat to know when client is connected through MQTT adapter one can fetch events from Redis Streams that MQTT adapter publishes. MQTT adapter publishes events every time client connects and disconnects to stream named mainflux.mqtt . Events that are coming from MQTT adapter have following fields: - thing_id ID of a thing that has connected to MQTT adapter, - timestamp is in Epoch UNIX Time Stamp format, - event_type can have two possible values, connect and disconnect, - instance represents MQTT adapter instance. If you want to integrate through docker-compose.yml you can use mainflux-es-redis service. Just connect to it and consume events from Redis Stream named mainflux.mqtt . Example of connect event: 1) 1) \"1555351214144-0\" 2) 1) \"thing_id\" 2) \"1c597a85-b68e-42ff-8ed8-a3a761884bc4\" 3) \"timestamp\" 4) \"1555351214\" 5) \"event_type\" 6) \"connect\" 7) \"instance\" 8) \"mqtt-adapter-1\" Example of disconnect event: 1) 1) \"1555351214188-0\" 2) 1) \"thing_id\" 2) \"1c597a85-b68e-42ff-8ed8-a3a761884bc4\" 3) \"timestamp\" 4) \"1555351214\" 5) \"event_type\" 6) \"disconnect\" 7) \"instance\" 8) \"mqtt-adapter-1\"","title":"Developer's Guide"},{"location":"dev-guide/#developers-guide","text":"","title":"Developer's guide"},{"location":"dev-guide/#getting-mainflux","text":"Mainflux source can be found in the official Mainflux GitHub repository . You should fork this repository in order to make changes to the project. The forked version of the repository should be cloned using the following: git clone <forked repository> $SOMEPATH/mainflux cd $SOMEPATH/mainflux Note: If your $SOMEPATH is equal to $GOPATH/src/github.com/MainfluxLabs/mainflux , make sure that your $GOROOT and $GOPATH do not overlap (otherwise, go modules won't work).","title":"Getting Mainflux"},{"location":"dev-guide/#building","text":"","title":"Building"},{"location":"dev-guide/#prerequisites","text":"Make sure that you have Protocol Buffers (version 3.19.1) compiler ( protoc ) installed. Go Protobuf installation instructions are here . Go Protobuf uses C bindings, so you will need to install C++ protobuf as a prerequisite. Mainflux uses Protocol Buffers for Go with Gadgets to generate faster marshaling and unmarshaling Go code. Protocol Buffers for Go with Gadgets installation instructions can be found here . A copy of Go (version 1.17.5) and docker template (version 3.7) will also need to be installed on your system. If any of these versions seem outdated, the latest can always be found in our CI script .","title":"Prerequisites"},{"location":"dev-guide/#build-all-services","text":"Use the GNU Make tool to build all Mainflux services: make Build artifacts will be put in the build directory. N.B. All Mainflux services are built as a statically linked binaries. This way they can be portable (transferred to any platform just by placing them there and running them) as they contain all needed libraries and do not relay on shared system libraries. This helps creating FROM scratch dockers.","title":"Build All Services"},{"location":"dev-guide/#build-individual-microservice","text":"Individual microservices can be built with: make <microservice_name> For example: make http will build the HTTP Adapter microservice.","title":"Build Individual Microservice"},{"location":"dev-guide/#building-dockers","text":"Dockers can be built with: make dockers or individually with: make docker_<microservice_name> For example: make docker_http N.B. Mainflux creates FROM scratch docker containers which are compact and small in size. N.B. The things-db and users-db containers are built from a vanilla PostgreSQL docker image downloaded from docker hub which does not persist the data when these containers are rebuilt. Thus, rebuilding of all docker containers with make dockers or rebuilding the things-db and users-db containers separately with make docker_things-db and make docker_users-db respectively, will cause data loss. All your users, things, profiles, groups will be lost! As we use this setup only for development, we don't guarantee any permanent data persistence. Though, in order to enable data retention, we have configured persistent volumes for each container that stores some data. If you want to update your Mainflux dockerized installation and want to keep your data, use make cleandocker to clean the containers and images and keep the data (stored in docker persistent volumes) and then make run to update the images and the containers. Check the Cleaning up your dockerized Mainflux setup section for details. Please note that this kind of updating might not work if there are database changes.","title":"Building Dockers"},{"location":"dev-guide/#building-docker-images-for-development","text":"In order to speed up build process, you can use commands such as: make dockers_dev or individually with make docker_dev_<microservice_name> Commands make dockers and make dockers_dev are similar. The main difference is that building images in the development mode is done on the local machine, rather than an intermediate image, which makes building images much faster. Before running this command, corresponding binary needs to be built in order to make changes visible. This can be done using make or make <service_name> command. Commands make dockers_dev and make docker_dev_<service_name> should be used only for development to speed up the process of image building. For deployment images, commands from section above should be used.","title":"Building Docker images for development"},{"location":"dev-guide/#suggested-workflow","text":"When the project is first cloned to your system, you will need to make sure and build all of the Mainflux services. make make dockers_dev As you develop and test changes, only the services related to your changes will need to be rebuilt. This will reduce compile time and create a much more enjoyable development experience. make <microservice_name> make docker_dev_<microservice_name> make run","title":"Suggested workflow"},{"location":"dev-guide/#overriding-the-default-docker-compose-configuration","text":"Sometimes, depending on the use case and the user's needs it might be useful to override or add some extra parameters to the docker-compose configuration. These configuration changes can be done by specifying multiple compose files with the docker-compose command line option -f as described here . The following format of the docker-compose command can be used to extend or override the configuration: docker-compose -f docker/docker-compose.yml -f docker/docker-compose.custom1.yml -f docker/docker-compose.custom2.yml up [-d] In the command above each successive file overrides the previous parameters. A practical example in our case would be to enable debugging and tracing in NATS so that we can see better how are the messages moving around. docker-compose.nats-debugging.yml version: \"3\" services: nats: command: --debug -DV When we have the override files in place, to compose the whole infrastructure including the persistent volumes we can execute: docker-compose -f docker/docker-compose.yml -f docker/docker-compose.nats-debugging.yml up -d Note: Please store your customizations to some folder outside the Mainflux's source folder and maybe add them to some other git repository. You can always apply your customizations by pointing to the right file using docker-compose -f ... .","title":"Overriding the default docker-compose configuration"},{"location":"dev-guide/#cleaning-up-your-dockerized-mainflux-setup","text":"If you want to clean your whole dockerized Mainflux installation you can use the make pv=true cleandocker command. Please note that by default the make cleandocker command will stop and delete all of the containers and images, but NOT DELETE persistent volumes . If you want to delete the gathered data in the system (the persistent volumes) please use the following command make pv=true cleandocker (pv = persistent volumes). This form of the command will stop and delete the containers, the images and will also delete the persistent volumes.","title":"Cleaning up your dockerized Mainflux setup"},{"location":"dev-guide/#mqtt-microservice","text":"The MQTT Microservice in Mainflux is special, as it is currently the only microservice written in NodeJS. It is not compiled, but node modules need to be downloaded in order to start the service: cd mqtt npm install Note that there is a shorthand for doing these commands with make tool: make mqtt After that, the MQTT Adapter can be started from top directory (as it needs to find *.proto files) with: node mqtt/mqtt.js","title":"MQTT Microservice"},{"location":"dev-guide/#troubleshooting","text":"Depending on your use case, MQTT topics, message size, the number of clients and the frequency with which the messages are sent it can happen that you experience some problems. Up until now it has been noticed that in case of high load, big messages and many clients it can happen that the MQTT microservice crashes with the following error: mainflux-mqtt | FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory mainflux-mqtt exited with code 137 This problem is caused the default allowed memory in node (V8). V8 gives the user 1.7GB per default . To fix the problem you should add the following environment variable NODE_OPTIONS:--max-old-space-size=SPACE_IN_MB in the environment section of the aedes.yml configuration. To find the right value for the --max-old-space-size parameter you'll have to experiment a bit depending on your needs. The Mainflux MQTT service uses the Aedes MQTT Broker for implementation of the MQTT related things. Therefore, for some questions or problems you can also check out the Aedes's documentation or reach out its contributors.","title":"Troubleshooting"},{"location":"dev-guide/#protobuf","text":"If you've made any changes to .proto files, you should call protoc command prior to compiling individual microservices. To do this by hand, execute: protoc --gofast_out=plugins=grpc:. *.proto protoc --gogo_out=plugins=grpc:. broker/*.proto A shorthand to do this via make tool is: make proto N.B. This must be done once at the beginning in order to generate protobuf Go structures needed for the build. However, if you don't change any of .proto files, this step is not mandatory, since all generated files are included in the repository (those are files with .pb.go extension).","title":"Protobuf"},{"location":"dev-guide/#cross-compiling-for-arm","text":"Mainflux can be compiled for ARM platform and run on Raspberry Pi or other similar IoT gateways, by following the instructions here or here as well as information found here . The environment variables GOARCH=arm and GOARM=7 must be set for the compilation. Cross-compilation for ARM with Mainflux make: GOOS=linux GOARCH=arm GOARM=7 make","title":"Cross-compiling for ARM"},{"location":"dev-guide/#running-tests","text":"To run all of the tests you can execute: make test Dockertest is used for the tests, so to run them, you will need the Docker daemon/service running.","title":"Running tests"},{"location":"dev-guide/#installing","text":"Installing Go binaries is simple: just move them from build to $GOBIN (do not fortget to add $GOBIN to your $PATH ). You can execute: make install which will do this copying of the binaries. N.B. Only Go binaries will be installed this way. The MQTT adapter is a NodeJS script and will stay in the mqtt dir.","title":"Installing"},{"location":"dev-guide/#deployment","text":"","title":"Deployment"},{"location":"dev-guide/#prerequisites_1","text":"Mainflux depends on several infrastructural services, notably NATS broker and PostgreSQL database.","title":"Prerequisites"},{"location":"dev-guide/#nats","text":"Mainflux uses NATS as it's central message bus. For development purposes (when not run via Docker), it expects that NATS is installed on the local system. To do this execute: go get github.com/nats-io/gnatsd This will install gnatsd binary that can be simply run by executing: gnatsd","title":"NATS"},{"location":"dev-guide/#postgresql","text":"Mainflux uses PostgreSQL to store metadata ( users , orgs , groups , things and profiles entities alongside with authorization tokens). It expects that PostgreSQL DB is installed, set up and running on the local system. Information how to set-up (prepare) PostgreSQL database can be found here , and it is done by executing following commands: # Create `users` and `things` databases sudo -u postgres createdb users sudo -u postgres createdb things # Set-up Postgres roles sudo su - postgres psql -U postgres postgres=# CREATE ROLE mainflux WITH LOGIN ENCRYPTED PASSWORD 'mainflux'; postgres=# ALTER USER mainflux WITH LOGIN ENCRYPTED PASSWORD 'mainflux';","title":"PostgreSQL"},{"location":"dev-guide/#mainflux-services","text":"Running of the Mainflux microservices can be tricky, as there is a lot of them and each demand configuration in the form of environment variables. The whole system (set of microservices) can be run with one command: make rundev which will properly configure and run all microservices. Please assure that MQTT microservice has node_modules installed, as explained in MQTT Microservice chapter. N.B. make rundev actually calls helper script scripts/run.sh , so you can inspect this script for the details.","title":"Mainflux Services"},{"location":"dev-guide/#events","text":"In order to be easily integratable system, Mainflux is using Redis Streams as an event log for event sourcing. Services that are publishing events to Redis Streams are things service and mqtt adapter.","title":"Events"},{"location":"dev-guide/#things-service","text":"For every operation that has side effects (that is changing service state) things service will generate new event and publish it to Redis Stream called mainflux.things . Every event has its own event ID that is automatically generated and operation field that can have one of the following values: - thing.create for thing creation, - thing.update for thing update, - thing.remove for thing removal, - profile.create for profile creation, - profile.update for profile update, - profile.remove for profile removal. By fetching and processing these events you can reconstruct things service state. If you store some of your custom data in metadata field, this is the perfect way to fetch it and process it. If you want to integrate through docker-compose.yml you can use mainflux-es-redis service. Just connect to it and consume events from Redis Stream named mainflux.things .","title":"Things Service"},{"location":"dev-guide/#thing-create-event","text":"Whenever thing is created, things service will generate new create event. This event will have the following format: 1) \"1555334740911-0\" 2) 1) \"id\" 2) \"1c36273a-94ea-4802-84d6-a51de140112a\" 3) \"group_id\" 4) \"2c36273a-94ea-4802-84d6-a51de140112b\" 5) \"profile_id\" 6) \"3c36273a-94ea-4802-84d6-a51de140112c\" 7) \"operation\" 8) \"thing.create\" 9) \"name\" 10) \"d0\" 11) \"metadata\" 12) \"{}\" As you can see from this example, every odd field represents field name while every even field represents field value. This is standard event format for Redis Streams. If you want to extract metadata field from this event, you'll have to read it as string first and then you can deserialize it to some structured format.","title":"Thing create event"},{"location":"dev-guide/#thing-update-event","text":"Whenever thing instance is updated, things service will generate new update event. This event will have the following format: 1) \"1555336161544-0\" 2) 1) \"id\" 2) \"3c36273a-94ea-4802-84d6-a51de140112e\" 3) \"profile_id\" 4) \"3c36273a-94ea-4802-84d6-a51de140112c\" 5) \"operation\" 6) \"thing.update\" 7) \"name\" 8) \"weio\" Note that thing update event will contain only those fields that were updated using update endpoint.","title":"Thing update event"},{"location":"dev-guide/#thing-remove-event","text":"Whenever thing instance is removed from the system, things service will generate and publish new remove event. This event will have the following format: 1) 1) \"1555339313003-0\" 2) 1) \"id\" 2) \"3c36273a-94ea-4802-84d6-a51de140112e\" 3) \"operation\" 4) \"thing.remove\"","title":"Thing remove event"},{"location":"dev-guide/#profile-create-event","text":"Whenever profile instance is created, things service will generate and publish new create event. This event will have the following format: 1) \"1555334740918-0\" 2) 1) \"id\" 2) \"16fb2748-8d3b-4783-b272-bb5f4ad4d661\" 3) \"group_id\" 4) \"2c36273a-94ea-4802-84d6-a51de140112b\" 5) \"operation\" 6) \"profile.create\" 7) \"name\" 8) \"p1\"","title":"Profile create event"},{"location":"dev-guide/#profile-update-event","text":"Whenever profile instance is updated, things service will generate and publish new update event. This event will have the following format: 1) \"1555338870341-0\" 2) 1) \"id\" 2) \"d9d8f31b-f8d4-49c5-b943-6db10d8e2949\" 3) \"name\" 4) \"profile1\" 5) \"operation\" 6) \"profile.update\" Note that update profile event will contain only those fields that were updated using update profile endpoint.","title":"Profile update event"},{"location":"dev-guide/#profile-remove-event","text":"Whenever profile instance is removed from the system, things service will generate and publish new remove event. This event will have the following format: 1) 1) \"1555339429661-0\" 2) 1) \"id\" 2) \"d9d8f31b-f8d4-49c5-b943-6db10d8e2949\" 3) \"operation\" 4) \"profile.remove\" Note: Every one of these events will omit fields that were not used or are not relevant for specific operation. Also, field ordering is not guaranteed, so DO NOT rely on it.","title":"Profile remove event"},{"location":"dev-guide/#mqtt-adapter","text":"Instead of using heartbeat to know when client is connected through MQTT adapter one can fetch events from Redis Streams that MQTT adapter publishes. MQTT adapter publishes events every time client connects and disconnects to stream named mainflux.mqtt . Events that are coming from MQTT adapter have following fields: - thing_id ID of a thing that has connected to MQTT adapter, - timestamp is in Epoch UNIX Time Stamp format, - event_type can have two possible values, connect and disconnect, - instance represents MQTT adapter instance. If you want to integrate through docker-compose.yml you can use mainflux-es-redis service. Just connect to it and consume events from Redis Stream named mainflux.mqtt . Example of connect event: 1) 1) \"1555351214144-0\" 2) 1) \"thing_id\" 2) \"1c597a85-b68e-42ff-8ed8-a3a761884bc4\" 3) \"timestamp\" 4) \"1555351214\" 5) \"event_type\" 6) \"connect\" 7) \"instance\" 8) \"mqtt-adapter-1\" Example of disconnect event: 1) 1) \"1555351214188-0\" 2) 1) \"thing_id\" 2) \"1c597a85-b68e-42ff-8ed8-a3a761884bc4\" 3) \"timestamp\" 4) \"1555351214\" 5) \"event_type\" 6) \"disconnect\" 7) \"instance\" 8) \"mqtt-adapter-1\"","title":"MQTT Adapter"},{"location":"edge/","text":"Edge # Mainflux IoT platform provides services for supporting management of devices on the edge. Typically, IoT solution includes devices (sensors/actuators) deployed in far edge and connected through some proxy gateway. Although most devices could be connected to the Mainflux directly, using gateways decentralizes system, decreases load on the cloud and makes setup less difficult. Also, gateways can provide additional data processing, filtering and storage. Services that can be used on gateway to enable data and control plane for edge: Agent Export Mainflux Figure 1 - Edge services deployment Figure shows edge gateway that is running Agent, Export and minimal deployment of Mainflux services. Mainflux services enable device management and MQTT protocol, NATS being a central message bus in Mainflux becomes also central message bus for other services like Agent and Export as well as for any new custom developed service that can be built to interface with devices with any of hardware supported interfaces on the gateway, those services would publish data to NATS where Export service can pick them up and send to cloud. Agent can be used to control deployed services as well as to monitor their liveliness through subcribing to heartbeat NATS subject where services should publish their liveliness status, like Export service does. Agent # Agent is service that is used to manage gateways that are connected to Mainflux in cloud. It provides a way to send commands to gateway and receive response via mqtt. There are two types of channels used for Agent data and control . Over the control we are sending commands and receiving response from commands. Data collected from sensors connected to gateway are being sent over data channel. Agent is able to configure itself provided that bootstrap server is running, it will retrieve configuration from bootstrap server provided few arguments - external_id and external_key see bootstraping . Agent service has following features: * Remote execution of commands * Remote terminal, remote session to bash managed by Agent * Heartbeat - listening to NATS topic heartbeat.> it can remotely provide info on running services, if services are publishing heartbeat ( like Export ) * Proxying commands to other gateway services * Edgex SMA - remotely making requests to EdgeX endpoints and fetching results, if EdgeX is deployed. Run Agent # Before running agent we need to provision a thing and DATA and CONTROL channel. Thing that will be used as gateway representation and make bootstrap configuration. If using Mainflux UI this is done automatically when adding gateway through UI. Gateway can be provisioned with provision service. When you provisioned gateway as described in provision you can check results curl -s -S -X GET http://mainflux-domain.com:8202/things/bootstrap/<external_id> -H \"Authorization: Thing <external_key>\" -H 'Content-Type: application/json' |jq { \"mainflux_id\": \"e22c383a-d2ab-47c1-89cd-903955da993d\", \"mainflux_key\": \"fc987711-1828-461b-aa4b-16d5b2c642fe\", \"mainflux_channels\": [ { \"id\": \"fa5f9ba8-a1fc-4380-9edb-d0c23eaa24ec\", \"name\": \"control-channel\", \"metadata\": { \"type\": \"control\" } }, { \"id\": \"24e5473e-3cbe-43d9-8a8b-a725ff918c0e\", \"name\": \"data-channel\", \"metadata\": { \"type\": \"data\" } }, { \"id\": \"1eac45c2-0f72-4089-b255-ebd2e5732bbb\", \"name\": \"export-channel\", \"metadata\": { \"type\": \"export\" } } ], \"content\": \"{\\\"agent\\\":{\\\"edgex\\\":{\\\"url\\\":\\\"http://localhost:48090/api/v1/\\\"},\\\"heartbeat\\\":{\\\"interval\\\":\\\"30s\\\"},\\\"log\\\":{\\\"level\\\":\\\"debug\\\"},\\\"mqtt\\\":{\\\"mtls\\\":false,\\\"qos\\\":0,\\\"retain\\\":false,\\\"skip_tls_ver\\\":true,\\\"url\\\":\\\"tcp://mainflux-domain.com:1883\\\"},\\\"server\\\":{\\\"nats_url\\\":\\\"localhost:4222\\\",\\\"port\\\":\\\"9000\\\"},\\\"terminal\\\":{\\\"session_timeout\\\":\\\"30s\\\"}},\\\"export\\\":{\\\"exp\\\":{\\\"cache_db\\\":\\\"0\\\",\\\"cache_pass\\\":\\\"\\\",\\\"cache_url\\\":\\\"localhost:6379\\\",\\\"log_level\\\":\\\"debug\\\",\\\"nats\\\":\\\"nats://localhost:4222\\\",\\\"port\\\":\\\"8172\\\"},\\\"mqtt\\\":{\\\"ca_path\\\":\\\"ca.crt\\\",\\\"cert_path\\\":\\\"thing.crt\\\",\\\"channel\\\":\\\"\\\",\\\"host\\\":\\\"tcp://mainflux-domain.com:1883\\\",\\\"mtls\\\":false,\\\"password\\\":\\\"\\\",\\\"priv_key_path\\\":\\\"thing.key\\\",\\\"qos\\\":0,\\\"retain\\\":false,\\\"skip_tls_ver\\\":false,\\\"username\\\":\\\"\\\"},\\\"routes\\\":[{\\\"mqtt_topic\\\":\\\"\\\",\\\"nats_topic\\\":\\\"channels\\\",\\\"subtopic\\\":\\\"\\\",\\\"type\\\":\\\"mfx\\\",\\\"workers\\\":10},{\\\"mqtt_topic\\\":\\\"\\\",\\\"nats_topic\\\":\\\"export\\\",\\\"subtopic\\\":\\\"\\\",\\\"type\\\":\\\"default\\\",\\\"workers\\\":10}]}}\" } external_id is usually MAC address, but anything that suits applications requirements can be used external_key is key that will be provided to agent process thing_id is mainflux thing id channels is 2-element array where first channel is CONTROL and second is DATA, both channels should be assigned to thing content is used for configuring parameters of agent and export service. Then to start the agent service you can do it like this git clone https://github.com/MainfluxLabs/agent make cd build MF_AGENT_LOG_LEVEL=debug \\ MF_AGENT_BOOTSTRAP_KEY=edged \\ MF_AGENT_BOOTSTRAP_ID=34:e1:2d:e6:cf:03 ./mainflux-agent {\"level\":\"info\",\"message\":\"Requesting config for 34:e1:2d:e6:cf:03 from http://localhost:8202/things/bootstrap\",\"ts\":\"2019-12-05T04:47:24.98411512Z\"} {\"level\":\"info\",\"message\":\"Getting config for 34:e1:2d:e6:cf:03 from http://localhost:8202/things/bootstrap succeeded\",\"ts\":\"2019-12-05T04:47:24.995465239Z\"} {\"level\":\"info\",\"message\":\"Connected to MQTT broker\",\"ts\":\"2019-12-05T04:47:25.009645082Z\"} {\"level\":\"info\",\"message\":\"Agent service started, exposed port 9000\",\"ts\":\"2019-12-05T04:47:25.009755345Z\"} {\"level\":\"info\",\"message\":\"Subscribed to MQTT broker\",\"ts\":\"2019-12-05T04:47:25.012930443Z\"} MF_AGENT_BOOTSTRAP_KEY - is external_key in bootstrap configuration. MF_AGENT_BOOSTRAP_ID - is external_id in bootstrap configuration. Remote execution of commands via Agent # # Set connection parameters as environment variables in shell CH=`curl -s -S -X GET http://some-domain-name:8202/things/bootstrap/34:e1:2d:e6:cf:03 -H \"Authorization: edged\" -H 'Content-Type: application/json' | jq -r '.mainflux_channels[0].id'` TH=`curl -s -S -X GET http://some-domain-name:8202/things/bootstrap/34:e1:2d:e6:cf:03 -H \"Authorization: edged\" -H 'Content-Type: application/json' | jq -r .mainflux_id` KEY=`curl -s -S -X GET http://some-domain-name:8202/things/bootstrap/34:e1:2d:e6:cf:03 -H \"Authorization: edged\" -H 'Content-Type: application/json' | jq -r .mainflux_key` # Subscribe for response mosquitto_sub -d -u $TH -P $KEY -t channels/$CH/messages/res/# -h some-domain-name -p 1883 # Publish command e.g `ls` mosquitto_pub -d -u $TH -P $KEY -t channels/$CH/messages/req -h some-domain-name -p 1883 -m '[{\"bn\":\"1:\", \"n\":\"exec\", \"vs\":\"ls, -l\"}]' Remote terminal # This can be checked from the UI, click on the details for gateway and below the gateway parameters you will se box with prompt, if agent is running and it is properly connected you should be able to execute commands remotely. Heartbeat # If there are services that are running on same gateway as agent and they are publishing heartbeat to NATS subject heartbeat.service_name.service You can get the list of services by sending following mqtt message # View services that are sending heartbeat mosquitto_pub -d -u $TH -P $KEY -t channels/$CH/messages/req -h some-domain-name -p 1883 -m '[{\"bn\":\"1:\", \"n\":\"service\", \"vs\":\"view\"}]' Response can be observed on channels/$CH/messages/res/# Proxying commands # You can send commands to services running on the same edge gateway as Agent if they are subscribed on same NATS server and correct subject. Service commands are being sent via MQTT to topic: channels/<control_channel_id>/messages/services/<service_name>/<subtopic> when messages is received Agent forwards them to NATS on subject: commands.<service_name>.<subtopic> Payload is up to the application and service itself. EdgeX # Edgex control messages are sent and received over control channel. MF sends a control SenML of the following form: [{\"bn\":\"<uuid>:\", \"n\":\"control\", \"vs\":\"<cmd>, <param>, edgexsvc1, edgexsvc2, \u2026, edgexsvcN\"}}] For example, [{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"operation, stop, edgex-support-notifications, edgex-core-data\"}] Agent, on the other hand, returns a response SenML of the following form: [{\"bn\":\"<uuid>:\", \"n\":\"<>\", \"v\":\"<RESP>\"}] Remote Commands # EdgeX defines SMA commands in the following RAML file Commands are: OPERATION CONFIG METRICS PING Operation mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/req -h localhost -m '[{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-operation, start, edgex-support-notifications, edgex-core-data\"}]' Config mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/req -h localhost -m '[{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-config, edgex-support-notifications, edgex-core-data\"}]' Metrics mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/req -h localhost -m '[{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-metrics, edgex-support-notifications, edgex-core-data\"}]' If you subscribe to mosquitto_sub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/# You can observe commands and response from commands executed against edgex [{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-metrics, edgex-support-notifications, edgex-core-data\"}] [{\"bn\":\"1\",\"n\":\"edgex-metrics\",\"vs\":\"{\\\"Metrics\\\":{\\\"edgex-core-data\\\":{\\\"CpuBusyAvg\\\":15.568632467698606,\\\"Memory\\\":{\\\"Alloc\\\":2040136,\\\"Frees\\\":876344,\\\"LiveObjects\\\":15134,\\\"Mallocs\\\":891478,\\\"Sys\\\":73332984,\\\"TotalAlloc\\\":80657464}},\\\"edgex-support-notifications\\\":{\\\"CpuBusyAvg\\\":14.65381169745318,\\\"Memory\\\":{\\\"Alloc\\\":961784,\\\"Frees\\\":127430,\\\"LiveObjects\\\":6095,\\\"Mallocs\\\":133525,\\\"Sys\\\":72808696,\\\"TotalAlloc\\\":11665416}}}}\\n\"}] Export # Mainflux Export service can send message from one Mainflux cloud to another via MQTT, or it can send messages from edge gateway to Mainflux Cloud. Export service is subscribed to local message bus and connected to MQTT broker in the cloud. Messages collected on local message bus are redirected to the cloud. When connection is lost, if QoS2 is used, messages from the local bus are stored into file or in memory to be resent upon reconnection. Additonaly Export service publishes liveliness status to Agent via NATS subject heartbeat.export.service Install # Get the code: go get github.com/MainfluxLabs/export cd $GOPATH/github.com/MainfluxLabs/export Make: make Usage # cd build ./mainflux-export Configuration # By default Export service looks for config file at ../configs/config.toml if no env vars are specified. [exp] log_level = \"debug\" nats = \"localhost:4222\" port = \"8170\" [mqtt] username = \"<thing_id>\" password = \"<thing_password>\" ca_path = \"ca.crt\" client_cert = \"\" client_cert_key = \"\" client_cert_path = \"thing.crt\" client_priv_key_path = \"thing.key\" mtls = \"false\" priv_key = \"thing.key\" retain = \"false\" skip_tls_ver = \"false\" url = \"tcp://mainflux.com:1883\" [[routes]] mqtt_topic = \"channel/<channel_id>/messages\" subtopic = \"subtopic\" nats_topic = \"export\" type = \"default\" workers = 10 [[routes]] mqtt_topic = \"channel/<channel_id>/messages\" subtopic = \"subtopic\" nats_topic = \"channels\" type = \"mfx\" workers = 10 Environment variables # Service will first look for MF_EXPORT_CONFIG_FILE for configuration and if not found it will be configured with env variables and new config file specified with MF_EXPORT_CONFIG_FILE (default value will be used if none specified) will be saved with values populated from env vars. The service is configured using the environment variables as presented in the table. Note that any unset variables will be replaced with their default values. For values in environment variables to take effect make sure that there is no MF_EXPORT_CONFIG_FILE file. If you run with environment variables you can create config file: MF_EXPORT_PORT=8178 \\ MF_EXPORT_LOG_LEVEL=debug \\ MF_EXPORT_MQTT_HOST=tcp://localhost:1883 \\ MF_EXPORT_MQTT_USERNAME=<thing_id> \\ MF_EXPORT_MQTT_PASSWORD=<thing_key> \\ MF_EXPORT_MQTT_CHANNEL=<channel_id> \\ MF_EXPORT_MQTT_SKIP_TLS=true \\ MF_EXPORT_MQTT_MTLS=false \\ MF_EXPORT_MQTT_CA=ca.crt \\ MF_EXPORT_MQTT_CLIENT_CERT=thing.crt \\ MF_EXPORT_MQTT_CLIENT_PK=thing.key \\ MF_EXPORT_CONFIG_FILE=export.toml \\ ../build/mainflux-export& Values from environment variables will be used to populate export.toml Http port # port - HTTP port where status of Export service can be fetched. curl -X GET http://localhost:8170/health '{\"status\": \"pass\", \"version\":\"0.12.1\", \"commit\":\"57cca9677721025da055c47957fc3e869e0325aa\" , \"description\":\"export service\", \"build_time\": \"2022-01-19_10:13:17\"}' MQTT connection # To establish connection to MQTT broker following settings are needed: - username - Mainflux - password - Mainflux - url - url of MQTT broker Additionally, you will need MQTT client certificates if you enable mTLS. To obtain certificates ca.crt , thing.crt and key thing.key follow instructions here or here . MTLS # To setup MTLS connection Export service requires client certificate and mtls in config or MF_EXPORT_MQTT_MTLS must be set to true . Client certificate can be provided in a file, client_cert_path and client_cert_key_path are used for specifying path to certificate files. If MTLS is used and no certificate file paths are specified then Export will look in client_cert and client_cert_key of config file expecting certificate content stored as string. Routes # Routes are being used for specifying which subscriber's topic(subject) goes to which publishing topic. Currently only MQTT is supported for publishing. To match Mainflux requirements mqtt_topic must contain channel/<channel_id>/messages , additional subtopics can be appended. mqtt_topic - channel/<channel_id>/messages/<custom_subtopic> nats_topic - Export service will be subscribed to NATS subject <nats_topic>.> subtopic - messages will be published to MQTT topic <mqtt_topic>/<subtopic>/<nats_subject> , where dots in nats_subject are replaced with '/' workers - specifies number of workers that will be used for message forwarding. type - specifies message transformation: default is for sending messages as they are received on NATS with no transformation (so they should be in SenML or JSON format if we want to persist them in Mainflux in cloud). If you don't want to persist messages in Mainflux or you are not exporting to Mainflux cloud - message format can be anything that suits your application as message passes untransformed. mfx is for messages that are being picked up on internal Mainflux NATS bus. When using Export along with Mainflux deployed on gateway ( Fig. 1 ) messages coming from MQTT broker that are published to NATS bus are Mainflux message . Using mfx type will extract payload and export will publish it to mqtt_topic . Extracted payload is SenML or JSON if we want to persist messages. nats_topic in this case must be channels , or if you want to pick messages from a specific channel in local Mainflux instance to be exported to cloud you can put channels.<local_mainflux_channel_id> . Before running Export service edit configs/config.toml and provide username , password and url * username - matches thing_id in Mainflux cloud instance * password - matches thing_key * channel - MQTT part of the topic where to publish MQTT data ( channel/<channel_id>/messages is format of mainflux MQTT topic) and plays a part in authorization. If Mainflux and Export service are deployed on same gateway Export can be configured to send messages from Mainflux internal NATS bus to Mainflux in a cloud. In order for Export service to listen on Mainflux NATS deployed on the same machine NATS port must be exposed. Edit Mainflux docker-compose.yml . NATS section must look like below: nats: image: nats:1.3.0 container_name: mainflux-nats restart: on-failure networks: - mainflux-base-net ports: - 4222:4222 How to save config via agent # Configuration file for Export service can be sent over MQTT using Agent service. mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<control_ch_id>/messages/req -h localhost -p 18831 -m \"[{\\\"bn\\\":\\\"1:\\\", \\\"n\\\":\\\"config\\\", \\\"vs\\\":\\\"save, export, <config_file_path>, <file_content_base64>\\\"}]\" vs=\"save, export, config_file_path, file_content_base64\" - vs determines where to save file and contains file content in base64 encoding payload: b,_ := toml.Marshal(export.Config) payload := base64.StdEncoding.EncodeToString(b) Using configure script # There is a configuration.sh script in a scripts directory that can be used for automatic configuration and start up of remotely deployed export . For this to work it is presumed that mainflux-export and scripts/export_start are placed in executable path on remote device. Additionally this script requires that remote device is provisioned following the steps described for provision service. To run it first edit script to set parameters MTLS=false EXTERNAL_KEY='raspberry' EXTERNAL_ID='pi' MAINFLUX_HOST='mainflux.com' MAINFLUX_USER_EMAIL='edge@email.com' MAINFLUX_USER_PASSWORD='12345678' EXTERNAL_KEY and EXTERNAL_ID are parameters posted to /mapping endpoint of provision service, MAINFLUX_HOST is location of cloud instance of Mainflux that export should connect to and MAINFLUX_USER_EMAIL and MAINFLUX_USER_PASSWORD are users credentials in the cloud. Example deployment # Edge deployment # The following are steps that are an example usage of Mainflux components to connect edge with cloud. We will start Mainflux in the cloud with additional services Bootstrap and Provision . Using Bootstrap and Provision we will create a configuration for use in gateway deployment. On the gateway we will start services Agent and Export using previously created configuration. Services in the cloud # Start the Mainflux: docker-compose -f docker/docker-compose.yml up Create user: mainflux-cli -m http://localhost:8180 users create test@email.com 12345678 Obtain user token: mainflux-cli -m http://localhost:8180 users token test@email.com 12345678 created: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODk5MDQ4MDQsImlhdCI6MTU4OTg2ODgwNCwiaXNzIjoibWFpbmZsdXguYXV0aG4iLCJzdWIiOiJ0ZXN0QGVtYWlsLmNvbSIsInR5cGUiOjB9.VSwpGoflOLqrHlCGoVVFPBdnnvsAhv2gc3EomXg9yM0 TOK=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODk5MDQ4MDQsImlhdCI6MTU4OTg2ODgwNCwiaXNzIjoibWFpbmZsdXguYXV0aG4iLCJzdWIiOiJ0ZXN0QGVtYWlsLmNvbSIsInR5cGUiOjB9.VSwpGoflOLqrHlCGoVVFPBdnnvsAhv2gc3EomXg9yM0 Provision a gateway: curl -s -S -X POST http://localhost:8190/mapping -H \"Authorization: Bearer $TOKEN\" -H 'Content-Type: application/json' -d '{\"name\":\"testing\", \"external_id\" : \"54:FG:66:DC:43\", \"external_key\":\"223334fw2\" }' | jq { \"things\": [ { \"id\": \"88529fb2-6c1e-4b60-b9ab-73b5d89f7404\", \"name\": \"thing\", \"key\": \"3529c1bb-7211-4d40-9cd8-b05833196093\", \"metadata\": { \"external_id\": \"54:FG:66:DC:43\" } } ], \"channels\": [ { \"id\": \"1aa3f736-0bd3-44b5-a917-a72cc743f633\", \"name\": \"control-channel\", \"metadata\": { \"type\": \"control\" } }, { \"id\": \"e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce\", \"name\": \"data-channel\", \"metadata\": { \"type\": \"data\" } } ], \"whitelisted\": { \"88529fb2-6c1e-4b60-b9ab-73b5d89f7404\": true } } Parameters and are representing the gateway. Provision will use them to create a bootstrap configuration that will make a relation with Mainflux entities used for connection, authentication and authorization thing and channel . These parameters will be used by Agent service on the gateway to retrieve that information and establish a connection with the cloud. Services on the Edge # Agent # Start the [NATS][nats] and Agent service: gnatsd MF_AGENT_BOOTSTRAP_ID=54:FG:66:DC:43 \\ MF_AGENT_BOOTSTRAP_KEY=\"223334fw2\" \\ MF_AGENT_BOOTSTRAP_URL=http://localhost:8202/things/bootstrap \\ build/mainflux-agent {\"level\":\"info\",\"message\":\"Requesting config for 54:FG:66:DC:43 from http://localhost:8202/things/bootstrap\",\"ts\":\"2020-05-07T15:50:58.041145096Z\"} {\"level\":\"info\",\"message\":\"Getting config for 54:FG:66:DC:43 from http://localhost:8202/things/bootstrap succeeded\",\"ts\":\"2020-05-07T15:50:58.120779415Z\"} {\"level\":\"info\",\"message\":\"Saving export config file /configs/export/config.toml\",\"ts\":\"2020-05-07T15:50:58.121602229Z\"} {\"level\":\"warn\",\"message\":\"Failed to save export config file Error writing config file: open /configs/export/config.toml: no such file or directory\",\"ts\":\"2020-05-07T15:50:58.121752142Z\"} {\"level\":\"info\",\"message\":\"Client agent-88529fb2-6c1e-4b60-b9ab-73b5d89f7404 connected\",\"ts\":\"2020-05-07T15:50:58.128500603Z\"} {\"level\":\"info\",\"message\":\"Agent service started, exposed port 9003\",\"ts\":\"2020-05-07T15:50:58.128531057Z\"} Export # git clone https://github.com/MainfluxLabs/export make Edit the configs/config.toml setting - username - thing from the results of provision request. - password - key from the results of provision request. - mqtt_topic - in routes set to channels/<channel_data_id>/messages from results of provision. - nats_topic - whatever you need, export will subscribe to export.<nats_topic> and forward messages to MQTT. - host - url of MQTT broker. [exp] cache_pass = \"\" cache_url = \"\" log_level = \"debug\" nats = \"localhost:4222\" port = \"8170\" [mqtt] ca_path = \"\" cert_path = \"\" host = \"tcp://localhost:1883\" mtls = false password = \"3529c1bb-7211-4d40-9cd8-b05833196093\" priv_key_path = \"\" qos = 0 retain = false skip_tls_ver = false username = \"88529fb2-6c1e-4b60-b9ab-73b5d89f7404\" [[routes]] mqtt_topic = \"channels/e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce/messages\" nats_topic = \">\" workers = 10 cd build ./mainflux-export 2020/05/07 17:36:57 Configuration loaded from file ../configs/config.toml {\"level\":\"info\",\"message\":\"Export service started, exposed port :8170\",\"ts\":\"2020-05-07T15:36:57.528398548Z\"} {\"level\":\"debug\",\"message\":\"Client export-88529fb2-6c1e-4b60-b9ab-73b5d89f7404 connected\",\"ts\":\"2020-05-07T15:36:57.528405818Z\"} Testing Export # git clone https://github.com/nats-io/nats.go cd github.com/nats-io/nats.go/examples/nats-pub go run main.go -s http://localhost:4222 export.test \"[{\\\"bn\\\":\\\"test\\\"}]\"; We have configured route for export, nats_topic = \">\" means that it will listen to NATS subject export.> and mqtt_topic is configured so that data will be sent to MQTT broker on topic channels/e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce/messages with appended NATS subject. In terminal where export is started you should see following message: {\"level\":\"debug\",\"message\":\"Published to: export.test, payload: [{\\\"bn\\\":\\\"test\\\"}]\",\"ts\":\"2020-05-08T15:14:15.757298992Z\"} In Mainflux mqtt service: mainflux-mqtt | {\"level\":\"info\",\"message\":\"Publish - client ID export-88529fb2-6c1e-4b60-b9ab-73b5d89f7404 to the topic: channels/e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce/messages/export/test\",\"ts\":\"2020-05-08T15:16:02.999684791Z\"}","title":"Edge"},{"location":"edge/#edge","text":"Mainflux IoT platform provides services for supporting management of devices on the edge. Typically, IoT solution includes devices (sensors/actuators) deployed in far edge and connected through some proxy gateway. Although most devices could be connected to the Mainflux directly, using gateways decentralizes system, decreases load on the cloud and makes setup less difficult. Also, gateways can provide additional data processing, filtering and storage. Services that can be used on gateway to enable data and control plane for edge: Agent Export Mainflux Figure 1 - Edge services deployment Figure shows edge gateway that is running Agent, Export and minimal deployment of Mainflux services. Mainflux services enable device management and MQTT protocol, NATS being a central message bus in Mainflux becomes also central message bus for other services like Agent and Export as well as for any new custom developed service that can be built to interface with devices with any of hardware supported interfaces on the gateway, those services would publish data to NATS where Export service can pick them up and send to cloud. Agent can be used to control deployed services as well as to monitor their liveliness through subcribing to heartbeat NATS subject where services should publish their liveliness status, like Export service does.","title":"Edge"},{"location":"edge/#agent","text":"Agent is service that is used to manage gateways that are connected to Mainflux in cloud. It provides a way to send commands to gateway and receive response via mqtt. There are two types of channels used for Agent data and control . Over the control we are sending commands and receiving response from commands. Data collected from sensors connected to gateway are being sent over data channel. Agent is able to configure itself provided that bootstrap server is running, it will retrieve configuration from bootstrap server provided few arguments - external_id and external_key see bootstraping . Agent service has following features: * Remote execution of commands * Remote terminal, remote session to bash managed by Agent * Heartbeat - listening to NATS topic heartbeat.> it can remotely provide info on running services, if services are publishing heartbeat ( like Export ) * Proxying commands to other gateway services * Edgex SMA - remotely making requests to EdgeX endpoints and fetching results, if EdgeX is deployed.","title":"Agent"},{"location":"edge/#run-agent","text":"Before running agent we need to provision a thing and DATA and CONTROL channel. Thing that will be used as gateway representation and make bootstrap configuration. If using Mainflux UI this is done automatically when adding gateway through UI. Gateway can be provisioned with provision service. When you provisioned gateway as described in provision you can check results curl -s -S -X GET http://mainflux-domain.com:8202/things/bootstrap/<external_id> -H \"Authorization: Thing <external_key>\" -H 'Content-Type: application/json' |jq { \"mainflux_id\": \"e22c383a-d2ab-47c1-89cd-903955da993d\", \"mainflux_key\": \"fc987711-1828-461b-aa4b-16d5b2c642fe\", \"mainflux_channels\": [ { \"id\": \"fa5f9ba8-a1fc-4380-9edb-d0c23eaa24ec\", \"name\": \"control-channel\", \"metadata\": { \"type\": \"control\" } }, { \"id\": \"24e5473e-3cbe-43d9-8a8b-a725ff918c0e\", \"name\": \"data-channel\", \"metadata\": { \"type\": \"data\" } }, { \"id\": \"1eac45c2-0f72-4089-b255-ebd2e5732bbb\", \"name\": \"export-channel\", \"metadata\": { \"type\": \"export\" } } ], \"content\": \"{\\\"agent\\\":{\\\"edgex\\\":{\\\"url\\\":\\\"http://localhost:48090/api/v1/\\\"},\\\"heartbeat\\\":{\\\"interval\\\":\\\"30s\\\"},\\\"log\\\":{\\\"level\\\":\\\"debug\\\"},\\\"mqtt\\\":{\\\"mtls\\\":false,\\\"qos\\\":0,\\\"retain\\\":false,\\\"skip_tls_ver\\\":true,\\\"url\\\":\\\"tcp://mainflux-domain.com:1883\\\"},\\\"server\\\":{\\\"nats_url\\\":\\\"localhost:4222\\\",\\\"port\\\":\\\"9000\\\"},\\\"terminal\\\":{\\\"session_timeout\\\":\\\"30s\\\"}},\\\"export\\\":{\\\"exp\\\":{\\\"cache_db\\\":\\\"0\\\",\\\"cache_pass\\\":\\\"\\\",\\\"cache_url\\\":\\\"localhost:6379\\\",\\\"log_level\\\":\\\"debug\\\",\\\"nats\\\":\\\"nats://localhost:4222\\\",\\\"port\\\":\\\"8172\\\"},\\\"mqtt\\\":{\\\"ca_path\\\":\\\"ca.crt\\\",\\\"cert_path\\\":\\\"thing.crt\\\",\\\"channel\\\":\\\"\\\",\\\"host\\\":\\\"tcp://mainflux-domain.com:1883\\\",\\\"mtls\\\":false,\\\"password\\\":\\\"\\\",\\\"priv_key_path\\\":\\\"thing.key\\\",\\\"qos\\\":0,\\\"retain\\\":false,\\\"skip_tls_ver\\\":false,\\\"username\\\":\\\"\\\"},\\\"routes\\\":[{\\\"mqtt_topic\\\":\\\"\\\",\\\"nats_topic\\\":\\\"channels\\\",\\\"subtopic\\\":\\\"\\\",\\\"type\\\":\\\"mfx\\\",\\\"workers\\\":10},{\\\"mqtt_topic\\\":\\\"\\\",\\\"nats_topic\\\":\\\"export\\\",\\\"subtopic\\\":\\\"\\\",\\\"type\\\":\\\"default\\\",\\\"workers\\\":10}]}}\" } external_id is usually MAC address, but anything that suits applications requirements can be used external_key is key that will be provided to agent process thing_id is mainflux thing id channels is 2-element array where first channel is CONTROL and second is DATA, both channels should be assigned to thing content is used for configuring parameters of agent and export service. Then to start the agent service you can do it like this git clone https://github.com/MainfluxLabs/agent make cd build MF_AGENT_LOG_LEVEL=debug \\ MF_AGENT_BOOTSTRAP_KEY=edged \\ MF_AGENT_BOOTSTRAP_ID=34:e1:2d:e6:cf:03 ./mainflux-agent {\"level\":\"info\",\"message\":\"Requesting config for 34:e1:2d:e6:cf:03 from http://localhost:8202/things/bootstrap\",\"ts\":\"2019-12-05T04:47:24.98411512Z\"} {\"level\":\"info\",\"message\":\"Getting config for 34:e1:2d:e6:cf:03 from http://localhost:8202/things/bootstrap succeeded\",\"ts\":\"2019-12-05T04:47:24.995465239Z\"} {\"level\":\"info\",\"message\":\"Connected to MQTT broker\",\"ts\":\"2019-12-05T04:47:25.009645082Z\"} {\"level\":\"info\",\"message\":\"Agent service started, exposed port 9000\",\"ts\":\"2019-12-05T04:47:25.009755345Z\"} {\"level\":\"info\",\"message\":\"Subscribed to MQTT broker\",\"ts\":\"2019-12-05T04:47:25.012930443Z\"} MF_AGENT_BOOTSTRAP_KEY - is external_key in bootstrap configuration. MF_AGENT_BOOSTRAP_ID - is external_id in bootstrap configuration.","title":"Run Agent"},{"location":"edge/#remote-execution-of-commands-via-agent","text":"# Set connection parameters as environment variables in shell CH=`curl -s -S -X GET http://some-domain-name:8202/things/bootstrap/34:e1:2d:e6:cf:03 -H \"Authorization: edged\" -H 'Content-Type: application/json' | jq -r '.mainflux_channels[0].id'` TH=`curl -s -S -X GET http://some-domain-name:8202/things/bootstrap/34:e1:2d:e6:cf:03 -H \"Authorization: edged\" -H 'Content-Type: application/json' | jq -r .mainflux_id` KEY=`curl -s -S -X GET http://some-domain-name:8202/things/bootstrap/34:e1:2d:e6:cf:03 -H \"Authorization: edged\" -H 'Content-Type: application/json' | jq -r .mainflux_key` # Subscribe for response mosquitto_sub -d -u $TH -P $KEY -t channels/$CH/messages/res/# -h some-domain-name -p 1883 # Publish command e.g `ls` mosquitto_pub -d -u $TH -P $KEY -t channels/$CH/messages/req -h some-domain-name -p 1883 -m '[{\"bn\":\"1:\", \"n\":\"exec\", \"vs\":\"ls, -l\"}]'","title":"Remote execution of commands via Agent"},{"location":"edge/#remote-terminal","text":"This can be checked from the UI, click on the details for gateway and below the gateway parameters you will se box with prompt, if agent is running and it is properly connected you should be able to execute commands remotely.","title":"Remote terminal"},{"location":"edge/#heartbeat","text":"If there are services that are running on same gateway as agent and they are publishing heartbeat to NATS subject heartbeat.service_name.service You can get the list of services by sending following mqtt message # View services that are sending heartbeat mosquitto_pub -d -u $TH -P $KEY -t channels/$CH/messages/req -h some-domain-name -p 1883 -m '[{\"bn\":\"1:\", \"n\":\"service\", \"vs\":\"view\"}]' Response can be observed on channels/$CH/messages/res/#","title":"Heartbeat"},{"location":"edge/#proxying-commands","text":"You can send commands to services running on the same edge gateway as Agent if they are subscribed on same NATS server and correct subject. Service commands are being sent via MQTT to topic: channels/<control_channel_id>/messages/services/<service_name>/<subtopic> when messages is received Agent forwards them to NATS on subject: commands.<service_name>.<subtopic> Payload is up to the application and service itself.","title":"Proxying commands"},{"location":"edge/#edgex","text":"Edgex control messages are sent and received over control channel. MF sends a control SenML of the following form: [{\"bn\":\"<uuid>:\", \"n\":\"control\", \"vs\":\"<cmd>, <param>, edgexsvc1, edgexsvc2, \u2026, edgexsvcN\"}}] For example, [{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"operation, stop, edgex-support-notifications, edgex-core-data\"}] Agent, on the other hand, returns a response SenML of the following form: [{\"bn\":\"<uuid>:\", \"n\":\"<>\", \"v\":\"<RESP>\"}]","title":"EdgeX"},{"location":"edge/#remote-commands","text":"EdgeX defines SMA commands in the following RAML file Commands are: OPERATION CONFIG METRICS PING Operation mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/req -h localhost -m '[{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-operation, start, edgex-support-notifications, edgex-core-data\"}]' Config mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/req -h localhost -m '[{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-config, edgex-support-notifications, edgex-core-data\"}]' Metrics mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/req -h localhost -m '[{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-metrics, edgex-support-notifications, edgex-core-data\"}]' If you subscribe to mosquitto_sub -u <thing_id> -P <thing_key> -t channels/<channel_id>/messages/# You can observe commands and response from commands executed against edgex [{\"bn\":\"1:\", \"n\":\"control\", \"vs\":\"edgex-metrics, edgex-support-notifications, edgex-core-data\"}] [{\"bn\":\"1\",\"n\":\"edgex-metrics\",\"vs\":\"{\\\"Metrics\\\":{\\\"edgex-core-data\\\":{\\\"CpuBusyAvg\\\":15.568632467698606,\\\"Memory\\\":{\\\"Alloc\\\":2040136,\\\"Frees\\\":876344,\\\"LiveObjects\\\":15134,\\\"Mallocs\\\":891478,\\\"Sys\\\":73332984,\\\"TotalAlloc\\\":80657464}},\\\"edgex-support-notifications\\\":{\\\"CpuBusyAvg\\\":14.65381169745318,\\\"Memory\\\":{\\\"Alloc\\\":961784,\\\"Frees\\\":127430,\\\"LiveObjects\\\":6095,\\\"Mallocs\\\":133525,\\\"Sys\\\":72808696,\\\"TotalAlloc\\\":11665416}}}}\\n\"}]","title":"Remote Commands"},{"location":"edge/#export","text":"Mainflux Export service can send message from one Mainflux cloud to another via MQTT, or it can send messages from edge gateway to Mainflux Cloud. Export service is subscribed to local message bus and connected to MQTT broker in the cloud. Messages collected on local message bus are redirected to the cloud. When connection is lost, if QoS2 is used, messages from the local bus are stored into file or in memory to be resent upon reconnection. Additonaly Export service publishes liveliness status to Agent via NATS subject heartbeat.export.service","title":"Export"},{"location":"edge/#install","text":"Get the code: go get github.com/MainfluxLabs/export cd $GOPATH/github.com/MainfluxLabs/export Make: make","title":"Install"},{"location":"edge/#usage","text":"cd build ./mainflux-export","title":"Usage"},{"location":"edge/#configuration","text":"By default Export service looks for config file at ../configs/config.toml if no env vars are specified. [exp] log_level = \"debug\" nats = \"localhost:4222\" port = \"8170\" [mqtt] username = \"<thing_id>\" password = \"<thing_password>\" ca_path = \"ca.crt\" client_cert = \"\" client_cert_key = \"\" client_cert_path = \"thing.crt\" client_priv_key_path = \"thing.key\" mtls = \"false\" priv_key = \"thing.key\" retain = \"false\" skip_tls_ver = \"false\" url = \"tcp://mainflux.com:1883\" [[routes]] mqtt_topic = \"channel/<channel_id>/messages\" subtopic = \"subtopic\" nats_topic = \"export\" type = \"default\" workers = 10 [[routes]] mqtt_topic = \"channel/<channel_id>/messages\" subtopic = \"subtopic\" nats_topic = \"channels\" type = \"mfx\" workers = 10","title":"Configuration"},{"location":"edge/#environment-variables","text":"Service will first look for MF_EXPORT_CONFIG_FILE for configuration and if not found it will be configured with env variables and new config file specified with MF_EXPORT_CONFIG_FILE (default value will be used if none specified) will be saved with values populated from env vars. The service is configured using the environment variables as presented in the table. Note that any unset variables will be replaced with their default values. For values in environment variables to take effect make sure that there is no MF_EXPORT_CONFIG_FILE file. If you run with environment variables you can create config file: MF_EXPORT_PORT=8178 \\ MF_EXPORT_LOG_LEVEL=debug \\ MF_EXPORT_MQTT_HOST=tcp://localhost:1883 \\ MF_EXPORT_MQTT_USERNAME=<thing_id> \\ MF_EXPORT_MQTT_PASSWORD=<thing_key> \\ MF_EXPORT_MQTT_CHANNEL=<channel_id> \\ MF_EXPORT_MQTT_SKIP_TLS=true \\ MF_EXPORT_MQTT_MTLS=false \\ MF_EXPORT_MQTT_CA=ca.crt \\ MF_EXPORT_MQTT_CLIENT_CERT=thing.crt \\ MF_EXPORT_MQTT_CLIENT_PK=thing.key \\ MF_EXPORT_CONFIG_FILE=export.toml \\ ../build/mainflux-export& Values from environment variables will be used to populate export.toml","title":"Environment variables"},{"location":"edge/#http-port","text":"port - HTTP port where status of Export service can be fetched. curl -X GET http://localhost:8170/health '{\"status\": \"pass\", \"version\":\"0.12.1\", \"commit\":\"57cca9677721025da055c47957fc3e869e0325aa\" , \"description\":\"export service\", \"build_time\": \"2022-01-19_10:13:17\"}'","title":"Http port"},{"location":"edge/#mqtt-connection","text":"To establish connection to MQTT broker following settings are needed: - username - Mainflux - password - Mainflux - url - url of MQTT broker Additionally, you will need MQTT client certificates if you enable mTLS. To obtain certificates ca.crt , thing.crt and key thing.key follow instructions here or here .","title":"MQTT connection"},{"location":"edge/#mtls","text":"To setup MTLS connection Export service requires client certificate and mtls in config or MF_EXPORT_MQTT_MTLS must be set to true . Client certificate can be provided in a file, client_cert_path and client_cert_key_path are used for specifying path to certificate files. If MTLS is used and no certificate file paths are specified then Export will look in client_cert and client_cert_key of config file expecting certificate content stored as string.","title":"MTLS"},{"location":"edge/#routes","text":"Routes are being used for specifying which subscriber's topic(subject) goes to which publishing topic. Currently only MQTT is supported for publishing. To match Mainflux requirements mqtt_topic must contain channel/<channel_id>/messages , additional subtopics can be appended. mqtt_topic - channel/<channel_id>/messages/<custom_subtopic> nats_topic - Export service will be subscribed to NATS subject <nats_topic>.> subtopic - messages will be published to MQTT topic <mqtt_topic>/<subtopic>/<nats_subject> , where dots in nats_subject are replaced with '/' workers - specifies number of workers that will be used for message forwarding. type - specifies message transformation: default is for sending messages as they are received on NATS with no transformation (so they should be in SenML or JSON format if we want to persist them in Mainflux in cloud). If you don't want to persist messages in Mainflux or you are not exporting to Mainflux cloud - message format can be anything that suits your application as message passes untransformed. mfx is for messages that are being picked up on internal Mainflux NATS bus. When using Export along with Mainflux deployed on gateway ( Fig. 1 ) messages coming from MQTT broker that are published to NATS bus are Mainflux message . Using mfx type will extract payload and export will publish it to mqtt_topic . Extracted payload is SenML or JSON if we want to persist messages. nats_topic in this case must be channels , or if you want to pick messages from a specific channel in local Mainflux instance to be exported to cloud you can put channels.<local_mainflux_channel_id> . Before running Export service edit configs/config.toml and provide username , password and url * username - matches thing_id in Mainflux cloud instance * password - matches thing_key * channel - MQTT part of the topic where to publish MQTT data ( channel/<channel_id>/messages is format of mainflux MQTT topic) and plays a part in authorization. If Mainflux and Export service are deployed on same gateway Export can be configured to send messages from Mainflux internal NATS bus to Mainflux in a cloud. In order for Export service to listen on Mainflux NATS deployed on the same machine NATS port must be exposed. Edit Mainflux docker-compose.yml . NATS section must look like below: nats: image: nats:1.3.0 container_name: mainflux-nats restart: on-failure networks: - mainflux-base-net ports: - 4222:4222","title":"Routes"},{"location":"edge/#how-to-save-config-via-agent","text":"Configuration file for Export service can be sent over MQTT using Agent service. mosquitto_pub -u <thing_id> -P <thing_key> -t channels/<control_ch_id>/messages/req -h localhost -p 18831 -m \"[{\\\"bn\\\":\\\"1:\\\", \\\"n\\\":\\\"config\\\", \\\"vs\\\":\\\"save, export, <config_file_path>, <file_content_base64>\\\"}]\" vs=\"save, export, config_file_path, file_content_base64\" - vs determines where to save file and contains file content in base64 encoding payload: b,_ := toml.Marshal(export.Config) payload := base64.StdEncoding.EncodeToString(b)","title":"How to save config via agent"},{"location":"edge/#using-configure-script","text":"There is a configuration.sh script in a scripts directory that can be used for automatic configuration and start up of remotely deployed export . For this to work it is presumed that mainflux-export and scripts/export_start are placed in executable path on remote device. Additionally this script requires that remote device is provisioned following the steps described for provision service. To run it first edit script to set parameters MTLS=false EXTERNAL_KEY='raspberry' EXTERNAL_ID='pi' MAINFLUX_HOST='mainflux.com' MAINFLUX_USER_EMAIL='edge@email.com' MAINFLUX_USER_PASSWORD='12345678' EXTERNAL_KEY and EXTERNAL_ID are parameters posted to /mapping endpoint of provision service, MAINFLUX_HOST is location of cloud instance of Mainflux that export should connect to and MAINFLUX_USER_EMAIL and MAINFLUX_USER_PASSWORD are users credentials in the cloud.","title":"Using configure script"},{"location":"edge/#example-deployment","text":"","title":"Example deployment"},{"location":"edge/#edge-deployment","text":"The following are steps that are an example usage of Mainflux components to connect edge with cloud. We will start Mainflux in the cloud with additional services Bootstrap and Provision . Using Bootstrap and Provision we will create a configuration for use in gateway deployment. On the gateway we will start services Agent and Export using previously created configuration.","title":"Edge deployment"},{"location":"edge/#services-in-the-cloud","text":"Start the Mainflux: docker-compose -f docker/docker-compose.yml up Create user: mainflux-cli -m http://localhost:8180 users create test@email.com 12345678 Obtain user token: mainflux-cli -m http://localhost:8180 users token test@email.com 12345678 created: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODk5MDQ4MDQsImlhdCI6MTU4OTg2ODgwNCwiaXNzIjoibWFpbmZsdXguYXV0aG4iLCJzdWIiOiJ0ZXN0QGVtYWlsLmNvbSIsInR5cGUiOjB9.VSwpGoflOLqrHlCGoVVFPBdnnvsAhv2gc3EomXg9yM0 TOK=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1ODk5MDQ4MDQsImlhdCI6MTU4OTg2ODgwNCwiaXNzIjoibWFpbmZsdXguYXV0aG4iLCJzdWIiOiJ0ZXN0QGVtYWlsLmNvbSIsInR5cGUiOjB9.VSwpGoflOLqrHlCGoVVFPBdnnvsAhv2gc3EomXg9yM0 Provision a gateway: curl -s -S -X POST http://localhost:8190/mapping -H \"Authorization: Bearer $TOKEN\" -H 'Content-Type: application/json' -d '{\"name\":\"testing\", \"external_id\" : \"54:FG:66:DC:43\", \"external_key\":\"223334fw2\" }' | jq { \"things\": [ { \"id\": \"88529fb2-6c1e-4b60-b9ab-73b5d89f7404\", \"name\": \"thing\", \"key\": \"3529c1bb-7211-4d40-9cd8-b05833196093\", \"metadata\": { \"external_id\": \"54:FG:66:DC:43\" } } ], \"channels\": [ { \"id\": \"1aa3f736-0bd3-44b5-a917-a72cc743f633\", \"name\": \"control-channel\", \"metadata\": { \"type\": \"control\" } }, { \"id\": \"e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce\", \"name\": \"data-channel\", \"metadata\": { \"type\": \"data\" } } ], \"whitelisted\": { \"88529fb2-6c1e-4b60-b9ab-73b5d89f7404\": true } } Parameters and are representing the gateway. Provision will use them to create a bootstrap configuration that will make a relation with Mainflux entities used for connection, authentication and authorization thing and channel . These parameters will be used by Agent service on the gateway to retrieve that information and establish a connection with the cloud.","title":"Services in the cloud"},{"location":"edge/#services-on-the-edge","text":"","title":"Services on the Edge"},{"location":"edge/#agent_1","text":"Start the [NATS][nats] and Agent service: gnatsd MF_AGENT_BOOTSTRAP_ID=54:FG:66:DC:43 \\ MF_AGENT_BOOTSTRAP_KEY=\"223334fw2\" \\ MF_AGENT_BOOTSTRAP_URL=http://localhost:8202/things/bootstrap \\ build/mainflux-agent {\"level\":\"info\",\"message\":\"Requesting config for 54:FG:66:DC:43 from http://localhost:8202/things/bootstrap\",\"ts\":\"2020-05-07T15:50:58.041145096Z\"} {\"level\":\"info\",\"message\":\"Getting config for 54:FG:66:DC:43 from http://localhost:8202/things/bootstrap succeeded\",\"ts\":\"2020-05-07T15:50:58.120779415Z\"} {\"level\":\"info\",\"message\":\"Saving export config file /configs/export/config.toml\",\"ts\":\"2020-05-07T15:50:58.121602229Z\"} {\"level\":\"warn\",\"message\":\"Failed to save export config file Error writing config file: open /configs/export/config.toml: no such file or directory\",\"ts\":\"2020-05-07T15:50:58.121752142Z\"} {\"level\":\"info\",\"message\":\"Client agent-88529fb2-6c1e-4b60-b9ab-73b5d89f7404 connected\",\"ts\":\"2020-05-07T15:50:58.128500603Z\"} {\"level\":\"info\",\"message\":\"Agent service started, exposed port 9003\",\"ts\":\"2020-05-07T15:50:58.128531057Z\"}","title":"Agent"},{"location":"edge/#export_1","text":"git clone https://github.com/MainfluxLabs/export make Edit the configs/config.toml setting - username - thing from the results of provision request. - password - key from the results of provision request. - mqtt_topic - in routes set to channels/<channel_data_id>/messages from results of provision. - nats_topic - whatever you need, export will subscribe to export.<nats_topic> and forward messages to MQTT. - host - url of MQTT broker. [exp] cache_pass = \"\" cache_url = \"\" log_level = \"debug\" nats = \"localhost:4222\" port = \"8170\" [mqtt] ca_path = \"\" cert_path = \"\" host = \"tcp://localhost:1883\" mtls = false password = \"3529c1bb-7211-4d40-9cd8-b05833196093\" priv_key_path = \"\" qos = 0 retain = false skip_tls_ver = false username = \"88529fb2-6c1e-4b60-b9ab-73b5d89f7404\" [[routes]] mqtt_topic = \"channels/e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce/messages\" nats_topic = \">\" workers = 10 cd build ./mainflux-export 2020/05/07 17:36:57 Configuration loaded from file ../configs/config.toml {\"level\":\"info\",\"message\":\"Export service started, exposed port :8170\",\"ts\":\"2020-05-07T15:36:57.528398548Z\"} {\"level\":\"debug\",\"message\":\"Client export-88529fb2-6c1e-4b60-b9ab-73b5d89f7404 connected\",\"ts\":\"2020-05-07T15:36:57.528405818Z\"}","title":"Export"},{"location":"edge/#testing-export","text":"git clone https://github.com/nats-io/nats.go cd github.com/nats-io/nats.go/examples/nats-pub go run main.go -s http://localhost:4222 export.test \"[{\\\"bn\\\":\\\"test\\\"}]\"; We have configured route for export, nats_topic = \">\" means that it will listen to NATS subject export.> and mqtt_topic is configured so that data will be sent to MQTT broker on topic channels/e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce/messages with appended NATS subject. In terminal where export is started you should see following message: {\"level\":\"debug\",\"message\":\"Published to: export.test, payload: [{\\\"bn\\\":\\\"test\\\"}]\",\"ts\":\"2020-05-08T15:14:15.757298992Z\"} In Mainflux mqtt service: mainflux-mqtt | {\"level\":\"info\",\"message\":\"Publish - client ID export-88529fb2-6c1e-4b60-b9ab-73b5d89f7404 to the topic: channels/e2adcfa6-96b2-425d-8cd4-ff8cb9c056ce/messages/export/test\",\"ts\":\"2020-05-08T15:16:02.999684791Z\"}","title":"Testing Export"},{"location":"enterprise/","text":"Enterprise # These services are exclusively available to users with a premium subscription . If you'd like to learn more or activate these services, please contact us at infos@mainflux.com . Downlinks # The Downlink service enables the integration of data from different platforms/services into Mainflux. In a situation where certain platforms do not have a way to send data via Webhook or in some other way, then the Downlink service comes to the rescue. The Downlink service provides data retrieval from certain services for a previously defined frequency. Downlink configuration offers the possibility of getting data for different frequencies, which are minutely, hourly, daily, and weekly. In addition to frequency-defined recurring fetches, it is possible to fetch one-time data for a specific date and time in the future. Downlink service supports retrieval data in JSON and XML format. Note: Detailed API documentation is available to users with a premium plan. Filestore # The Filestore Service provides secure File storage for both individual devices (Things) and Groups. This service allows you to upload, update, view, list, and delete Files associated with Things or Groups in a structured and efficient manner. Key Features: * Thing-Specific File Management: Store and manage Files tied to individual Things. * Group-Specific File Management: Manage Files shared across device Groups. The Filestore Service is useful for storing configuration files or logs for individual devices, ensuring easy access and updates. It also facilitates sharing firmware updates or other files across multiple devices within a Group, streamlining Group File management. Note: Detailed API documentation is available to users with a premium plan.","title":"Enterprise"},{"location":"enterprise/#enterprise","text":"These services are exclusively available to users with a premium subscription . If you'd like to learn more or activate these services, please contact us at infos@mainflux.com .","title":"Enterprise"},{"location":"enterprise/#downlinks","text":"The Downlink service enables the integration of data from different platforms/services into Mainflux. In a situation where certain platforms do not have a way to send data via Webhook or in some other way, then the Downlink service comes to the rescue. The Downlink service provides data retrieval from certain services for a previously defined frequency. Downlink configuration offers the possibility of getting data for different frequencies, which are minutely, hourly, daily, and weekly. In addition to frequency-defined recurring fetches, it is possible to fetch one-time data for a specific date and time in the future. Downlink service supports retrieval data in JSON and XML format. Note: Detailed API documentation is available to users with a premium plan.","title":"Downlinks"},{"location":"enterprise/#filestore","text":"The Filestore Service provides secure File storage for both individual devices (Things) and Groups. This service allows you to upload, update, view, list, and delete Files associated with Things or Groups in a structured and efficient manner. Key Features: * Thing-Specific File Management: Store and manage Files tied to individual Things. * Group-Specific File Management: Manage Files shared across device Groups. The Filestore Service is useful for storing configuration files or logs for individual devices, ensuring easy access and updates. It also facilitates sharing firmware updates or other files across multiple devices within a Group, streamlining Group File management. Note: Detailed API documentation is available to users with a premium plan.","title":"Filestore"},{"location":"getting-started/","text":"Getting Started # Step 1 - Run the System # Before proceeding, install the following prerequisites: Docker (version 24.0.7) Docker compose (version 2.23.3) Once everything is installed, execute the following command from project root: make run This will start Mainflux docker composition, which will output the logs from the containers. Step 2 - Install the CLI # Open a new terminal from which you can interact with the running Mainflux system. The easiest way to do this is by using the Mainflux CLI, which can be downloaded as a tarball from GitHub (here we use release 0.12.1 but be sure to use the latest CLI release ): wget -O- https://github.com/MainfluxLabs/mainflux/releases/download/0.12.1/mainflux-cli_0.12.1_linux-amd64.tar.gz | tar xvz -C $GOBIN Make sure that $GOBIN is added to your $PATH so that mainflux-cli command can be accessible system-wide Build mainflux-cli # Build mainflux-cli if the pre-built CLI is not compatible with your OS, i.e MacOS. Please see the CLI for further details. Step 3 - Provision the System # Once installed, you can use the CLI to quick-provision the system for testing: mainflux-cli provision test This command actually creates a temporary testing user, logs it in, then creates two things and two profiles on behalf of this user. This quickly provisions a Mainflux system with one simple testing scenario. Output of the command follows this pattern: { \"email\": \"friendly_beaver@email.com\", \"password\": \"12345678\" } \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NDcwMjE3ODAsImlhdCI6MTU0Njk4NTc4MCwiaXNzIjoibWFpbmZsdXgiLCJzdWIiOiJmcmllbmRseV9iZWF2ZXJAZW1haWwuY29tIn0.Tyk31Ae680KqMrDqP895PRZg_GUytLE0IMIR_o3oO7o\" [ { \"id\": \"b7bfc4b6-c18d-47c5-b343-98235c5acc19\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"name\": \"p0\" }, { \"id\": \"378678cd-891b-4a39-b026-869938783f54\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"name\": \"p1\" } ] [ { \"id\": \"513d02d2-16c1-4f23-98be-9e12f8fee898\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"profile_id\":\"b7bfc4b6-c18d-47c5-b343-98235c5acc19\", \"key\": \"69590b3a-9d76-4baa-adae-9b5fec0ea14f\", \"name\": \"d0\", }, { \"id\": \"bf78ca98-2fef-4cfc-9f26-e02da5ecdf67\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"profile_id\":\"378678cd-891b-4a39-b026-869938783f54\", \"key\": \"840c1ea1-2e8d-4809-a6d3-3433a5c489d2\", \"name\": \"d1\", } ] In the Mainflux system terminal (where docker compose is running) you should see following logs: mainflux-users | {\"level\":\"info\",\"message\":\"Method register for user friendly_beaver@email.com took 97.573974ms to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.745989495Z\"} mainflux-users | {\"level\":\"info\",\"message\":\"Method login for user friendly_beaver@email.com took 69.308406ms to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.820610461Z\"} mainflux-users | {\"level\":\"info\",\"message\":\"Method identity for client friendly_beaver@email.com took 50.903\u00b5s to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.822208948Z\"} mainflux-things | {\"level\":\"info\",\"message\":\"Method create_things for things [{513d02d2-16c1-4f23-98be-9e12f8fee898 737d2200-64a1-482f-839d-64906b0bd80e b7bfc4b6-c18d-47c5-b343-98235c5acc19 d0 69590b3a-9d76-4baa-adae-9b5fec0ea14f map[]},{bf78ca98-2fef-4cfc-9f26-e02da5ecdf67 737d2200-64a1-482f-839d-64906b0bd80e 378678cd-891b-4a39-b026-869938783f54 d1 840c1ea1-2e8d-4809-a6d3-3433a5c489d2 map[]}] took 4.865299ms to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.826786175Z\"} ... This proves that these provisioning commands were sent from the CLI to the Mainflux system. Step 4 - Send Messages # Once system is provisioned, a thing can start sending messages: mainflux-cli messages send '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' <thing_key> For example: mainflux-cli messages send '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' 69590b3a-9d76-4baa-adae-9b5fec0ea14f In the Mainflux system terminal you should see following logs: mainflux-things | {\"level\":\"info\",\"message\":\"Method get_pub_conf_by_key for thing 513d02d2-16c1-4f23-98be-9e12f8fee898 took 1.410194ms to complete without errors.\",\"ts\":\"2019-01-08T22:19:30.148097648Z\"} mainflux-http | {\"level\":\"info\",\"message\":\"Method publish took 336.685\u00b5s to complete without errors.\",\"ts\":\"2019-01-08T22:19:30.148689601Z\"} This proves that messages have been correctly sent through the system via the protocol adapter ( mainflux-http ).","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#step-1-run-the-system","text":"Before proceeding, install the following prerequisites: Docker (version 24.0.7) Docker compose (version 2.23.3) Once everything is installed, execute the following command from project root: make run This will start Mainflux docker composition, which will output the logs from the containers.","title":"Step 1 - Run the System"},{"location":"getting-started/#step-2-install-the-cli","text":"Open a new terminal from which you can interact with the running Mainflux system. The easiest way to do this is by using the Mainflux CLI, which can be downloaded as a tarball from GitHub (here we use release 0.12.1 but be sure to use the latest CLI release ): wget -O- https://github.com/MainfluxLabs/mainflux/releases/download/0.12.1/mainflux-cli_0.12.1_linux-amd64.tar.gz | tar xvz -C $GOBIN Make sure that $GOBIN is added to your $PATH so that mainflux-cli command can be accessible system-wide","title":"Step 2 - Install the CLI"},{"location":"getting-started/#build-mainflux-cli","text":"Build mainflux-cli if the pre-built CLI is not compatible with your OS, i.e MacOS. Please see the CLI for further details.","title":"Build mainflux-cli"},{"location":"getting-started/#step-3-provision-the-system","text":"Once installed, you can use the CLI to quick-provision the system for testing: mainflux-cli provision test This command actually creates a temporary testing user, logs it in, then creates two things and two profiles on behalf of this user. This quickly provisions a Mainflux system with one simple testing scenario. Output of the command follows this pattern: { \"email\": \"friendly_beaver@email.com\", \"password\": \"12345678\" } \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NDcwMjE3ODAsImlhdCI6MTU0Njk4NTc4MCwiaXNzIjoibWFpbmZsdXgiLCJzdWIiOiJmcmllbmRseV9iZWF2ZXJAZW1haWwuY29tIn0.Tyk31Ae680KqMrDqP895PRZg_GUytLE0IMIR_o3oO7o\" [ { \"id\": \"b7bfc4b6-c18d-47c5-b343-98235c5acc19\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"name\": \"p0\" }, { \"id\": \"378678cd-891b-4a39-b026-869938783f54\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"name\": \"p1\" } ] [ { \"id\": \"513d02d2-16c1-4f23-98be-9e12f8fee898\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"profile_id\":\"b7bfc4b6-c18d-47c5-b343-98235c5acc19\", \"key\": \"69590b3a-9d76-4baa-adae-9b5fec0ea14f\", \"name\": \"d0\", }, { \"id\": \"bf78ca98-2fef-4cfc-9f26-e02da5ecdf67\", \"group_id\":\"737d2200-64a1-482f-839d-64906b0bd80e\", \"profile_id\":\"378678cd-891b-4a39-b026-869938783f54\", \"key\": \"840c1ea1-2e8d-4809-a6d3-3433a5c489d2\", \"name\": \"d1\", } ] In the Mainflux system terminal (where docker compose is running) you should see following logs: mainflux-users | {\"level\":\"info\",\"message\":\"Method register for user friendly_beaver@email.com took 97.573974ms to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.745989495Z\"} mainflux-users | {\"level\":\"info\",\"message\":\"Method login for user friendly_beaver@email.com took 69.308406ms to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.820610461Z\"} mainflux-users | {\"level\":\"info\",\"message\":\"Method identity for client friendly_beaver@email.com took 50.903\u00b5s to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.822208948Z\"} mainflux-things | {\"level\":\"info\",\"message\":\"Method create_things for things [{513d02d2-16c1-4f23-98be-9e12f8fee898 737d2200-64a1-482f-839d-64906b0bd80e b7bfc4b6-c18d-47c5-b343-98235c5acc19 d0 69590b3a-9d76-4baa-adae-9b5fec0ea14f map[]},{bf78ca98-2fef-4cfc-9f26-e02da5ecdf67 737d2200-64a1-482f-839d-64906b0bd80e 378678cd-891b-4a39-b026-869938783f54 d1 840c1ea1-2e8d-4809-a6d3-3433a5c489d2 map[]}] took 4.865299ms to complete without errors.\",\"ts\":\"2019-01-08T22:16:20.826786175Z\"} ... This proves that these provisioning commands were sent from the CLI to the Mainflux system.","title":"Step 3 - Provision the System"},{"location":"getting-started/#step-4-send-messages","text":"Once system is provisioned, a thing can start sending messages: mainflux-cli messages send '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' <thing_key> For example: mainflux-cli messages send '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' 69590b3a-9d76-4baa-adae-9b5fec0ea14f In the Mainflux system terminal you should see following logs: mainflux-things | {\"level\":\"info\",\"message\":\"Method get_pub_conf_by_key for thing 513d02d2-16c1-4f23-98be-9e12f8fee898 took 1.410194ms to complete without errors.\",\"ts\":\"2019-01-08T22:19:30.148097648Z\"} mainflux-http | {\"level\":\"info\",\"message\":\"Method publish took 336.685\u00b5s to complete without errors.\",\"ts\":\"2019-01-08T22:19:30.148689601Z\"} This proves that messages have been correctly sent through the system via the protocol adapter ( mainflux-http ).","title":"Step 4 - Send Messages"},{"location":"kubernetes/","text":"Kubernetes # Mainflux can be easily deployed on Kubernetes platform by using Helm Chart from official Mainflux DevOps GitHub repository . Prerequisites # Kubernetes kubectl Helm v3 Stable Helm repository Nginx Ingress Controller Kubernetes # Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerised applications. Install it locally or have access to a cluster. Follow these instructions if you need more information. Kubectl # Kubectl is official Kubernetes command line client. Follow these instructions to install it. Regarding the cluster control with kubectl , default config .yaml file should be ~/.kube/config . Helm v3 # Helm is the package manager for Kubernetes. Follow these instructions to install it. Stable Helm Repository # Add a stable chart repository: helm repo add stable https://charts.helm.sh/stable Add a bitnami chart repository: helm repo add bitnami https://charts.bitnami.com/bitnami Nginx Ingress Controller # Follow these instructions to install it or: helm install ingress-nginx ingress-nginx/ingress-nginx --version 3.26.0 --create-namespace -n ingress-nginx Deploying Mainflux # Get Helm charts from Mainflux DevOps GitHub repository : git clone https://github.com/MainfluxLabs/devops.git cd devops/charts/mainflux Update the on-disk dependencies to mirror Chart.yaml: helm dependency update If you didn't already have namespace created you should do it with: kubectl create namespace mf Deploying release named mainflux in namespace named mf is done with just: helm install mainflux . -n mf Mainflux is now deployed on your Kubernetes. Customizing Installation # You can override default values while installing with --set option. For example, if you want to specify ingress hostname and pull latest tag of users image: helm install mainflux -n mf --set ingress.hostname='example.com' --set users.image.tag='latest' Or if release is already installed, you can update it: helm upgrade mainflux -n mf --set ingress.hostname='example.com' --set users.image.tag='latest' The following table lists the configurable parameters and their default values. Parameter Description Default defaults.logLevel Log level debug defaults.image.pullPolicy Docker Image Pull Policy IfNotPresent defaults.image.repository Docker Image Repository mainflux defaults.image.tag Docker Image Tag 0.11.0 defaults.replicaCount Replicas of MQTT adapter, Things, Envoy and Authn 3 defaults.natsPort NATS port 4222 defaults.jaegerPort Jaeger port 6831 nginxInternal.mtls.tls TLS secret which contains the server cert/key nginxInternal.mtls.intermediateCrt Generic secret which contains the intermediate cert used to verify clients ingress.enabled Should the Nginx Ingress be created true ingress.hostname Hostname for the Nginx Ingress ingress.tls.hostname Hostname of the Nginx Ingress certificate ingress.tls.secret TLS secret for the Nginx Ingress nats.maxPayload Maximum payload size in bytes that the NATS server will accept 268435456 nats.replicaCount NATS replicas 3 authn.dbPort AuthN service DB port 5432 authn.grpcPort AuthN service gRPC port 8181 authn.httpPort AuthN service HTTP port 8189 users.dbPort Users service DB port 5432 users.httpPort Users service HTTP port 8180 things.dbPort Things service DB port 5432 things.httpPort Things service HTTP port 8182 things.authGrpcPort Things service Auth gRPC port 8183 things.authHttpPort Things service Auth HTTP port 8989 things.redisESPort Things service Redis Event Store port 6379 things.redisCachePort Things service Redis Auth Cache port 6379 adapter_http.httpPort HTTP adapter port 8185 mqtt.proxy.mqttPort MQTT adapter proxy port 1884 mqtt.proxy.wsPort MQTT adapter proxy WS port 8081 mqtt.broker.mqttPort MQTT adapter broker port 1883 mqtt.broker.wsPort MQTT adapter broker WS port 8080 mqtt.broker.persistentVolume.size MQTT adapter broker data Persistent Volume size 5Gi mqtt.redisESPort MQTT adapter Event Store port 6379 mqtt.redisCachePort MQTT adapter Redis Auth Cache port 6379 adapter_coap.udpPort CoAP adapter UDP port 5683 ui.port UI port 3000 All Mainflux services (both core and add-ons) can have their logLevel , image.pullPolicy , image.repository and image.tag overridden. Mainflux Core is a minimalistic set of required Mainflux services. They are all installed by default: auth users things adapter_http adapter_mqtt adapter_coap adapter_ws ui Mainflux Add-ons are optional services that are disabled by default. Find in Configuration table parameters for enabling them. By default scale of MQTT adapter, Things, Envoy, Authn and NATS will be set to 3. It's recommended that you set this values to number of your nodes in Kubernetes cluster, i.e. --set defaults.replicaCount=3 --set nats.replicaCount=3 Additional Steps to Configure Ingress Controller # To send MQTT messages to your host on ports 1883 and 8883 some additional steps are required in configuring NGINX Ingress Controller. NGINX Ingress Controller uses ConfigMap to expose TCP services. That ConfigMap is included in helm chart in ingress.yaml file assuming that location of ConfigMap should be ingress-nginx/tcp-services . If Ingress Controller expects it in some other namespace or with other name you should edit metadata in ingress.yaml . This location was set with --tcp-services-configmap flag and you can check it in deployment of Ingress Controller or add it there in args section for nginx-ingress-controller if it's not already specified. This is explained in NGINX Ingress documentation Also, those two ports need to be exposed in the Service defined for the Ingress. You can do that with command that edit your service: kubectl edit svc -n ingress-nginx nginx-ingress-ingress-nginx-controller and add in spec->ports: - name: mqtt port: 1883 protocol: TCP targetPort: 1883 - name: mqtts port: 8883 protocol: TCP targetPort: 8883 TLS & mTLS # For testing purposes you can generate certificates as explained in detail in authentication chapter of this document. So, you can use this script and after replacing all localhost with your hostname, run: make ca make server_cert make thing_cert KEY=<thing_key> you should get in certs folder these certificates that we will use for setting up TLS and mTLS: ca.crt ca.key ca.srl mainflux-server.crt mainflux-server.key thing.crt thing.key Create kubernetes secrets using those certificates with running commands from (secrets script)[https://github.com/MainfluxLabs/devops/blob/master/charts/mainflux/secrets/secrets.sh]. In this example secrets are created in mf namespace: kubectl -n mf create secret tls mainflux-server \\ --key mainflux-server.key \\ --cert mainflux-server.crt kubectl -n mf create secret generic ca \\ --from-file=ca.crt You can check if they are succesfully created: kubectl get secrets -n mf And now set ingress.hostname, ingress.tls.hostname to your hostname and ingress.tls.secret to mainflux-server and after helm update you have secured ingress with TLS certificate. For mTLS you need to set nginx_internal.mtls.tls=\"mainflux-server\" and nginx_internal.mtls.intermediate_crt=\"ca\" . Now you can test sending mqtt message with this parameters: mosquitto_pub -d -L mqtts://<thing_id>:<thing_key>@example.com:8883/messages --cert thing.crt --key thing.key --cafile ca.crt -m \"test-message\"","title":"Kubernetes"},{"location":"kubernetes/#kubernetes","text":"Mainflux can be easily deployed on Kubernetes platform by using Helm Chart from official Mainflux DevOps GitHub repository .","title":"Kubernetes"},{"location":"kubernetes/#prerequisites","text":"Kubernetes kubectl Helm v3 Stable Helm repository Nginx Ingress Controller","title":"Prerequisites"},{"location":"kubernetes/#kubernetes_1","text":"Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerised applications. Install it locally or have access to a cluster. Follow these instructions if you need more information.","title":"Kubernetes"},{"location":"kubernetes/#kubectl","text":"Kubectl is official Kubernetes command line client. Follow these instructions to install it. Regarding the cluster control with kubectl , default config .yaml file should be ~/.kube/config .","title":"Kubectl"},{"location":"kubernetes/#helm-v3","text":"Helm is the package manager for Kubernetes. Follow these instructions to install it.","title":"Helm v3"},{"location":"kubernetes/#stable-helm-repository","text":"Add a stable chart repository: helm repo add stable https://charts.helm.sh/stable Add a bitnami chart repository: helm repo add bitnami https://charts.bitnami.com/bitnami","title":"Stable Helm Repository"},{"location":"kubernetes/#nginx-ingress-controller","text":"Follow these instructions to install it or: helm install ingress-nginx ingress-nginx/ingress-nginx --version 3.26.0 --create-namespace -n ingress-nginx","title":"Nginx Ingress Controller"},{"location":"kubernetes/#deploying-mainflux","text":"Get Helm charts from Mainflux DevOps GitHub repository : git clone https://github.com/MainfluxLabs/devops.git cd devops/charts/mainflux Update the on-disk dependencies to mirror Chart.yaml: helm dependency update If you didn't already have namespace created you should do it with: kubectl create namespace mf Deploying release named mainflux in namespace named mf is done with just: helm install mainflux . -n mf Mainflux is now deployed on your Kubernetes.","title":"Deploying Mainflux"},{"location":"kubernetes/#customizing-installation","text":"You can override default values while installing with --set option. For example, if you want to specify ingress hostname and pull latest tag of users image: helm install mainflux -n mf --set ingress.hostname='example.com' --set users.image.tag='latest' Or if release is already installed, you can update it: helm upgrade mainflux -n mf --set ingress.hostname='example.com' --set users.image.tag='latest' The following table lists the configurable parameters and their default values. Parameter Description Default defaults.logLevel Log level debug defaults.image.pullPolicy Docker Image Pull Policy IfNotPresent defaults.image.repository Docker Image Repository mainflux defaults.image.tag Docker Image Tag 0.11.0 defaults.replicaCount Replicas of MQTT adapter, Things, Envoy and Authn 3 defaults.natsPort NATS port 4222 defaults.jaegerPort Jaeger port 6831 nginxInternal.mtls.tls TLS secret which contains the server cert/key nginxInternal.mtls.intermediateCrt Generic secret which contains the intermediate cert used to verify clients ingress.enabled Should the Nginx Ingress be created true ingress.hostname Hostname for the Nginx Ingress ingress.tls.hostname Hostname of the Nginx Ingress certificate ingress.tls.secret TLS secret for the Nginx Ingress nats.maxPayload Maximum payload size in bytes that the NATS server will accept 268435456 nats.replicaCount NATS replicas 3 authn.dbPort AuthN service DB port 5432 authn.grpcPort AuthN service gRPC port 8181 authn.httpPort AuthN service HTTP port 8189 users.dbPort Users service DB port 5432 users.httpPort Users service HTTP port 8180 things.dbPort Things service DB port 5432 things.httpPort Things service HTTP port 8182 things.authGrpcPort Things service Auth gRPC port 8183 things.authHttpPort Things service Auth HTTP port 8989 things.redisESPort Things service Redis Event Store port 6379 things.redisCachePort Things service Redis Auth Cache port 6379 adapter_http.httpPort HTTP adapter port 8185 mqtt.proxy.mqttPort MQTT adapter proxy port 1884 mqtt.proxy.wsPort MQTT adapter proxy WS port 8081 mqtt.broker.mqttPort MQTT adapter broker port 1883 mqtt.broker.wsPort MQTT adapter broker WS port 8080 mqtt.broker.persistentVolume.size MQTT adapter broker data Persistent Volume size 5Gi mqtt.redisESPort MQTT adapter Event Store port 6379 mqtt.redisCachePort MQTT adapter Redis Auth Cache port 6379 adapter_coap.udpPort CoAP adapter UDP port 5683 ui.port UI port 3000 All Mainflux services (both core and add-ons) can have their logLevel , image.pullPolicy , image.repository and image.tag overridden. Mainflux Core is a minimalistic set of required Mainflux services. They are all installed by default: auth users things adapter_http adapter_mqtt adapter_coap adapter_ws ui Mainflux Add-ons are optional services that are disabled by default. Find in Configuration table parameters for enabling them. By default scale of MQTT adapter, Things, Envoy, Authn and NATS will be set to 3. It's recommended that you set this values to number of your nodes in Kubernetes cluster, i.e. --set defaults.replicaCount=3 --set nats.replicaCount=3","title":"Customizing Installation"},{"location":"kubernetes/#additional-steps-to-configure-ingress-controller","text":"To send MQTT messages to your host on ports 1883 and 8883 some additional steps are required in configuring NGINX Ingress Controller. NGINX Ingress Controller uses ConfigMap to expose TCP services. That ConfigMap is included in helm chart in ingress.yaml file assuming that location of ConfigMap should be ingress-nginx/tcp-services . If Ingress Controller expects it in some other namespace or with other name you should edit metadata in ingress.yaml . This location was set with --tcp-services-configmap flag and you can check it in deployment of Ingress Controller or add it there in args section for nginx-ingress-controller if it's not already specified. This is explained in NGINX Ingress documentation Also, those two ports need to be exposed in the Service defined for the Ingress. You can do that with command that edit your service: kubectl edit svc -n ingress-nginx nginx-ingress-ingress-nginx-controller and add in spec->ports: - name: mqtt port: 1883 protocol: TCP targetPort: 1883 - name: mqtts port: 8883 protocol: TCP targetPort: 8883","title":"Additional Steps to Configure Ingress Controller"},{"location":"kubernetes/#tls-mtls","text":"For testing purposes you can generate certificates as explained in detail in authentication chapter of this document. So, you can use this script and after replacing all localhost with your hostname, run: make ca make server_cert make thing_cert KEY=<thing_key> you should get in certs folder these certificates that we will use for setting up TLS and mTLS: ca.crt ca.key ca.srl mainflux-server.crt mainflux-server.key thing.crt thing.key Create kubernetes secrets using those certificates with running commands from (secrets script)[https://github.com/MainfluxLabs/devops/blob/master/charts/mainflux/secrets/secrets.sh]. In this example secrets are created in mf namespace: kubectl -n mf create secret tls mainflux-server \\ --key mainflux-server.key \\ --cert mainflux-server.crt kubectl -n mf create secret generic ca \\ --from-file=ca.crt You can check if they are succesfully created: kubectl get secrets -n mf And now set ingress.hostname, ingress.tls.hostname to your hostname and ingress.tls.secret to mainflux-server and after helm update you have secured ingress with TLS certificate. For mTLS you need to set nginx_internal.mtls.tls=\"mainflux-server\" and nginx_internal.mtls.intermediate_crt=\"ca\" . Now you can test sending mqtt message with this parameters: mosquitto_pub -d -L mqtts://<thing_id>:<thing_key>@example.com:8883/messages --cert thing.crt --key thing.key --cafile ca.crt -m \"test-message\"","title":"TLS &amp; mTLS"},{"location":"messaging/","text":"Messaging # Once a profile is provisioned and assigned to a thing, publishing messages can begin. The following sections will provide an example of message publishing for each of the supported protocols. Configure Profile Config # For successful publishing of messages, when creating a profile, it is necessary to define configuration parameters within the structure config . The config structure consists of the following fields: content_type , write , webhook , transformer , smtp_id . A content_type field defines the payload format of messages in order to transform and store them properly. Available formats are SenML, CBOR, and JSON and they can be defined correspondingly with values application/senml+json , application/senml+cbor and application/json . A write field determines whether messages should be stored in the database. When write is set to true , messages will be saved in the database. Conversely, if write is set to false , messages will be sent without storing them. Here's an example of SenML-JSON metadata: { \"config\": { \"content_type\": \"application/senml+json\", \"write\": true, \"webhook\": false, \"smtp_id\": \"\" } } Here's an example of SenML-CBOR metadata: { \"config\": { \"content_type\": \"application/senml+cbor\", \"write\": true, \"webhook\": false, \"smtp_id\": \"\" } } The payload of the IoT message often contains message time. It can be in different formats (like base time and record time in the case of SenML) and the message field can be under the arbitrary key. Usually, we would want to map that time to the Mainflux Message field created , and for that reason, we need to configure the transformer to be able to read the field, parse it using proper format and location (if devices time is different from the service time), and map it to Mainflux Message. When content_type is defined as application/json , inside the transformer structure it is possible to configure the field time_field which is the name of the JSON key to use as a timestamp, time_format to use for the field value and time_location . Here's an example of JSON metadata: { \"config\": { \"content_type\": \"application/json\", \"write\": true, \"webhook\": false, \"transformer\": { \"data_filters\": [\"val1\", \"val2\"], \"data_field\":\"field1\", \"time_field\": \"t\", \"time_format\": \"unix\", \"time_location\": \"UTC\" }, \"smtp_id\": \"\" } } In case it is necessary to extract the received payload and use a specific object within the payload, it is possible to define a value within the data_field field that will be used to extract the payload. If we have a payload from which we want to get a list of \"params\", then the config should look like this: { \"config\": { \"content_type\": \"application/json\", \"write\": true, \"transformer\": { \"data_filters\": [], \"data_field\": \"root.params\", \"time_field\": \"created\", \"time_format\": \"rfc3339\", \"time_location\": \"UTC\" } } } Received payload with params: { \"root\": { \"params\": [ { \"field\": \"temperature\", \"value\": 20, \"created\": \"2024-12-24T17:15:55.000Z\" }, { \"field\": \"humidity\", \"value\": 45, \"created\": \"2024-12-24T17:17:00.000Z\" } ] } } The extraction result is: [ { \"field\": \"temperature\", \"value\": 20, \"created\": \"2024-12-24T17:15:55.000Z\" }, { \"field\": \"humidity\", \"value\": 45, \"created\": \"2024-12-24T17:17:00.000Z\" } ] Field data_field represents a string containing dot-separated values, unless only first-level extraction is used, then only the field name is enough (for example, \"root\"). Each of those words represents the level of the JSON payload to be extracted, which is important to specify them correctly for nested objects. For the messages that contain JSON array as the root element , JSON Transformer does normalization of the data: it creates a separate JSON message for each JSON object in the root. The data_filters field inside the transformer contains the values based on which the transformer filters incoming payload messages. If there is certain data that you want to store, you can define it in the data_filters field. For the previous example, we can filter the extracted payload and save only the fields under the key \"field\" and \"value\", then the updated config structure would look like this: { \"config\": { \"content_type\": \"application/json\", \"write\": true, \"transformer\": { \"data_filters\": [\"field\",\"value\"], \"data_field\": \"root.params\", \"time_field\": \"created\", \"time_format\": \"rfc3339\", \"time_location\": \"UTC\" } } } If the data_filters and data_field fields are empty, the whole payload will be used. The explanations for the webhook and smtp_id fields of the config can be found in the Webhooks and Notifiers sections. Notifiers # Notifiers service provides a service for sending notifications. It can be configured to send email notifications over SMTP (Simple Mail Transfer Protocol). Notification can be enabled by setting the appropriate notifier ID to the smtp_id field within the Profile Config. Here is an example with the value of the smtp_id field: { \"config\": { \"content_type\": \"application/senml+json\", \"write\": false, \"webhook\": false, \"smtp_id\": \"a9bf9e57-1685-4c89-bafb-ff5af830be8b\" } } Note: If write is set to false , notifications will be sent without storing the message in the database. Webhooks # Webhooks service provides forwarding received messages to other platforms. Setting the value true or false in the webhook field within Profile Config determines whether messages will be forwarded. Here is an example with the value of the webhook field: { \"config\": { \"content_type\": \"application/json\", \"write\": false, \"webhook\": true, \"smtp_id\": \"\" } } Subtopics # In order to use subtopics and give more meaning about the content of messages published or received by subscription, you can simply add any suffix to base /messages topic. Example subtopic publish/subscribe for bedroom temperature would be /messages/bedroom/temperature . Subtopics are generic and multilevel. You can use almost any suffix with any depth. Topics with subtopics are propagated to NATS broker in the following format <format>.messages.<optional_subtopic> . The format prefix is included in the topic which is obtained from the content_type field specified in the transformer part of the config structure in the Profile. The prefix value can be set to json or senml . Our example topic /messages/bedroom/temperature with content_type defined as application/senml+json will be translated to appropriate NATS topic senml.messages.bedroom.temperature . You can use multilevel subtopics, that have multiple parts. These parts are separated by . or / separators. When you use combination of these two, have in mind that behind the scene, / separator will be replaced with . . Every empty part of subtopic will be removed. What this means is that subtopic a///b is equivalent to a/b . When you want to subscribe, you can use NATS wildcards * and > . Every subtopic part can have * or > as it's value, but if there is any other character beside these wildcards, subtopic will be invalid. What this means is that subtopics such as a.b*c.d will be invalid, while a.b.*.c.d will be valid. Note: When using MQTT, it's recommended that you use standard MQTT wildcards + and # . For more information and examples checkout official nats.io documentation HTTP # To publish message, a thing with proper profile should send following request: curl -s -S -i --cacert docker/ssl/certs/ca.crt -X POST -H \"Authorization: Thing <thing_key>\" -H \"Content-Type: application/senml+json\" https://localhost/http/messages -d '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' Note: If you're going to use senml message format, you should always send messages as an array. For more information about the HTTP messaging service API, please check out the API documentation . MQTT # To send and receive messages over MQTT you could use Mosquitto tools , or Paho if you want to use MQTT over WebSocket. To publish message, thing should call following command: mosquitto_pub -u <thing_id> -P <thing_key> -t /messages -h localhost -m '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' To subscribe to a topic, thing should call following command: mosquitto_sub -u <thing_id> -P <thing_key> -t /messages -h localhost If you want to use standard topic such as /messages with SenML content type (JSON or CBOR), you should use following topic /messages . If you are using TLS to secure MQTT connection, add --cafile docker/ssl/certs/ca.crt to every command. CoAP # CoAP adapter implements CoAP protocol using underlying UDP and according to RFC 7252 . To send and receive messages over CoAP, you can use CoAP CLI . To set the add-on, please follow the installation instructions provided here . Examples: coap-cli get /messages/subtopic -auth 1e1017e6-dee7-45b4-8a13-00e6afeb66eb -o coap-cli post /messages/subtopic -auth 1e1017e6-dee7-45b4-8a13-00e6afeb66eb -d \"hello world\" coap-cli post /messages/subtopic -auth 1e1017e6-dee7-45b4-8a13-00e6afeb66eb -d \"hello world\" -h 0.0.0.0 -p 1234 To send a message, use POST request. To subscribe, send GET request with Observe option (flag o ) set to false. There are two ways to unsubscribe: 1) Send GET request with Observe option set to true. 2) Forget the token and send RST message as a response to CONF message received by the server. The most of the notifications received from the Adapter are non-confirmable. By RFC 7641 : Server must send a notification in a confirmable message instead of a non-confirmable message at least every 24 hours. This prevents a client that went away or is no longer interested from remaining in the list of observers indefinitely. CoAP Adapter sends these notifications every 12 hours. To configure this period, please check adapter documentation If the client is no longer interested in receiving notifications, the second scenario described above can be used to unsubscribe. WS # Mainflux supports MQTT-over-WS , rather than pure WS protocol. This brings numerous benefits for IoT applications that are derived from the properties of MQTT - like QoS and PUB/SUB features. There are 2 recommended Javascript libraries for implementing browser support for Mainflux MQTT-over-WS connectivity: Eclipse Paho JavaScript Client MQTT.js As WS is an extension of HTTP protocol, Mainflux exposes it on port 80 , so it's usage is practically transparent. Additionally, please notice that since same port as for HTTP is used ( 80 ), and extension URL /mqtt should be used - i.e. connection URL should be ws://<host_addr>/mqtt . For quick testing you can use HiveMQ UI tool . Here is an example of a browser application connecting to Mainflux server and sending and receiving messages over WebSocket using MQTT.js library: <script src=\"https://unpkg.com/mqtt/dist/mqtt.min.js\"></script> <script> // Initialize a mqtt variable globally console.log(mqtt) // connection option const options = { clean: true, // retain session connectTimeout: 4000, // Timeout period // Authentication information clientId: '14d6c682-fb5a-4d28-b670-ee565ab5866c', username: '14d6c682-fb5a-4d28-b670-ee565ab5866c', password: 'ec82f341-d4b5-4c77-ae05-34877a62428f', } var topic = '/messages' // Connect string, and specify the connection method by the protocol // ws Unencrypted WebSocket connection // wss Encrypted WebSocket connection const connectUrl = 'ws://localhost/mqtt' const client = mqtt.connect(connectUrl, options) client.on('reconnect', (error) => { console.log('reconnecting:', error) }) client.on('error', (error) => { console.log('Connection failed:', error) }) client.on('connect', function () { console.log('client connected:' + options.clientId) client.subscribe(topic, { qos: 0 }) client.publish(topic, 'WS connection demo!', { qos: 0, retain: false }) }) client.on('message', function (topic, message, packet) { console.log('Received Message:= ' + message.toString() + '\\nOn topic:= ' + topic) }) client.on('close', function () { console.log(options.clientId + ' disconnected') }) </script> N.B. Eclipse Paho lib adds sub-URL /mqtt automaticlly, so procedure for connecting to the server can be something like this: var loc = { hostname: 'localhost', port: 80 } // Create a client instance client = new Paho.MQTT.Client(loc.hostname, Number(loc.port), \"clientId\") // Connect the client client.connect({onSuccess:onConnect});","title":"Messaging"},{"location":"messaging/#messaging","text":"Once a profile is provisioned and assigned to a thing, publishing messages can begin. The following sections will provide an example of message publishing for each of the supported protocols.","title":"Messaging"},{"location":"messaging/#configure-profile-config","text":"For successful publishing of messages, when creating a profile, it is necessary to define configuration parameters within the structure config . The config structure consists of the following fields: content_type , write , webhook , transformer , smtp_id . A content_type field defines the payload format of messages in order to transform and store them properly. Available formats are SenML, CBOR, and JSON and they can be defined correspondingly with values application/senml+json , application/senml+cbor and application/json . A write field determines whether messages should be stored in the database. When write is set to true , messages will be saved in the database. Conversely, if write is set to false , messages will be sent without storing them. Here's an example of SenML-JSON metadata: { \"config\": { \"content_type\": \"application/senml+json\", \"write\": true, \"webhook\": false, \"smtp_id\": \"\" } } Here's an example of SenML-CBOR metadata: { \"config\": { \"content_type\": \"application/senml+cbor\", \"write\": true, \"webhook\": false, \"smtp_id\": \"\" } } The payload of the IoT message often contains message time. It can be in different formats (like base time and record time in the case of SenML) and the message field can be under the arbitrary key. Usually, we would want to map that time to the Mainflux Message field created , and for that reason, we need to configure the transformer to be able to read the field, parse it using proper format and location (if devices time is different from the service time), and map it to Mainflux Message. When content_type is defined as application/json , inside the transformer structure it is possible to configure the field time_field which is the name of the JSON key to use as a timestamp, time_format to use for the field value and time_location . Here's an example of JSON metadata: { \"config\": { \"content_type\": \"application/json\", \"write\": true, \"webhook\": false, \"transformer\": { \"data_filters\": [\"val1\", \"val2\"], \"data_field\":\"field1\", \"time_field\": \"t\", \"time_format\": \"unix\", \"time_location\": \"UTC\" }, \"smtp_id\": \"\" } } In case it is necessary to extract the received payload and use a specific object within the payload, it is possible to define a value within the data_field field that will be used to extract the payload. If we have a payload from which we want to get a list of \"params\", then the config should look like this: { \"config\": { \"content_type\": \"application/json\", \"write\": true, \"transformer\": { \"data_filters\": [], \"data_field\": \"root.params\", \"time_field\": \"created\", \"time_format\": \"rfc3339\", \"time_location\": \"UTC\" } } } Received payload with params: { \"root\": { \"params\": [ { \"field\": \"temperature\", \"value\": 20, \"created\": \"2024-12-24T17:15:55.000Z\" }, { \"field\": \"humidity\", \"value\": 45, \"created\": \"2024-12-24T17:17:00.000Z\" } ] } } The extraction result is: [ { \"field\": \"temperature\", \"value\": 20, \"created\": \"2024-12-24T17:15:55.000Z\" }, { \"field\": \"humidity\", \"value\": 45, \"created\": \"2024-12-24T17:17:00.000Z\" } ] Field data_field represents a string containing dot-separated values, unless only first-level extraction is used, then only the field name is enough (for example, \"root\"). Each of those words represents the level of the JSON payload to be extracted, which is important to specify them correctly for nested objects. For the messages that contain JSON array as the root element , JSON Transformer does normalization of the data: it creates a separate JSON message for each JSON object in the root. The data_filters field inside the transformer contains the values based on which the transformer filters incoming payload messages. If there is certain data that you want to store, you can define it in the data_filters field. For the previous example, we can filter the extracted payload and save only the fields under the key \"field\" and \"value\", then the updated config structure would look like this: { \"config\": { \"content_type\": \"application/json\", \"write\": true, \"transformer\": { \"data_filters\": [\"field\",\"value\"], \"data_field\": \"root.params\", \"time_field\": \"created\", \"time_format\": \"rfc3339\", \"time_location\": \"UTC\" } } } If the data_filters and data_field fields are empty, the whole payload will be used. The explanations for the webhook and smtp_id fields of the config can be found in the Webhooks and Notifiers sections.","title":"Configure Profile Config"},{"location":"messaging/#notifiers","text":"Notifiers service provides a service for sending notifications. It can be configured to send email notifications over SMTP (Simple Mail Transfer Protocol). Notification can be enabled by setting the appropriate notifier ID to the smtp_id field within the Profile Config. Here is an example with the value of the smtp_id field: { \"config\": { \"content_type\": \"application/senml+json\", \"write\": false, \"webhook\": false, \"smtp_id\": \"a9bf9e57-1685-4c89-bafb-ff5af830be8b\" } } Note: If write is set to false , notifications will be sent without storing the message in the database.","title":"Notifiers"},{"location":"messaging/#webhooks","text":"Webhooks service provides forwarding received messages to other platforms. Setting the value true or false in the webhook field within Profile Config determines whether messages will be forwarded. Here is an example with the value of the webhook field: { \"config\": { \"content_type\": \"application/json\", \"write\": false, \"webhook\": true, \"smtp_id\": \"\" } }","title":"Webhooks"},{"location":"messaging/#subtopics","text":"In order to use subtopics and give more meaning about the content of messages published or received by subscription, you can simply add any suffix to base /messages topic. Example subtopic publish/subscribe for bedroom temperature would be /messages/bedroom/temperature . Subtopics are generic and multilevel. You can use almost any suffix with any depth. Topics with subtopics are propagated to NATS broker in the following format <format>.messages.<optional_subtopic> . The format prefix is included in the topic which is obtained from the content_type field specified in the transformer part of the config structure in the Profile. The prefix value can be set to json or senml . Our example topic /messages/bedroom/temperature with content_type defined as application/senml+json will be translated to appropriate NATS topic senml.messages.bedroom.temperature . You can use multilevel subtopics, that have multiple parts. These parts are separated by . or / separators. When you use combination of these two, have in mind that behind the scene, / separator will be replaced with . . Every empty part of subtopic will be removed. What this means is that subtopic a///b is equivalent to a/b . When you want to subscribe, you can use NATS wildcards * and > . Every subtopic part can have * or > as it's value, but if there is any other character beside these wildcards, subtopic will be invalid. What this means is that subtopics such as a.b*c.d will be invalid, while a.b.*.c.d will be valid. Note: When using MQTT, it's recommended that you use standard MQTT wildcards + and # . For more information and examples checkout official nats.io documentation","title":"Subtopics"},{"location":"messaging/#http","text":"To publish message, a thing with proper profile should send following request: curl -s -S -i --cacert docker/ssl/certs/ca.crt -X POST -H \"Authorization: Thing <thing_key>\" -H \"Content-Type: application/senml+json\" https://localhost/http/messages -d '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' Note: If you're going to use senml message format, you should always send messages as an array. For more information about the HTTP messaging service API, please check out the API documentation .","title":"HTTP"},{"location":"messaging/#mqtt","text":"To send and receive messages over MQTT you could use Mosquitto tools , or Paho if you want to use MQTT over WebSocket. To publish message, thing should call following command: mosquitto_pub -u <thing_id> -P <thing_key> -t /messages -h localhost -m '[{\"bn\":\"some-base-name:\",\"bt\":1.276020076001e+09, \"bu\":\"A\",\"bver\":5, \"n\":\"voltage\",\"u\":\"V\",\"v\":120.1}, {\"n\":\"current\",\"t\":-5,\"v\":1.2}, {\"n\":\"current\",\"t\":-4,\"v\":1.3}]' To subscribe to a topic, thing should call following command: mosquitto_sub -u <thing_id> -P <thing_key> -t /messages -h localhost If you want to use standard topic such as /messages with SenML content type (JSON or CBOR), you should use following topic /messages . If you are using TLS to secure MQTT connection, add --cafile docker/ssl/certs/ca.crt to every command.","title":"MQTT"},{"location":"messaging/#coap","text":"CoAP adapter implements CoAP protocol using underlying UDP and according to RFC 7252 . To send and receive messages over CoAP, you can use CoAP CLI . To set the add-on, please follow the installation instructions provided here . Examples: coap-cli get /messages/subtopic -auth 1e1017e6-dee7-45b4-8a13-00e6afeb66eb -o coap-cli post /messages/subtopic -auth 1e1017e6-dee7-45b4-8a13-00e6afeb66eb -d \"hello world\" coap-cli post /messages/subtopic -auth 1e1017e6-dee7-45b4-8a13-00e6afeb66eb -d \"hello world\" -h 0.0.0.0 -p 1234 To send a message, use POST request. To subscribe, send GET request with Observe option (flag o ) set to false. There are two ways to unsubscribe: 1) Send GET request with Observe option set to true. 2) Forget the token and send RST message as a response to CONF message received by the server. The most of the notifications received from the Adapter are non-confirmable. By RFC 7641 : Server must send a notification in a confirmable message instead of a non-confirmable message at least every 24 hours. This prevents a client that went away or is no longer interested from remaining in the list of observers indefinitely. CoAP Adapter sends these notifications every 12 hours. To configure this period, please check adapter documentation If the client is no longer interested in receiving notifications, the second scenario described above can be used to unsubscribe.","title":"CoAP"},{"location":"messaging/#ws","text":"Mainflux supports MQTT-over-WS , rather than pure WS protocol. This brings numerous benefits for IoT applications that are derived from the properties of MQTT - like QoS and PUB/SUB features. There are 2 recommended Javascript libraries for implementing browser support for Mainflux MQTT-over-WS connectivity: Eclipse Paho JavaScript Client MQTT.js As WS is an extension of HTTP protocol, Mainflux exposes it on port 80 , so it's usage is practically transparent. Additionally, please notice that since same port as for HTTP is used ( 80 ), and extension URL /mqtt should be used - i.e. connection URL should be ws://<host_addr>/mqtt . For quick testing you can use HiveMQ UI tool . Here is an example of a browser application connecting to Mainflux server and sending and receiving messages over WebSocket using MQTT.js library: <script src=\"https://unpkg.com/mqtt/dist/mqtt.min.js\"></script> <script> // Initialize a mqtt variable globally console.log(mqtt) // connection option const options = { clean: true, // retain session connectTimeout: 4000, // Timeout period // Authentication information clientId: '14d6c682-fb5a-4d28-b670-ee565ab5866c', username: '14d6c682-fb5a-4d28-b670-ee565ab5866c', password: 'ec82f341-d4b5-4c77-ae05-34877a62428f', } var topic = '/messages' // Connect string, and specify the connection method by the protocol // ws Unencrypted WebSocket connection // wss Encrypted WebSocket connection const connectUrl = 'ws://localhost/mqtt' const client = mqtt.connect(connectUrl, options) client.on('reconnect', (error) => { console.log('reconnecting:', error) }) client.on('error', (error) => { console.log('Connection failed:', error) }) client.on('connect', function () { console.log('client connected:' + options.clientId) client.subscribe(topic, { qos: 0 }) client.publish(topic, 'WS connection demo!', { qos: 0, retain: false }) }) client.on('message', function (topic, message, packet) { console.log('Received Message:= ' + message.toString() + '\\nOn topic:= ' + topic) }) client.on('close', function () { console.log(options.clientId + ' disconnected') }) </script> N.B. Eclipse Paho lib adds sub-URL /mqtt automaticlly, so procedure for connecting to the server can be something like this: var loc = { hostname: 'localhost', port: 80 } // Create a client instance client = new Paho.MQTT.Client(loc.hostname, Number(loc.port), \"clientId\") // Connect the client client.connect({onSuccess:onConnect});","title":"WS"},{"location":"security/","text":"Security # Server Configuration # Users # If either the cert or key is not set, the server will use insecure transport. MF_USERS_SERVER_CERT the path to server certificate in pem format. MF_USERS_SERVER_KEY the path to the server key in pem format. Things # If either the cert or key is not set, the server will use insecure transport. MF_THINGS_SERVER_CERT the path to server certificate in pem format. MF_THINGS_SERVER_KEY the path to the server key in pem format. Standalone mode # Sometimes it makes sense to run Things as a standalone service to reduce network traffic or simplify deployment. This means that Things service operates only using a single user and is able to authorize it without gRPC communication with Auth service. When running Things in the standalone mode, Auth and Users services can be omitted from the deployment. To run service in a standalone mode, set MF_THINGS_STANDALONE_EMAIL and MF_THINGS_STANDALONE_TOKEN . Client Configuration # If you wish to secure the gRPC connection to Things and Users services you must define the CAs that you trust. This does not support mutual certificate authentication. Adapter Configuration # MF_HTTP_ADAPTER_CA_CERTS , MF_MQTT_ADAPTER_CA_CERTS , MF_WS_ADAPTER_CA_CERTS , MF_COAP_ADAPTER_CA_CERTS - the path to a file that contains the CAs in PEM format. If not set, the default connection will be insecure. If it fails to read the file, the adapter will fail to start up. Things # MF_THINGS_CA_CERTS - the path to a file that contains the CAs in PEM format. If not set, the default connection will be insecure. If it fails to read the file, the service will fail to start up. Securing PostgreSQL Connections # By default, Mainflux will connect to Postgres using insecure transport. If a secured connection is required, you can select the SSL mode and set paths to any extra certificates and keys needed. MF_USERS_DB_SSL_MODE the SSL connection mode for Users. MF_USERS_DB_SSL_CERT the path to the certificate file for Users. MF_USERS_DB_SSL_KEY the path to the key file for Users. MF_USERS_DB_SSL_ROOT_CERT the path to the root certificate file for Users. MF_THINGS_DB_SSL_MODE the SSL connection mode for Things. MF_THINGS_DB_SSL_CERT the path to the certificate file for Things. MF_THINGS_DB_SSL_KEY the path to the key file for Things. MF_THINGS_DB_SSL_ROOT_CERT the path to the root certificate file for Things. Supported database connection modes are: disabled (default), required , verify-ca and verify-full . Securing gRPC # By default gRPC communication is not secure as Mainflux system is most often run in a private network behind the reverse proxy. However, TLS can be activated and configured.","title":"Security"},{"location":"security/#security","text":"","title":"Security"},{"location":"security/#server-configuration","text":"","title":"Server Configuration"},{"location":"security/#users","text":"If either the cert or key is not set, the server will use insecure transport. MF_USERS_SERVER_CERT the path to server certificate in pem format. MF_USERS_SERVER_KEY the path to the server key in pem format.","title":"Users"},{"location":"security/#things","text":"If either the cert or key is not set, the server will use insecure transport. MF_THINGS_SERVER_CERT the path to server certificate in pem format. MF_THINGS_SERVER_KEY the path to the server key in pem format.","title":"Things"},{"location":"security/#standalone-mode","text":"Sometimes it makes sense to run Things as a standalone service to reduce network traffic or simplify deployment. This means that Things service operates only using a single user and is able to authorize it without gRPC communication with Auth service. When running Things in the standalone mode, Auth and Users services can be omitted from the deployment. To run service in a standalone mode, set MF_THINGS_STANDALONE_EMAIL and MF_THINGS_STANDALONE_TOKEN .","title":"Standalone mode"},{"location":"security/#client-configuration","text":"If you wish to secure the gRPC connection to Things and Users services you must define the CAs that you trust. This does not support mutual certificate authentication.","title":"Client Configuration"},{"location":"security/#adapter-configuration","text":"MF_HTTP_ADAPTER_CA_CERTS , MF_MQTT_ADAPTER_CA_CERTS , MF_WS_ADAPTER_CA_CERTS , MF_COAP_ADAPTER_CA_CERTS - the path to a file that contains the CAs in PEM format. If not set, the default connection will be insecure. If it fails to read the file, the adapter will fail to start up.","title":"Adapter Configuration"},{"location":"security/#things_1","text":"MF_THINGS_CA_CERTS - the path to a file that contains the CAs in PEM format. If not set, the default connection will be insecure. If it fails to read the file, the service will fail to start up.","title":"Things"},{"location":"security/#securing-postgresql-connections","text":"By default, Mainflux will connect to Postgres using insecure transport. If a secured connection is required, you can select the SSL mode and set paths to any extra certificates and keys needed. MF_USERS_DB_SSL_MODE the SSL connection mode for Users. MF_USERS_DB_SSL_CERT the path to the certificate file for Users. MF_USERS_DB_SSL_KEY the path to the key file for Users. MF_USERS_DB_SSL_ROOT_CERT the path to the root certificate file for Users. MF_THINGS_DB_SSL_MODE the SSL connection mode for Things. MF_THINGS_DB_SSL_CERT the path to the certificate file for Things. MF_THINGS_DB_SSL_KEY the path to the key file for Things. MF_THINGS_DB_SSL_ROOT_CERT the path to the root certificate file for Things. Supported database connection modes are: disabled (default), required , verify-ca and verify-full .","title":"Securing PostgreSQL Connections"},{"location":"security/#securing-grpc","text":"By default gRPC communication is not secure as Mainflux system is most often run in a private network behind the reverse proxy. However, TLS can be activated and configured.","title":"Securing gRPC"},{"location":"storage/","text":"Storage # Mainflux supports various storage databases in which messages are stored: PostgreSQL TimescaleDB MongoDB These storages are activated via docker-compose add-ons. The <project_root>/docker folder contains an addons directory. This directory is used for various services that are not core to the Mainflux platform but could be used for providing additional features. In order to run these services, core services, as well as the network from the core composition, should be already running. Writers # Writers provide an implementation of various message writers . Message writers are services that consume Mainflux messages, transform them to desired format and store them in certain data stores. For proper consumption of messages based on subtopics and their transformation, see Subtopics and Configure Profile Config sections on the messaging page. PostgreSQL and PostgreSQL Writer # docker-compose -f docker/addons/postgres-writer/docker-compose.yml up -d Postgres default port (5432) is exposed, so you can use various tools for database inspection and data visualization. Timescale and Timescale Writer # docker-compose -f docker/addons/timescale-writer/docker-compose.yml up -d Timescale default port (5432) is exposed, so you can use various tools for database inspection and data visualization. MongoDB and MongoDB Writer # docker-compose -f docker/addons/mongodb-writer/docker-compose.yml up -d MongoDB default port (27017) is exposed, so you can use various tools for database inspection and data visualization. Readers # Readers provide an implementation of various message readers . Message readers are services that consume normalized (in SenML format) Mainflux messages from data storage and opens HTTP API for message consumption. Installing corresponding writer before reader is implied. Each of the Reader services exposes the same HTTP API for fetching messages on its default port. To read sent messages you should send GET request to /messages with thing access token in Authorization header. Response should look like this: HTTP/1.1 200 OK Content-Type: application/json Date: Tue, 18 Sep 2018 18:56:19 GMT Content-Length: 228 { \"messages\": [ { \"Publisher\": 1, \"Protocol\": \"mqtt\", \"Name\": \"name:voltage\", \"Unit\": \"V\", \"Value\": 5.6, \"Time\": 48.56 }, { \"Publisher\": 1, \"Protocol\": \"mqtt\", \"Name\": \"name:temperature\", \"Unit\": \"C\", \"Value\": 24.3, \"Time\": 48.56 } ] } Note that you will receive only those messages that were sent by authorization token's owner. You can specify offset and limit parameters in order to fetch specific group of messages. An example of HTTP request looks like: curl -s -S -i -H \"Authorization: Thing <thing_key>\" http://localhost:<service_port>/messages?offset=0&limit=5&format=json If you don't provide offset and limit parameters, default values will be used instead: 0 for offset and 10 for limit . The format parameter indicates in which format the messages will be returned. The default format is senml if the format is not defined, and if the desired format is JSON, you need to specify json for the format. MongoDB Reader # To start MongoDB reader, execute the following command: docker-compose -f docker/addons/mongodb-reader/docker-compose.yml up -d PostgreSQL Reader # To start PostgreSQL reader, execute the following command: docker-compose -f docker/addons/postgres-reader/docker-compose.yml up -d Timescale Reader # To start Timescale reader, execute the following command: docker-compose -f docker/addons/timescale-reader/docker-compose.yml up -d","title":"Storage"},{"location":"storage/#storage","text":"Mainflux supports various storage databases in which messages are stored: PostgreSQL TimescaleDB MongoDB These storages are activated via docker-compose add-ons. The <project_root>/docker folder contains an addons directory. This directory is used for various services that are not core to the Mainflux platform but could be used for providing additional features. In order to run these services, core services, as well as the network from the core composition, should be already running.","title":"Storage"},{"location":"storage/#writers","text":"Writers provide an implementation of various message writers . Message writers are services that consume Mainflux messages, transform them to desired format and store them in certain data stores. For proper consumption of messages based on subtopics and their transformation, see Subtopics and Configure Profile Config sections on the messaging page.","title":"Writers"},{"location":"storage/#postgresql-and-postgresql-writer","text":"docker-compose -f docker/addons/postgres-writer/docker-compose.yml up -d Postgres default port (5432) is exposed, so you can use various tools for database inspection and data visualization.","title":"PostgreSQL and PostgreSQL Writer"},{"location":"storage/#timescale-and-timescale-writer","text":"docker-compose -f docker/addons/timescale-writer/docker-compose.yml up -d Timescale default port (5432) is exposed, so you can use various tools for database inspection and data visualization.","title":"Timescale and Timescale Writer"},{"location":"storage/#mongodb-and-mongodb-writer","text":"docker-compose -f docker/addons/mongodb-writer/docker-compose.yml up -d MongoDB default port (27017) is exposed, so you can use various tools for database inspection and data visualization.","title":"MongoDB and MongoDB Writer"},{"location":"storage/#readers","text":"Readers provide an implementation of various message readers . Message readers are services that consume normalized (in SenML format) Mainflux messages from data storage and opens HTTP API for message consumption. Installing corresponding writer before reader is implied. Each of the Reader services exposes the same HTTP API for fetching messages on its default port. To read sent messages you should send GET request to /messages with thing access token in Authorization header. Response should look like this: HTTP/1.1 200 OK Content-Type: application/json Date: Tue, 18 Sep 2018 18:56:19 GMT Content-Length: 228 { \"messages\": [ { \"Publisher\": 1, \"Protocol\": \"mqtt\", \"Name\": \"name:voltage\", \"Unit\": \"V\", \"Value\": 5.6, \"Time\": 48.56 }, { \"Publisher\": 1, \"Protocol\": \"mqtt\", \"Name\": \"name:temperature\", \"Unit\": \"C\", \"Value\": 24.3, \"Time\": 48.56 } ] } Note that you will receive only those messages that were sent by authorization token's owner. You can specify offset and limit parameters in order to fetch specific group of messages. An example of HTTP request looks like: curl -s -S -i -H \"Authorization: Thing <thing_key>\" http://localhost:<service_port>/messages?offset=0&limit=5&format=json If you don't provide offset and limit parameters, default values will be used instead: 0 for offset and 10 for limit . The format parameter indicates in which format the messages will be returned. The default format is senml if the format is not defined, and if the desired format is JSON, you need to specify json for the format.","title":"Readers"},{"location":"storage/#mongodb-reader","text":"To start MongoDB reader, execute the following command: docker-compose -f docker/addons/mongodb-reader/docker-compose.yml up -d","title":"MongoDB Reader"},{"location":"storage/#postgresql-reader","text":"To start PostgreSQL reader, execute the following command: docker-compose -f docker/addons/postgres-reader/docker-compose.yml up -d","title":"PostgreSQL Reader"},{"location":"storage/#timescale-reader","text":"To start Timescale reader, execute the following command: docker-compose -f docker/addons/timescale-reader/docker-compose.yml up -d","title":"Timescale Reader"},{"location":"tracing/","text":"Tracing # Distributed tracing is a method of profiling and monitoring applications. It can provide valuable insight when optimizing and debugging an application. Mainflux includes the Jaeger open tracing framework as a service with its stack by default. Launch # The Jaeger service will launch with the rest of the Mainflux services. All services can be launched using: make run The Jaeger UI can then be accessed at http://localhost:16686 from a browser. Details about the UI can be found in Jaeger's official documentation . Configure # The Jaeger service can be disabled by using the scale flag with docker-compose up and setting the jaeger container to 0. --scale jaeger=0 make rungw will run all of the Mainflux services except for the Jaeger service. This is currently the only difference from make run . The make rungw command runs Mainflux for gateway devices. There could potentially be more differences running with this command in the future. Jaeger uses 5 ports within the Mainflux framework. These ports can be edited in the .env file. Variable Description Default MF_JAEGER_PORT Agent port for compact jaeger.thrift protocol 6831 MF_JAEGER_FRONTEND UI port 16686 MF_JAEGER_COLLECTOR Collector for jaeger.thrift directly from clients 14268 MF_JAEGER_CONFIGS Configuration server 5778 MF_JAEGER_URL Jaeger access from within Mainflux jaeger:6831 Example # As an example for using Jaeger, we can look at the traces generated after provisioning the system. Make sure to have ran the provisioning script that is part of the Getting Started step. Before getting started with Jaeger, there are a few terms that are important to define. A trace can be thought of as one transaction within the system. A trace is made up of one or more spans . These are the individual steps that must be taken for a trace to perform its action. A span has tags and logs associated with it. Tags are key-value pairs that provide information such as a database type or http method. Tags are useful when filtering traces in the Jaeger UI. Logs are structured messages used at specific points in the trace's transaction. These are typically used to indicate an error. When first navigating to the Jaeger UI, it will present a search page with an empty results section. There are multiple fields to search from including service, operation, tags and time frames. Clicking Find Traces will fill the results section with traces containing the selected fields. The top of the results page includes a scatter plot of the traces and their durations. This can be very useful for finding a trace with a prolonged runtime. Clicking on one of the points will open the trace page of that trace. Below the graph is a list of all the traces with a summary of its information. Each trace shows a unique identifier, the overall runtime, the spans it is composed of and when it was ran. Clicking on one of the traces will open the trace page of that trace. The trace page provides a more detailed breakdown of the individual span calls. The top of the page shows a chart breaking down what spans the trace is spending its time in. Below the chart are the individual spans and their details. Expanding the spans shows any tags associated with that span and process information. This is also where any errors or logs seen while running the span will be reported. This is just a brief overview of the possibilities of Jaeger and its UI. For more information, check out Jaeger's official documentation .","title":"Tracing"},{"location":"tracing/#tracing","text":"Distributed tracing is a method of profiling and monitoring applications. It can provide valuable insight when optimizing and debugging an application. Mainflux includes the Jaeger open tracing framework as a service with its stack by default.","title":"Tracing"},{"location":"tracing/#launch","text":"The Jaeger service will launch with the rest of the Mainflux services. All services can be launched using: make run The Jaeger UI can then be accessed at http://localhost:16686 from a browser. Details about the UI can be found in Jaeger's official documentation .","title":"Launch"},{"location":"tracing/#configure","text":"The Jaeger service can be disabled by using the scale flag with docker-compose up and setting the jaeger container to 0. --scale jaeger=0 make rungw will run all of the Mainflux services except for the Jaeger service. This is currently the only difference from make run . The make rungw command runs Mainflux for gateway devices. There could potentially be more differences running with this command in the future. Jaeger uses 5 ports within the Mainflux framework. These ports can be edited in the .env file. Variable Description Default MF_JAEGER_PORT Agent port for compact jaeger.thrift protocol 6831 MF_JAEGER_FRONTEND UI port 16686 MF_JAEGER_COLLECTOR Collector for jaeger.thrift directly from clients 14268 MF_JAEGER_CONFIGS Configuration server 5778 MF_JAEGER_URL Jaeger access from within Mainflux jaeger:6831","title":"Configure"},{"location":"tracing/#example","text":"As an example for using Jaeger, we can look at the traces generated after provisioning the system. Make sure to have ran the provisioning script that is part of the Getting Started step. Before getting started with Jaeger, there are a few terms that are important to define. A trace can be thought of as one transaction within the system. A trace is made up of one or more spans . These are the individual steps that must be taken for a trace to perform its action. A span has tags and logs associated with it. Tags are key-value pairs that provide information such as a database type or http method. Tags are useful when filtering traces in the Jaeger UI. Logs are structured messages used at specific points in the trace's transaction. These are typically used to indicate an error. When first navigating to the Jaeger UI, it will present a search page with an empty results section. There are multiple fields to search from including service, operation, tags and time frames. Clicking Find Traces will fill the results section with traces containing the selected fields. The top of the results page includes a scatter plot of the traces and their durations. This can be very useful for finding a trace with a prolonged runtime. Clicking on one of the points will open the trace page of that trace. Below the graph is a list of all the traces with a summary of its information. Each trace shows a unique identifier, the overall runtime, the spans it is composed of and when it was ran. Clicking on one of the traces will open the trace page of that trace. The trace page provides a more detailed breakdown of the individual span calls. The top of the page shows a chart breaking down what spans the trace is spending its time in. Below the chart are the individual spans and their details. Expanding the spans shows any tags associated with that span and process information. This is also where any errors or logs seen while running the span will be reported. This is just a brief overview of the possibilities of Jaeger and its UI. For more information, check out Jaeger's official documentation .","title":"Example"}]}